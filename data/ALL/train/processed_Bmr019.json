[
    {
        "transcript": "OK , we 're on . OK . So , I mean , everyone who 's on the wireless check that they 're on . C we {disfmarker} Alright . I see . Yeah . Yeah . OK , our agenda was quite short . Oh , could you {pause} close the door , maybe ? Yeah . Sure . Two items , which was , uh , digits and possibly stuff on {disfmarker} on , uh , forced alignment , which Jane said that Liz and Andreas had in information on ,  but they didn't , Mm - hmm . I guess the only other thing , uh , for which I {disfmarker} so . We should do that second , because Liz might join us in time for that . OK . Um . OK , so there 's digits , alignments , and , um , I guess the other thing , {vocalsound} which I came unprepared for , uh , {vocalsound} is , uh , to dis s s see if there 's anything anybody wants to discuss about the Saturday meeting . Right . So . Any {disfmarker} I mean , maybe not . Digits and alignments . But {disfmarker} Uh . Talk about aligning people 's schedules . Yeah . Yeah . Mm - hmm . Yeah . I mean {disfmarker} Right . Yeah , I mean , it was {disfmarker} Yeah , it 's forced alignment of people 's schedules . Yeah . Forced align . If we 're very {disfmarker} Yeah . Yeah . With {disfmarker} with {disfmarker} whatever it was , a month and a half or something ahead of time , the only time we could find in common {disfmarker} roughly in common , was on a Saturday . Yeah . Ugh . Yep . It 's pretty sad . Yeah . Yeah . Have {disfmarker} Have we thought about having a conference call to include him in more of {disfmarker} {vocalsound} in more of the meeting ? I {disfmarker} I mean , I don't know , if we had the {disfmarker} if we had the telephone on the table {disfmarker} No . But , h I mean , he probably has to go do something . No , actually I {disfmarker} I have to {disfmarker} I have to shuttle {pause} kids from various places to various other places . Right ? I see . OK . Yeah . So . And I don't have {disfmarker} and I don't , um , have a cell phone A cell phone ? so I can't be having a conference call while driving . R r right . No . {comment} It 's not good . So we have to {disfmarker} we {disfmarker} That 's not good . Plus , it would make for interesting noise {disfmarker} background noise .  Yep . Uh {disfmarker} So we have to equip him with a {disfmarker} with a {disfmarker} {vocalsound} with a head - mounted , uh , cell phone Ye - we and we 'd have to force you to read lots and lots of digits , and {disfmarker} so it could get real {disfmarker} {vocalsound} real car noise . Oh , yeah . Yeah . Oh , yeah . Take advantage . And with the kids in the background . I 'll let {disfmarker} I 'd let {disfmarker} Yeah . I let , uh , my five - year - old have a try at the digits , eh . Yeah . So , anyway , I can talk about digits . Um , did everyone get the results or shall I go over them again ? I mean that it was basically {disfmarker} the only thing that was even slightly surprising was that the lapel did so well . Um , and in retrospect that 's not as surprising as maybe i it shouldn't have been as surprising as I {disfmarker} as {disfmarker} as I felt it was . The lapel mike is a very high - quality microphone . And as Morgan pointed out , that there are actually some advantages to it in terms of breath noises and clothes rustling {pause} if no one else is talking . Yeah . Exactly . Um , so , uh {disfmarker} Mm - hmm . Well , it 's {disfmarker} Yeah , sort of the bre the breath noises and the mouth clicks and so forth like that , the lapel 's gonna be better on . It 's g it {disfmarker} Or the cross - talk . Yeah . The lapel is typically worse on the {disfmarker} on clothes rustling , but if no one 's rustling their clothes , Right . I mean , a lot of people are just sort of leaning over and reading the digits , it 's {disfmarker} it 's {disfmarker} so it 's {disfmarker} it 's a very different task than sort of the natural . Yeah . You don't move much during reading digits , I think . Yeah . So . Yeah . Right . Probably the fact that it picks up other people 's speakers {disfmarker} other people 's talking is an indication of that it {disfmarker} the fact it is a good microphone . Yeah . Right . So in the digits , in most {disfmarker} most cases , there weren't other people talking . Right . Right . So . So . D do the lapel mikes have any directionality to them ? There typically don't , no . Because I {disfmarker} I suppose you could make some that have sort of {disfmarker} that you have to orient towards your mouth , They have a little bit , and then it would {disfmarker} but they 're not noise - cancelling . So , uh {disfmarker} They 're {disfmarker} they 're intended to be omni - directional . Right . And th it 's {disfmarker} and because you don't know how people are gonna put them on , you know . Mm - hmm . Right . So , also , Andreas , on that one the {disfmarker} the back part of it should be right against your head . And that will he keep it from flopping aro up and down as much . It is against my head . OK . Yeah . Um . Yeah , we actually talked about this in the , uh , front - end meeting this morning , too . Much the same thing , Uh - huh . and {disfmarker} and it was {disfmarker} uh , I mean , there the point of interest to the group was primarily that , um , {vocalsound} the , uh {disfmarker} the system that we had that was based on H T K , that 's used by , you know , {pause} all the participants in Aurora , {vocalsound} was so much worse {vocalsound} than the {disfmarker} than the S R Everybody . And the interesting thing is that even though , {vocalsound} yes , it 's a digits task and that 's a relatively small number of words and there 's a bunch of digits that you train on , {vocalsound} it 's just not as good as having a {disfmarker} a l very large amount of data and training up a {disfmarker} a {disfmarker} a nice good big {vocalsound} HMM . Um , also you had the adaptation in the SRI system , which we didn't have in this . Um . So . Um . And we know {disfmarker} Di - did I send you some results without adaptation ? No . I s I think Stephane , uh , had seen them . Or if you did , I didn't include them , cuz it was {disfmarker} So {disfmarker} Yeah , I think I did , actually . So there was a significant loss from not doing the adaptation . Yeah . Um . A {disfmarker} a {disfmarker} a couple percent or some I mean {disfmarker} Well , I don't know it {disfmarker} Overall {disfmarker} Uh , I {disfmarker} I don't remember , but there was {disfmarker} {nonvocalsound} there was a significant , um , loss or win {comment} from adaptation {disfmarker} with {disfmarker} with adaptation . And , um , that was the phone - loop adaptation . And then there was a very small {disfmarker} like point one percent on the natives {disfmarker} uh , win from doing , um , you know , adaptation to {pause} the recognition hypotheses . And {pause} I tried both means adaptation and means and variances , and the variances added another {disfmarker} or subtracted another point one percent . So , {vocalsound} it 's , um {disfmarker} that 's the number there . Point six , I believe , is what you get with both , uh , means and variance adaptation . Right . But I think one thing is that , uh , I would presume {disfmarker} Hav - Have you ever t {vocalsound} Have you ever tried this exact same recognizer out on the actual TI - digits test set ? This exact same recognizer ? No . It might be interesting to do that . Cuz my {disfmarker} my {disfmarker} cuz my sense , um {disfmarker} But {disfmarker} but , I have {disfmarker} I mean , people {disfmarker} people at SRI are actually working on digits . I bet it would do even slightly better . I could {disfmarker} and they are using a system that 's , um {disfmarker} you know , h is actually trained on digits , um , but h h otherwise uses the same , you know , decoder , the same , uh , training methods , and so forth , Mm - hmm . and I could ask them what they get {pause} on TI - digits . Yeah , bu although I 'd be {disfmarker} I think it 'd be interesting to just take this exact actual system so that these numbers were comparable Mm - hmm . and try it out on TI - digits . Well , Adam knows how to run it , Yeah . Yeah . No problem . so you just make a f Yeah . Yeah . Cuz our sense from the other {disfmarker} from the Aurora , uh , task is that {disfmarker} And try it with TI - digits ? Mm - hmm . I mean , cuz we were getting sub one percent {vocalsound} numbers on TI - digits also with the tandem thing . Mm - hmm . So , {vocalsound} one {disfmarker} so there were a number of things we noted from this . Mmm . One is , yeah , the SRI system is a lot better than the HTK {disfmarker} Hmm . this , you know , very limited training HTK system . Mm - hmm . Uh , but the other is that , um , the digits {vocalsound} recorded here in this room with these close mikes , i uh , are actually a lot harder than the {pause} studio - recording TI - digits . I think , you know , one reason for that , uh , might be that there 's still {disfmarker} even though it 's close - talking , there still is some noise and some room acoustics . Mm - hmm . Mm - hmm . And another might be that , uh , I 'd {disfmarker} I would presume that in the studio , uh , uh , situation recording read speech that if somebody did something a little funny or n pronounced something a little funny or made a little {disfmarker} that they didn't include it , They didn't include it . they made them do it again . Whereas , I took out {pause} the ones that I noticed that were blatant {disfmarker} that were correctable . Mmm . Yeah . So that , if someone just read the wrong digit , I corrected it . Yeah . And then there was another one where Jose couldn't tell whether {disfmarker} I couldn't tell whether he was saying zero or six . And I asked him and he couldn't tell either . Hmm . So I just cut it out . Yeah . You know , so I just e edited out the first , i uh , word of the utterance . Um , so there 's a little bit of correction but it 's definitely not as clean as TI - digits . So my expectations is TI - digits would , especially {disfmarker} I think TI - digits is all {pause} American English . Mm - hmm . Right ? So it would probably do even a little better still on the SRI system , but we could give it a try . Well . But {pause} remember , we 're using a telephone bandwidth front - end here , uh , on this , uh {disfmarker} on this SRI system , so , {vocalsound} um , I was {disfmarker} I thought that maybe that 's actually a good thing because it {disfmarker} it gets rid of some of the {disfmarker} uh , the noises , um , you know , in the {disfmarker} the {disfmarker} below and above the {disfmarker} um , the , you know , speech bandwidth Mm - hmm . Mm - hmm . and , um , I suspect that to get sort of the last bit out of these higher - quality recordings you would have to in fact , uh , use models that , uh , were trained on wider - band data . And of course we can't do that or {disfmarker} Wha - what 's TI - digits ? I thought t It 's wide - band , yeah . It 's {disfmarker} in {disfmarker} in fact , we looked it up It is wide - band . OK . and it was actually twenty kilohertz sampling . Oh , that 's right . I {disfmarker} I did look that up . Mm - hmm . I couldn't remember whether that was TI - digits or one of the other digit tasks . Yeah . Right . But {disfmarker} but , I would {disfmarker} Yeah . It 's {disfmarker} it 's easy enough to try , just run it on {disfmarker} Yeah . Mm - hmm . See w So , Morgan , you 're getting a little breath noise . Now , eh , does {disfmarker} You might wanna move the mike down a little bit . one {disfmarker} one issue {disfmarker} one issue with {disfmarker} with that is that {vocalsound} um , the system has this , uh , notion of a speaker to {disfmarker} which is used in adaptation , variance norm uh , you know , both in , uh , mean and variance normalization and also in the VTL {pause} estimation . Mm - hmm . So {disfmarker} Yeah , I noticed the script that extracted it . Do y ? Is {disfmarker} ? So does {disfmarker} so th so does {disfmarker} does , um , {vocalsound} the TI - digits database have speakers that are known ? Yep . Yep . And is there {disfmarker} is there enough data or a comparable {disfmarker} comparable amount of data to {disfmarker} to what we have in our recordings here ? That I don't know . I don't know . I don't know how many speakers there are , Yeah . and {disfmarker} and how many speakers per utterance . OK . Well , the other thing would be to do it without the adaptation and compare to these numbers without the adaptation . That would {disfmarker} Right . Uh , but I 'm not so much worried about the adaptation , actually , than {disfmarker} than the , um , {vocalsound} um {disfmarker} the , uh , VTL estimation . Right . If you have only one utterance per speaker you might actually screw up on estimating the {disfmarker} the warping , uh , factor . So , um {disfmarker} I strongly suspect that they have more speakers than we do . So , uh {disfmarker} Right . But it 's not the amount of speakers , it 's the num it 's the amount of data per speaker . Right . So we {disfmarker} we could probably do an extraction that was roughly equivalent . Right . Right . Um . So {disfmarker} So , although I {disfmarker} I sort of know how to run it , there are a little {disfmarker} a f few details here and there that I 'll have to {pause} dig out . OK . The key {disfmarker} So th the system actually extracts the speaker ID from the waveform names . Right . I saw that . And there 's a {disfmarker} there 's a script {disfmarker} and that is actually all in one script . So there 's this one script that parses waveform names and extracts things like the , um , speaker , uh , ID or something that can stand in as a speaker ID . So , we might have to modify that script to recognize the , um , speakers , {vocalsound} um , in the {disfmarker} in the , uh , um , {vocalsound} TI - digits {pause} database . Right . Right . And that , uh {disfmarker} Or you can fake {disfmarker} you can fake {pause} names for these waveforms that resemble the names that we use here for the {disfmarker} for the meetings . Right . That would be the , sort of {disfmarker} probably the safest way to do {disfmarker} I might have to do that anyway to {disfmarker} to do {disfmarker} because we may have to do an extract to get the {pause} amount of data per speaker about right . Uh - huh . The other thing is , isn't TI - digits isolated digits ? Right . Or is that another one ? I 'm {disfmarker} I looked through a bunch of the digits t corp corpora , and now they 're all blurring . Mm - hmm . Cuz one of them was literally people reading a single digit . And then others were connected digits . Yeah . Most of TI - digits is connected digits , I think . OK . The {disfmarker} I mean , we had a Bellcore corpus that we were using . It was {disfmarker} {vocalsound} that 's {disfmarker} that was isolated digits . Maybe it 's the Bell Gram . Bell Digits . Alright . Um . By the way , I think we can improve these numbers if we care to compr improve them {vocalsound} by , um , {vocalsound} not starting with the Switchboard models but by taking the Switchboard models and doing supervised adaptation on a small amount of digit data collected in this setting . Yep . Because that would adapt your models to the room acoustics and f for the far - field microphones , you know , to the noise . And that should really improve things , um , further . And then you use those adapted models , which are not speaker adapted but sort of acous you know , channel adapted {disfmarker} Channel adapted . use that as the starting models for your speaker adaptation . Yeah . {vocalsound} But the thing is , uh {disfmarker} I mean , w when you {disfmarker} it depends whether you 're ju were just using this as a {disfmarker} {vocalsound} a starter task for {disfmarker} you know , to get things going for conversational or if we 're really interested i in connected digits . And I {disfmarker} I think the answer is both . And for {disfmarker} for connected digits over the telephone you don't actually want to put a whole lot of effort into adaptation Well , I don't know . because {vocalsound} somebody {pause} gets on the phone and says a number and then you just want it . You don't {disfmarker} don't , uh {disfmarker} This is {disfmarker} this {disfmarker} that one 's better . Right . Mm - hmm . Um , but , you know , I {disfmarker} uh , my impression was that you were actually interested in the far - field microphone , uh , problem , I mean . So , you want to {disfmarker} you want to {disfmarker} That 's the obvious thing to try . Oh . Oh . Right . Right ? Then , eh {disfmarker} because you {disfmarker} you don't have any {disfmarker} Yeah . That 's where the most m acoustic mismatch is between the currently used models and the {disfmarker} the r the set up here . Right . So . Yeah . So that 'd be anoth another interesting data point . Mm - hmm . I mean , I {disfmarker} I guess I 'm saying I don't know if we 'd want to do that as the {disfmarker} as {disfmarker} Other way . Other way . Liz {disfmarker} Now you 're all watching me . It f it clips over your ears . Alright . This way . There you go . If you have a strong fe if you have a strong preference , you could use this . You 're all watching . This is terrible . It 's just we {disfmarker} we think it has some spikes . So , uh , we {disfmarker} we didn't use that one . I 'll get it . But you could if you want . Yeah . At any rate , I don't know if w I don't know . And Andre - Andreas , your {disfmarker} your microphone 's a little bit low . Yeah . It is ? I don't know if we wanna use that as the {disfmarker} Yeah . Uh , it pivots . Uh . So if you see the picture It {disfmarker} it {disfmarker} like this . I I {disfmarker} and then you have to scr I {disfmarker} I already adjusted this a number of times . Eh . I {disfmarker} I Yeah , I think these mikes are not working as well as I would like . can't quite seem to {disfmarker} Yeah , I think this contraption around your head is not {pause} working so well . Too many adju too many adjustments . Yeah . Anyway , what I was saying is that I {disfmarker} I think I probably wouldn't want to see that as sort of like the norm , that we compared all things to . That looks good . Yeah . To , uh , the {disfmarker} to have {disfmarker} have all this ad all this , uh , adaptation . But I think it 's an important data point , if you 're {disfmarker} if {disfmarker} Yeah . Right . Um . The other thing that {disfmarker} that , uh {disfmarker} of course , what Barry was looking at was {disfmarker} was just that , the near versus far . And , yeah , the adaptation would get {vocalsound} th some of that . Mm - hmm . But , I think even {disfmarker} even if there was , uh , only a factor of two or something , like I was saying in the email , I think that 's {disfmarker} {vocalsound} that 's a big factor . So {disfmarker} Mm - hmm . N Liz , you could also just use the other mike if you 're having problems with that one . Well . OK . Yeah . This would be OK . We {disfmarker} we {disfmarker} we think that this has spikes on it , It 's this thing 's {disfmarker} This is too big for my head . so it 's not as good acoustically , Yeah , basically your ears are too big . but {disfmarker} I mean , mine are too . E th everybody 's ears are too big for these things . No , my {disfmarker} my {disfmarker} But this is too big for my head . So , I mean , {comment} {comment} it doesn't {disfmarker} you know , it 's sit Uh {disfmarker} Well , if you 'd rather have this one then it 's {disfmarker} OK . Yeah . Oh , well . It 's {pause} great . So the {disfmarker} To get that , uh , pivoted this way , it pivots like this . No this way . Yeah . Yeah . There you go . And there 's a screw that you can tighten . And then it {disfmarker} Right . Right . I already {pause} tried to get it close . Good . So if it doesn't bounce around too much , that 's actually good placement . OK . That looks good . But it looks like it 's gonna bounce a lot . So , where were we ? Uh {disfmarker} {vocalsound} Yeah . Yeah . Digits . Adaptation . Uh , adaptation , non - adaptation , um , factor of two , um {disfmarker} Oh , yeah . I know what I was go w What k u By the way , wh what factor of two did you {disfmarker} ? Oh , no , no . I mean {disfmarker} It 's tha that {disfmarker} that we were saying , you know , well is {disfmarker} how much worse is far than near , you know . Oh , th OK . And I mean it depends on which one you 're looking at , That factor of two . but for the everybody , it 's {vocalsound} little under a factor or two . Mm - hmm . Yeah . I {disfmarker} I know what I was thinking was that maybe , uh , i i we could actually t t try at least looking at , uh , some of the {disfmarker} the large vocabulary speech from a far microphone , at least from the good one . Mm - hmm . I mean , before I thought we 'd get , you know , a hundred and fifty percent error or something , but if {disfmarker} {vocalsound} if , uh {disfmarker} if we 're getting thirty - five , forty percent or something , {vocalsound} u um {disfmarker} Mm - hmm . Actually if you run , though , on a close - talking mike over the whole meeting , during all those silences , you get , like , four hundred percent word error . Mm - hmm . Right . I understand . But doing the same kind of limited thing {disfmarker} Or {disfmarker} or some high number . Yeah , sure . Get all these insertions . But I 'm saying if you do the same kind of limited thing {vocalsound} as people have done in Switchboard evaluations or as {disfmarker} a Yeah . Where you know who the speaker is and there 's no overlap ? And you do just the far - field for those regions ? Yeah . Yeah . The same sort of numbers that we got those graphs from . Right ? Could we do exactly the same thing that we 're doing now , but do it with a far - field mike ? Yeah , do it with one of {disfmarker} on Cuz we extract the times from the near - field mike , but you use the acoustics from the far - field mike . Right . I understand that . I just meant that {disfmarker} so you have {pause} three choices . There 's , um {disfmarker} You can use times where that person is talking only from the transcripts but the segmentations were {disfmarker} were synchronized . Or you can do a forced alignment on the close - talking to determine that , the you know , within this segment , these really were the times that this person was talking and elsewhere in the segment other people are overlapping and just front - end those pieces . Or you can run it on the whole data , which is {disfmarker} which is , you know , a {disfmarker} But {disfmarker} but {disfmarker} but how did we get the {disfmarker} how did we determine the links , uh , that we 're testing on in the stuff we reported ? In the H L T paper we took {pause} segments that are channel {disfmarker} time - aligned , which is now h being changed in the transcription process , which is good , and we took cases where the transcribers said there was only one person talking here , because no one else had time {disfmarker} any words in that segment and called that \" non - overlap \" . And tha And that 's what we were getting those numbers from . Yes . Tho - good {disfmarker} the good numbers . Right . The bad numbers were from {pause} the segments where there was overlap . Well , we could start with the good ones . Yeah . But anyway {disfmarker} so I think that we should try it once with {vocalsound} the same conditions that were used to create those , and in those same segments just use one of the P Z Right . So we {disfmarker} we can do that . Yeah . And then , you know , I mean , the thing is if we were getting , uh {disfmarker} what , thirty - five , forty percent , something like that on {disfmarker} on that particular set , uh , does it go to seventy or eighty ? Right . Or , does it use up so much memory we can't decode it ? It might also depend on which speaker th it is and how close they are to the PZM ? Uh {disfmarker} I don't know how different they are from each other . You want to probably choose the PZM channel that is closest to the speaker . To be best {disfmarker} Yeah . For this particular digit ones , I just picked that one . f Well {disfmarker} OK . So we would then use that one , too , So {disfmarker} Oh , OK . This is kind of central . or {disfmarker} ? You know , it 's {disfmarker} so i but I would {disfmarker} I 'd pick that one . It 'll be less good for some people than for other , but I {disfmarker} I 'd like to see it on the same {disfmarker} exact same data set that {disfmarker} that we did the other thing on . Actually {disfmarker} I sh actually should 've picked a different one , Right ? because {pause} that could be why the PDA is worse . Because it 's further away from most of the people reading digits . It 's further away . Yeah . Yeah . That 's probably one of the reasons . Hmm . Mm - hmm . Well , yeah . You could look at , I guess , that PZM or something . Yep . But the other is , it 's very , uh {disfmarker} I mean , even though there 's {disfmarker} I 'm sure the f f the {disfmarker} the SRI , uh , front - end has some kind of pre - emphasis , it 's {disfmarker} it 's , uh {disfmarker} {vocalsound} still , th it 's picking up lots of low - frequency energy . Mm - hmm . So , even discriminating against it , I 'm sure some of it 's getting through . Um . But , yeah , you 're right . Prob - a part of it is just the distance . And aren't these pretty bad microphones ? Yep . I mean {disfmarker} Well , they 're bad . But , I mean , if you listen to it , it sounds OK . You know ? u Yeah . Yeah . When you listen to it , uh , the PZM and the PDA {disfmarker} Yeah , th the PDA has higher sound floor but not by a lot . It 's really pretty {disfmarker} uh , pretty much the same . I just remember you saying you got them to be cheap on purpose . Cheap in terms of their quality . So . Well , they 're {pause} twenty - five cents or so . Th - we wanted them to be {disfmarker} to be typical of what would be in a PDA . Yeah . Mm - hmm . So they are {disfmarker} they 're not the PZM three hundred dollar type . They 're the twenty - five cent , Yeah . buy them in packs of thousand type . I see . But , I mean , the thing is people use those little mikes for everything because they 're really not bad . Everything . Mm - hmm . I mean , if you 're not {vocalsound} doing something ridiculous like feeding it to a speech recognizer , they {disfmarker} they {disfmarker} {vocalsound} they {disfmarker} you know , you can hear the sou hear the sounds just fine . Right . You know , it 's {disfmarker} They {disfmarker} I mean , i it 's more or less the same principles as these other mikes are built under , it 's just that {pause} there 's less quality control . They just , you know , churn them out and don't check them . Um . So . So that was {disfmarker} Yeah . So that was i interesting result . So like I said , the front - end guys are very much interested in {disfmarker} in this is as {disfmarker} as well and So {disfmarker} so , but where is this now ? I mean , what 's {disfmarker} where do we go from here ? Yeah . That was gonna be my question . I mean , we {disfmarker} so we have a {disfmarker} we have a {disfmarker} a system that works pretty well but it 's not , you know , the system that people here are used to using {disfmarker} to working with . Well , I think what we wanna do is we want to {disfmarker} eh , So what {disfmarker} what do we do now ? and we 've talked about this in other {pause} contexts {disfmarker} we want to {vocalsound} have the ability to feed it different features . Mm - hmm . And then , um , {vocalsound} from the point of view of the front - end research , it would be s uh , substituting for HTK . OK . OK . I think that 's the key thing . And then if we can feed it different features , then we can try all the different things that we 're trying there . OK . Alright . And then , um , uh , also Dave is {disfmarker} is thinking about using the data in different ways , uh , to {vocalsound} um , uh , explicitly work on reverberation Mm - hmm . starting with some techniques that some other people have {pause} found somewhat useful , and {disfmarker} Yeah . OK . So {disfmarker} so the key {pause} thing that 's missing here is basically the ability to feed , you know , other features {vocalsound} i into the recognizer Right . and also then to train the system . Right . OK . And , uh , es I don't know when Chuck will be back but that 's exactly what he {disfmarker} he 's gonna {disfmarker} H h He 's {disfmarker} he 's sort of back , but he drove for fourteen hours an and wasn't gonna make it in today . Oh , OK . So , I think that 's one of the things that he said he would be working on . Um . Yeah . Just sort of t to make sure that {pause} we can do that Yeah . and {disfmarker} Um . Right . It 's {disfmarker} uh , I mean , the {disfmarker} the front - end is f i tha that 's in the SRI recognizer is very nice in that it does a lot of things on the fly but it unfortunately {pause} is not {pause} designed and , um {disfmarker} {vocalsound} like the , uh , ICSI system is , where you can feed it from a pipeline of {disfmarker} of the command . So , the {disfmarker} what that means probably for the foreseeable future is that you have to , uh , dump out , um {disfmarker} you know , if you want to use some new features , you have to dump them into individual files and {pause} give those files to the recognizer . We do {disfmarker} we tend to do that anyway . OK . Oh . So , although you {disfmarker} you can pipe it as well , we tend to do it that way because that way you can concentrate on one block and not keep re - doing it over and over . Oh , OK . Yeah . Alright . Yeah . So I 've {disfmarker} I {disfmarker} So tha that 's exactly what the P - file {pause} is for . Yeah . Yeah , the {disfmarker} the {disfmarker} the cumbersome thing is {disfmarker} is , um {disfmarker} is that you actually have to dump out little {disfmarker} little files . Uh {disfmarker} So for each segment that you want to recognize {vocalsound} you have to {pause} dump out {pause} a separate file . Uh - huh . Just like i th like th as if there were these waveform segments , but instead you have sort of feature file segments . But , you know {disfmarker} So . Cool . OK . So the s the {disfmarker} the next thing we had on the agenda was something about alignments ? Oh . Yes , we have {disfmarker} I don't know , did you wanna talk about it , or {disfmarker} ? I can give a {disfmarker} I was just telling this to Jane and {disfmarker} and {disfmarker} W we {disfmarker} we were able to get some definite improvement on the forced alignments by looking at them first and then realizing the kinds of errors {pause} that were occurring and um , some of the errors occurring very frequently are just things like the first word being moved to as early as possible in the recognition , which is a um , I think was both a {disfmarker} a pruning {pause} problem and possibly a problem with needing constraints on word locations . And so we tried both of these st things . We tried saying {disfmarker} I don't know , I got this {vocalsound} whacky idea that {disfmarker} just from looking at the data , that when people talk {pause} their words are usually chunked together . It 's not that they say one word and then there 's a bunch of words together . They 're {comment} might say one word and then another word far away if they were doing just backchannels ? But in general , if there 's , like , five or six words and one word 's far away from it , that 's probably wrong on average . So , um {disfmarker} And then also , ca the pruning , of course , was too {disfmarker} too severe . So that 's actually interesting . The pruning was the same value that we used for recognition . And we had lowered that {disfmarker} we had used tighter pruning after Liz ran some experiments showing that , you know , it runs slower and there 's no real difference in {disfmarker} Actually it was better with {disfmarker} slightly better or about th No gain . it was the same with tighter pruning . Right . So for free recognition , this {disfmarker} the lower pruning value is better . It 's probably cuz the recognition 's just bad en at a point where it 's bad enough that {disfmarker} that you don't lose anything . You {disfmarker} Correct . Right . Um , but it turned out for {disfmarker} for {disfmarker} to get accurate alignments it was really important to open up the pruning significantly . Right . Hmm . Um {pause} because otherwise it would sort of do greedy alignment , um , in regions where there was no real speech yet from the foreground speaker . Mm - hmm . Um , {vocalsound} so that was one big factor that helped improve things and then the other thing was that , you know , as Liz said the {disfmarker} we f enforce the fact that , uh , the foreground speech has to be continuous . It cannot be {disfmarker} you cannot have a background speech hypothesis in the middle of the foreground speech . You can only have background speech at the beginning and the end . Yeah . I mean , yeah , it isn't always true , and I think what we really want is some clever way to do this , where , um , you know , from the data or from maybe some hand - corrected alignments from transcribers that things like words that do occur just by themselves {pause} a alone , like backchannels or something that we did allow to have background speech around it {disfmarker} Yeah . those would be able to do that , Sorry . but the rest would be constrained . So , I think we have a version that 's pretty good for the native speakers . I don't know yet about the non - native speakers . And , um , we basically also made noise models for the different {disfmarker} sort of grouped some of the {pause} mouth noises together . Um , so , and then there 's a background speech model . And we also {disfmarker} There was some neat {disfmarker} or , interesting cases , like there 's one meeting where , {vocalsound} um , Jose 's giving a presentation and he 's talking about , um , the word \" mixed {pause} signal \" and someone didn't understand , uh , that you were saying \" mixed \" {disfmarker} I think , Morgan . And so your speech - ch was s saying something about mixed signal . Yeah , yeah . And the next turn was a lot of people saying \" mixed \" , like \" he means mixed signal \" or \" I think it 's mixed \" . And the word \" mixed \" in this segment occurs , like , a bunch of times . Sh And Chuck 's on the lapel here , and he also says \" mixed \" but it 's at the last one , and of course the aligner th aligns it everywhere else to everybody else 's \" mixed \" , Yeah . cuz there 's no adaptation yet . So there 's {disfmarker} {vocalsound} I think there 's some issues about {disfmarker} u We probably want to adapt at least the foreground speaker . But , I guess Andreas tried adapting both the foreground and a background generic speaker , and that 's actually a little bit of a f funky model . Like , it gives you some weird alignments , just because often the background speakers match better to the foreground than the foreground speaker . Oh {disfmarker} Yeah . So there 's some things there , Oh . especially when you get lots of the same words , uh , occurring in the {disfmarker} Well , the {disfmarker} I {disfmarker} I think you can do better by {vocalsound} uh , cloning {disfmarker} so we have a reject phone . And you {disfmarker} and what we wanted to try with {disfmarker} you know , once we have this paper written and have a little more time , {vocalsound} uh , t cloning that reject model and then one copy of it would be adapted to the foreground speaker to capture the rejects in the foreground , like fragments and stuff , and the other copy would be adapted to the background speaker . Right . I mean , in general we actually {disfmarker} And {disfmarker} Right now the words like {pause} partial words are {pause} reject models and you normally allow those to match to any word . Mm - hmm . But then the background speech was also a reject model , and so this constraint of not allowing rejects in between {disfmarker} you know , it needs to differentiate between the two . So just sort of working through a bunch of debugging kinds of issues . Right . And another one is turns , like people starting with {vocalsound} \" well I think \" and someone else is {pause} \" well how about \" . So the word \" well \" is in this {disfmarker} in this {pause} segment multiple times , and as soon as it occurs usually the aligner will try to align it to the first person who says it . But then that constraint of sort of {disfmarker} uh , proximity constraint will push it over to the person who really said it in general . Is the proximity constraint a hard constraint , or did you do some sort of probabilistic weighting distance , or {disfmarker} ? We {disfmarker} we didn't {disfmarker} Right now it 's a kluge . No . We {disfmarker} w OK . We {disfmarker} it 's straightforward to actually just have a {disfmarker} a penalty that doesn't completely disallows it but discourages it . But , um , we just didn't have time to play with , you know , tuning yet another {disfmarker} yet another parameter . The ve level . Yeah . Yeah . And really the reason we can't do it is just that we don't have a {disfmarker} we don't have ground truth for these . So , {vocalsound} we would need a hand - marked , um , {vocalsound} word - level alignments or at least sort of the boundaries of the speech betw you know , between the speakers . Um , and then use that as a reference and tune the parameters of the {disfmarker} of the model , uh , to op to get the best {pause} performance . Yeah . G given {disfmarker} I {disfmarker} I mean , I wa I wa I was gonna ask you anyway , uh , how you assessed that things were better . Mm - hmm . I looked at them . I spent two days {disfmarker} um , in Waves {disfmarker} OK . Oh , it was painful because {vocalsound} the thing is , you know the alignments share a lot in common , so {disfmarker} And you 're {disfmarker} yo you 're looking at these segments where there 's a lot of speech . I mean , a lot of them have a lot of words . Not by every speaker Yeah . but by some speaker there 's a lot of words . No , not {disfmarker} Yeah . I mean that if you look at the individual segments from just one person you don't see a lot of words , Ju Yeah . but altogether you 'll see a lot of words up there . Yeah . Mm - hmm . Yeah . And so the reject is also mapping and pauses {disfmarker} So I looked at them all in Waves and just lined up all the alignments , and , at first it sort of looked like a mess and then the more I looked at it , I thought \" OK , well it 's moving these words leftward and {disfmarker} \" You know , it wasn't that bad . It was just doing certain things wrong . So {disfmarker} But , I don't , you know , have time to l {comment} to look at all of them and it would be really useful to have , like , a {disfmarker} a transcriber who could use Waves , um , just mark , like , the beginning and end of the foreground speaker 's real words {disfmarker} like , the beginning of the first word , the end of the last word {disfmarker} and then we could , you know , do some adjustments . Yeah . I {disfmarker} OK . I have to ask you something , is i does it have to be Waves ? Because if we could benefit from what you did , incorporate that into the present transcripts , {comment} that would help . No . And then , um , the other thing is , I believe that I did hand So . One of these transcripts was gone over by a transcriber and then I hand - marked it myself so that we do have , uh , the beginning and ending of individual utterances . Um , I didn't do it word level , Mm - hmm . but {disfmarker} but in terms {disfmarker} Mm - hmm . So I {disfmarker} so for {disfmarker} for one of the N S A groups . And also I went back to the original one that I first transcribed and {disfmarker} and did it w uh , w uh , utterance by utterance for that particular one . So I think you do have {disfmarker} if that 's a sufficient unit , I think that you do have hand - marking for that . But it 'd be wonderful to be able to {vocalsound} benefit from your Waves stuff . Mm - hmm . We don't care what {disfmarker} what tool you use . Yeah . I mean , if {disfmarker} if you can , um {disfmarker} if you wanna {disfmarker} OK . I used it in Transcriber U uh {disfmarker} and it 's {disfmarker} it 's in the {disfmarker} well , Jane and I were {disfmarker} just in terms of the tool , talking about this . I guess Sue had had some {pause} reactions . You know , interface - wise if you 're looking at speech , you wanna be able to know really where the words are . And so , {vocalsound} we can give you some examples of sort of what this output looks like , Yeah , that 's right . Middle of the word , or {disfmarker} um , and see if you can in maybe incorporate it into the Transcriber tool some way , or {disfmarker} Well , I th I 'm thinking just ch e e incorporating it into the representation . Um . I mean , if it 's {disfmarker} if it 's {disfmarker} You mean like {disfmarker} Yeah , word start insights . if you have start points , if you have , like , time tags , Right . which is what I assume . Isn't that what {disfmarker} what you {disfmarker} ? Well , see , Adam would be {disfmarker} Yeah , whatever you use . Yeah . I mean , we convert it to this format that the , um , NIST scoring tool unders uh , CTM . Conversation Time - Marked file . And {disfmarker} and then that 's the {disfmarker} that 's what the {disfmarker} I think Transcriber , uh , outputs CTM . If it {disfmarker} ? OK . Yeah . So you would know this more than I would . I think so . So , I mean {disfmarker} It seems like she {disfmarker} if she 's g if she 's moving time marks around , Right . since our representation in Transcriber uses time marks , it seems like there should be some way of {disfmarker} of using that {disfmarker} benefitting from that . Right . Yeah , it wou the advantage would just be that when you brought up a bin you would be able {disfmarker} if you were zoomed in enough in Transcriber to see all the words , Mm - hmm . you would be able to , like , have the words sort of located in time , if you wanted to do that . So {disfmarker} so if we e e even just had a {disfmarker} a {disfmarker} It sounds like w we {disfmarker} {vocalsound} we almost do . So . Uh , if we {disfmarker} We have two . We have two . Yeah . Just ha uh , trying out {pause} the alignment {vocalsound} procedure that you have on that Mm - hmm . you could actually get something , um {disfmarker} uh , uh , get an objective measure . Uh {disfmarker} Mm - hmm . You mean on {disfmarker} on the hand - marked , um {disfmarker} So we {disfmarker} we only r hav I only looked at actually alignments from one meeting that we chose , Yeah . I think MR four , just randomly , um {disfmarker} And {disfmarker} Actually , not randomly . Not randomly {disfmarker} We knew {disfmarker} we knew that it had these insertion errors from {disfmarker} It had sort of {pause} average recognition performance in a bunch of speakers Yeah . Yeah . and it was a Meeting Recorder meeting . Um . But , yeah , we should try to use what you have . I did re - run recognition on your new version of MR one . Oh , good . I {disfmarker} I mean the {disfmarker} the one with Dan {pause} Ellis in it {vocalsound} and Eric . Good ! Uh - huh . Yeah , exactly . Yeah . Yeah . I don't think that was the new version . Um {disfmarker} That {disfmarker} Yeah , actually it wasn't the new new , it was the medium new . OK . But {disfmarker} but we would {disfmarker} we should do the {disfmarker} the latest version . OK . Yeah . It was the one from last week . You {disfmarker} did you adjust the {disfmarker} the utterance times , um , for each channel ? Yes . Yes , I did . And furthermore , I found that there were a certain number where {disfmarker} {vocalsound} not {disfmarker} not a lot , but several times I actually {vocalsound} moved an utterance from {vocalsound} Adam 's channel to Dan 's or from Dan 's to Adam 's . So there was some speaker identif And the reason was because {vocalsound} I transcribed that at a point before {disfmarker} {vocalsound} uh , before we had the multiple audio available f so I couldn't switch between the audio . I {disfmarker} I transcribed it off of the mixed channel entirely , which meant in overlaps , I was at a {disfmarker} at a terrific disadvantage . Right . Right . In addition it was before the channelized , uh , possibility was there . And finally I did it using the speakers of my , um {disfmarker} {vocalsound} of {disfmarker} you know , off the CPU on my {disfmarker} on my machine cuz I didn't have a headphone . Right . So it @ @ , like , I mean {disfmarker} Yeah , I {disfmarker} I mean , i in retrospect {vocalsound} it would 've been good to ha {vocalsound} have got I should 've gotten a headphone . But in any case , um , thi this is {disfmarker} this was transcribed in a {disfmarker} in a , {vocalsound} uh , less optimal way than {disfmarker} than the ones that came after it , and I was able to {disfmarker} you know , an and this meant that there were some speaker identif identifications which were changes . Well , I know there were some speaker labelling problems , um , after interruptions . Yeah . Fixed that . Is that what you 're referring to ? I mean , cuz there 's this one instance when , for example , you 're running down the stairs . Oh , well {disfmarker} I remember this meeting really well . Yeah . Don {disfmarker} Don has had {disfmarker} {vocalsound} He knows {disfmarker} he can just read it like a play . Right . It 's a {disfmarker} Yeah , I 've {disfmarker} I 've {disfmarker} I 'm very well acquainted with this meeting . Yeah . Yeah , I can s \" And then she said , and then he said . \" Yeah , I know it by heart . So , um , {vocalsound} there 's one point when you 're running down the stairs . Uh - oh . Right ? And , like , there 's an interruption . You interrupt somebody , but then there 's no line after that . For example , there 's no speaker identification after that line . Uh - huh . Is that what you 're talking about ? Or were there mislabellings as far as , like , the a Adam was {disfmarker} ? That was fixed , um , before {disfmarker} i i i I think I I think I understood that pretty {disfmarker} Yeah . Cuz I thought I let you know about that . Thank you for mentioning . Yeah , no , tha that {disfmarker} That I think went away a couple of versions ago , Yeah . OK . but it 's good to know . But you 're actually saying that certain , uh , speakers were mis mis - identified . Yeah . So , with {disfmarker} under {disfmarker} um , uh , listening to the mixed channel , there were times when , as surprising as that is , I got Adam 's voice confused with Dan 's and vice versa {disfmarker} OK . not for long utterances , OK . Yeah . but jus just a couple of places , Mm - hmm . and embedde embedded in overlaps . The other thing that was w interesting to me was that I picked up a lot of , um , backchannels which were hidden in the mixed signal , Right . which , you know , I mean , you c not {disfmarker} not too surprising . But the other thing that {disfmarker} I {disfmarker} I hadn't thought about this , but I thou I wanted to raise this when you were {disfmarker} uh , with respect to also a strategy which might help with the alignments potentially , but that 's {disfmarker} When I was looking at these backchannels , they were turning up usually {disfmarker} {vocalsound} very often in {disfmarker} w well , I won't say \" usually \" {disfmarker} but anyway , very often , I picked them up in a channel {vocalsound} w which was the person who had asked a question . S so , like , someone says \" an and have you done the so - and - so ? \" And then there would be backchannels , but it would be the person who asked the question . Other people weren't really doing much backchannelling . And , you know , sometimes you have the {disfmarker} Yeah , uh - huh . Well , that 's interesting . Yeah . I mean , i it wouldn't be perfect , but {disfmarker} but it does seem more natural to give a backchannel when {disfmarker} when you 're somehow involved in the topic , No , that 's really interesting . Mm - hmm . and the most natural way is for you to have initiated the topic by asking a question . Well , That 's interesting . I think {disfmarker} No . I think it 's {disfmarker} actually I think what 's going on is backchannelling is something that happens in two - party conversations . Mm - hmm . And if you ask someone a question , you essentially initiating a little two - party conversation . Yeah . Well , actu Yeah , when we looked at this {disfmarker} Exactly . So then you 're {disfmarker} so and then you 're expected to backchannel because the person is addressing you directly and not everybody . Exactly . Exactly my point . An - and so this is the expectation thing that {disfmarker} uh , uh , Yeah . Yeah . Mm - hmm . Right . just the dyadic {disfmarker} Right . But in addition , you know , if someone has done this analysis himself and isn't involved in the dyad , but they might also give backchannels to verify what {disfmarker} what the answer is that this {disfmarker} that the {disfmarker} the answerer 's given {disfmarker} H Right . I tell you , I say {disfmarker} I say \" uh - huh \" a lot , It 's {disfmarker} There you go . Well , but it 's interesting cuz , uh {disfmarker} while people are talking to each other . But there are fewer {disfmarker} I think there are fewer \" uh - huhs \" . There you go . Yeah . Yeah . I mean , just from {disfmarker} We were looking at word frequency lists to try to find the cases that we would allow to have the reject words in between in doing the alignment . You know the ones we wouldn't constrain to be next to the other words . Oh , yeah . And \" uh - huh \" is not as frequent as it sort of would be in Switchboard , if you looked at just a word frequency list of one - word short utterances . And \" yeah \" is way up there , but not \" uh - huh \" . And so I was thinking thi it 's not like {pause} you 're being encouraged by everybody else to keep {pause} talking in the meeting . And uh , that 's all , I I 'll stop there , cuz I I think what you say makes a lot of sense . Well , that 's right . And that would {disfmarker} But it was sort of {disfmarker} Well , an And what you say is the {disfmarker} is the re uh , o other side of this , which is that , you know , so th there are lots of channels where you don't have these backchannels , w when a question has been asked and {disfmarker} and these {disfmarker} Right . There 's just probably less backchannelling in general , Mm - hmm . So that 's good news , really . even if you consider every other person altogether one person in the meeting , but we 'll find out anyway . We were {disfmarker} I guess the other thing we 're {disfmarker} we 're {disfmarker} I should say is that we 're gonna , um try {disfmarker} compare this type of overlap analysis to Switchboard , where {disfmarker} And and CallHome , where we have both sides , so that we can try to answer this question of , you know , {vocalsound} is there really more overlap in meetings or is it just because we don't have the other channel in Switchboard Mm - hmm . Mm - hmm . and we don't know what people are doing . Try to create a paper out of that . Yeah . I mean , y y you folks have probably {pause} already told me , but were {disfmarker} were you intending to do a Eurospeech submission , or {disfmarker} ? Um , you mean the one due tomorrow ? Yeah . Yeah . Well , we 're still , like , writing the scripts for doing the research , and we will {disfmarker} Yes , we 're gonna try . Mm - hmm . And I was telling Don , do not {pause} take this as an example of how people should work . Do as I say , That 's r So , {comment} we will try . don't do as I do . Yeah . It 'll probably be a little late , Well {disfmarker} but I 'm gonna try it . It is different . In previous years , Eurospeech only had the abstract due by now , not the full paper . Right . Right . And so all our timing was off . I 've given up on trying to do digits . I just don't think that what I have so far makes a Eurospeech paper . Well , I 'm no We may be in the same position , and I figured {vocalsound} we 'll try , because that 'll at least get us to the point where we have {disfmarker} We have this really nice database format that Andreas and I were working out that {disfmarker} It {disfmarker} it 's not very fancy . It 's just a ASCII line by line format , but it does give you information {disfmarker} It 's the {disfmarker} it 's the spurt format . It {disfmarker} Yeah , we 're calling these \" spurts \" after Chafe . I was trying to find what 's a word for {pause} a continuous region with {pause} pauses around it ? Hmm . Yeah . I know that th the Telecom people use {disfmarker} use \" spurt \" for that . Good . They do ? Oh ! Yes . Oh . Oh . And that 's {disfmarker} I mean , I {disfmarker} I was using that for a while when I was doing the rate of speech stuff , I would jus because I {disfmarker} because I looked up in some books and I found {disfmarker} OK , I wanna find a spurt {vocalsound} in which {disfmarker} Ah , right ! It 's just , like , defined by the acoustics . and {disfmarker} an because {disfmarker} cuz it 's another question about how {pause} many pauses they put in between them . Horrible . Right . But how fast do they do {pause} the words within the spurt ? Right . Yeah . Well , that 's what we were calling spurt , It 's gonna {disfmarker} you know \" Burst \" also ? Burst . Isn't \" burst \" is used also ? so {disfmarker} Spurt has the horrible name overloading with other {disfmarker} with hardware at ICSI . Here . Just very locally , yeah . Well , well , Chafe had this wor I think it was Chafe , or somebody had a {disfmarker} the word \" spurt \" originally , But {disfmarker} but that just {disfmarker} Here @ @ {disfmarker} and so I {disfmarker} But tha that 's good to know . Actually {disfmarker} Was thi it 's Chafe ? Well , see , I know S Sue wrote about spurts of development . So maybe we should talk {disfmarker} Maybe it was Sue {disfmarker} ? Y But , in any case , I think it 's a good term , So we have spurts and we have spurt - ify dot shell and spurt - ify Yeah . and , uh {disfmarker} Hmm ! Yeah . And ma maybe {disfmarker} maybe Chafe did . Uh . And then it 's got all {disfmarker} it 's a verb now . I know {disfmarker} I know Ch - Chafe dealt with {disfmarker} So s That 's cool . W uh , w Chafe speaks about intonation units . Yes . Right . But maybe he speaks about spurts as well We and I just don't know . Yeah , go ahead . I 've heard \" burst \" also . So what we 're doing {disfmarker} uh , this {disfmarker} this is just {disfmarker} maybe someone has s some {disfmarker} some ideas about how to do it better , Mmm . but we {disfmarker} So we 're taking these , uh , alignments from the individual channels . We 're {disfmarker} from each alignment we 're producing , uh , one of these CTM files , Great . which essentially has {disfmarker} it 's just a linear sequence of words with the begin times for every word and the duration . It looks like a Waves label file almost . Right ? And {disfmarker} and {disfmarker} and of course {disfmarker} It 's just {disfmarker} Right . But it has {disfmarker} one {disfmarker} the first column has the meeting name , so it could actually contain several meetings . Um . And the second column is the channel . Third column is the , um , start times of the words and the fourth column is the duration of the words . And then we 're , um {disfmarker} OK . Then we have a messy alignment process where we actually insert into the sequence of words the , uh , tags for , like , where {disfmarker} where sentence {disfmarker} ends of sentence , question marks , um , {vocalsound} various other things . Yeah . These are things that we had Don {disfmarker} Uh . So , Don sort of , um , propagated the punctuation from the original transcriber {disfmarker} Right . so whether it was , like , question mark or period or , {vocalsound} um , you know , comma and things like that , and we kept the {disfmarker} and disfluency dashes {disfmarker} uh , kept those in because we sort of wanna know where those are relative to the spurt overlaps {disfmarker} Mm - hmm . Right . sp overlaps , So {disfmarker} so those are actually sort of retro - fitted into the time alignment . or {disfmarker} And then we merge all the alignments from the various channels and we sort them by time . And then there 's a {disfmarker} then there 's a process where you now determine the spurts . That is {disfmarker} Actually , no , you do that before you merge the various channels . So you {disfmarker} you id identify by some criterion , which is pause length {disfmarker} you identify the beginnings and ends of these spurts , and you put another set of tags in there to keep those straight . Mm - hmm . And then you merge everything in terms of , you know , linearizing the sequence based on the time marks . And then {vocalsound} you extract the individual channels again , but this time you know where the other people start and end talking {disfmarker} you know , where their spurts start and end . And so you extract the individual channels , uh , one sp spurt by spurt as it were . Um , and inside the words or between the words you now have begin and end {pause} tags for overlaps . So , you {disfmarker} you basically have everything sort of lined up and in a form where you can look at the individual speakers and how their speech relates to the other speakers ' speech . Right . Uh , I mean , I think that 's actually really u useful also And {disfmarker} because even if you weren't studying overlaps , if you wanna get a transcription for the far - field mikes , how are you gonna know which words from which speakers occurred at which times relative to each other ? You have to be able to {pause} get a transcript like {disfmarker} like this anyway , just for doing far - field recognition . So , you know , it 's {disfmarker} it 's sort of {disfmarker} Yeah . I thi it 's just an issue we haven't dealt with before , how you time - align things that are overlapping anyway . That 's wonderful . So {disfmarker} I mean , i I never thought about it before , Well {disfmarker} And {disfmarker} and we {disfmarker} but {disfmarker} Y yes . In {disfmarker} I mean , s when I came up with the original data {disfmarker} suggested data format based on the transcription graph , there 's capability of doing that sort of thing in there . Right . But you can't get it directly from the transcription . Mm - hmm . Yeah , that 's right . Right . Well , this is {disfmarker} this is just {disfmarker} Yeah , this is like a poor man 's ver formatting version . But it 's , you know {disfmarker} It 's clean , it 's just not fancy . Right . Um . Well , there 's lots of little things . It 's like there 're twelve different scripts which you run and then at the end you have what you want . But , um , at the very last stage we throw away the actual time information . All we care about is whether {disfmarker} that there 's a certain word was overlapped by someone else 's word . So you sort of {disfmarker} at that point , you discretize things into just having overlap or no overlap . Because we figure that 's about the level of analysis that we want to do for this paper . Mm - hmm . But if you wanted to do a more fine - grained analysis and say , you know , how far into the word is the overlap , you could do that . Yeah . It 's just {disfmarker} it 'll just require more {disfmarker} Just {pause} sort of huge . you know , slightly different {disfmarker} What 's interesting is it 's exactly what , um , i in discussing with , um , Sue about this , Yeah . um , she , um , i i i indicated that that {disfmarker} you know , that 's very important for overlap analysis . Yeah . It 's {disfmarker} it 's nice to know , Right . and also I think as a human , like , I don't always hear these in the actual order that they occur . So I can have two foreground speakers , you know , Morgan an and {vocalsound} um , Adam and Jane could all be talking , and I could align each of them to be starting their utterance at the correct time , and then look where they are relative to each other , and that 's not really what I heard . And that 's another thing she said . Cuz it 's just hard to do . This is {disfmarker} This is Bever 's {disfmarker} Bever 's effect , Y Yeah . when {disfmarker} where {disfmarker} In psy ps psycho - linguistics you have these experiments where people have perceptual biases a as to what they hear , It 's sort of {disfmarker} Yeah , you sort of move things around until you get to a {pause} low information point that {disfmarker} that {disfmarker} Not the best {disfmarker} and yo then you can bring in the other person . So it 's {vocalsound} actually not even possible , I think , for any person to listen to a mixed signal , even equalize , and make sure that they have all the words in the right order . So , I guess , we 'll try to write this Eurospeech paper . Mm - hmm . Superb . I mean , we will write it . Whether they accept it {pause} late or not , I don't know . Um , and the good thing is that we have {disfmarker} It 's sort of a beginning of what Don can use to link the prosodic features from each file to each other . Yeah . Yeah . That 's the good thing about these pape So . i You know , might as well . Plus , mayb Hmm ? We - I ju Otherwise we won't get the work done {comment} {vocalsound} on our deadline . I don't know , m Yeah . I mean , u u Jane likes to look at data . Maybe , you know , you could {disfmarker} you could look at this format and see if you find anything interesting . Yeah . I don't know . Yeah . No , it 's {disfmarker} that 's the good thing about these pape paper deadlines and , uh , you know , class projects , and {disfmarker} {vocalsound} and things like that , Well , what I 'm thinking is {disfmarker} Yeah . Yeah . Right . Mm - hmm . Well , my {disfmarker} Well th th the other thing that {disfmarker} that {disfmarker} that yo that you usually don't tell your graduate students is that these deadlines are actually not that , um , you know , strictly enforced , because you {disfmarker} you really get g Forces you to do the work . Yeah . Yeah . Exactly . Strict . because {pause} the {disfmarker} Oh , now it 's out in the public , this {disfmarker} this {disfmarker} this secret information . because {disfmarker} Right . Yeah . I think we can ha bec b {vocalsound} Nah {disfmarker} So {disfmarker} No . No . Nah . i Because these {disfmarker} the conference organizers actually have an interest in getting lots of submissions . Right . Right . I mean , a {disfmarker} a monetary interest . Yeah . So {disfmarker} {vocalsound} Um . Th - that 's {disfmarker} that 's true . And good ones , good ones , which sometimes means {pause} a little extra time . And good submission That 's {disfmarker} Right . That 's true . Well {disfmarker} That 's another issue , By th by the way , this is totally unfair , you may {disfmarker} you may feel , but {disfmarker} but the {disfmarker} the , uh {disfmarker} the morning meeting folks actually have an {disfmarker} an extra month or so . Mm - hmm . Yep . Yep . The Aurora {disfmarker} there 's a special Aurora {disfmarker} Uh {disfmarker} When {disfmarker} There 's a special Aurora session Oh . and the Aurora pe people involved in Aurora have till Ma - uh , early May {pause} or something to turn in their paper . Mmm . Oh . Mmm . Oh , well maybe we 'll submit to s {comment} {vocalsound} Actually {disfmarker} Well , then you can just {disfmarker} Maybe you can submit the digits paper on e for the Aurora session . Yeah . Yeah . Yeah . Oh , I could ! Yeah . I if it w I could submit that to Aurora . Well {disfmarker} That would be pretty {disfmarker} pretty {disfmarker} Yeah . i it has {disfmarker} Yeah .  S That wouldn't work . No , it wouldn't work . It 's not Aurora . It 's {disfmarker} it 's not the Aurora {disfmarker} I mean , it {disfmarker} it 's {disfmarker} it 's actually the Aurora task . Maybe they 'll get s Aurora 's very specific . It Well , maybe it won't be after this {vocalsound} deadline {pause} extension . But {disfmarker} but the people {disfmarker} I mean , a {disfmarker} a paper that is not on Aurora would probably be more interesting at that point Maybe they 'll {disfmarker} because everybody 's so sick and tired of the Aurora task . Yeah . Oh , I thought you meant this was just the digits section . I didn't know you meant it was Aurora digits . Yeah . Well , no . If you {disfmarker} if you have {disfmarker} it 's to {disfmarker} if you discuss some relation to the Aurora task , like if you use the same {disfmarker} This is not the Aurora task . So they just do a little grep for {disfmarker} Do {disfmarker} uh , d d Do not {disfmarker} do not {disfmarker} we are not setting a good example . Um . Well , a relation other than negation , maybe , This is not a {disfmarker} um . So . Anyway . I don't know . But the good thing is this does {disfmarker} Well , I I don't know . I mean , you could {disfmarker} you could do a paper on {pause} what 's wrong with the Aurora task by comparing it to {pause} other ways of doing it . How well does an Aurora system do on {disfmarker} on {disfmarker} you know , on digits collected in a {disfmarker} in this environment ?  Different way . Yeah . Yeah . Maybe . Maybe . Pretty hokey . I think it 's a littl little far - fetched . Nah , I mean , the thing is Aurora 's pretty closed community . Yep . I mean , you know , the people who were involved in the {disfmarker} {vocalsound} the only people who are allowed to test on that are people who {disfmarker} who made it above a certain threshold in the first round , Mm - hmm . It 's very specific . uh {vocalsound} w in ninety - nine and it 's {disfmarker} it 's sort of a {disfmarker} it 's {disfmarker} not like a {disfmarker} Well , that 's maybe why they don't f know that they have a crummy system . I mean , a crummy back - end . No , I mean {disfmarker} I mean , seriously , if you {disfmarker} if you have a very {disfmarker} No , I 'm sorry . Uh , {comment} \" beep \" {vocalsound} \" bee \" I mean , th No . I didn't mean anybody {disfmarker} any particular system . I meant this H T K back - end . Oh , you don't like HTK ? If they {disfmarker} Yeah . I don't h I don't have any stock in HTK or Entropic or anything . No . I mean , this {disfmarker} it it 's the HTK {pause} that is trained on a very limited amount of data . It 's d it 's very specific . Right . Yeah . But so , if you {disfmarker} But maybe you should , you know , consider more {disfmarker} using more data , or {disfmarker} I mean {disfmarker} Oh , yeah . I {disfmarker} I really think that that 's true . And they i i If yo if you sort of hermetically stay within one task and don't look left and right , then you 're gonna {disfmarker} But they {disfmarker} they had {disfmarker} i But {disfmarker} They had something very specific in mind when they designed it . Right ? Well , u i Right . And so {disfmarker} so you can {disfmarker} you can argue about maybe that wasn't the right thing to do , but , you know , they {disfmarker} they {disfmarker} they had something specific . But , one of the reasons I have Chuck 's messing around with {disfmarker} with the back - end that you 're not supposed to touch {disfmarker} I mean , for the evaluations , yes , we 'll run a version that hasn't been touched . Mm - hmm . Mm - hmm . But , uh , one of the reasons I have him messing around with that , because I think it 's sort of an open question that we don't know the answer to . People always say very glibly {vocalsound} that i if you s show improvement on a bad system , that doesn't mean anything , cuz it may not be {disfmarker} {vocalsound} show {disfmarker} uh , because , you know , it doesn't tell you anything about the good system . Mm - hmm . And I {disfmarker} I 've always sort of felt that that depends . You know , that if some peopl If you 're actually are getting at something that has some {pause} conceptual substance to it , it will port . Mm - hmm . And in fact , most methods that people now use were originally tried with something that was not their absolute {pause} best system at some level . But of course , sometimes it doesn't , uh , port . So I think that 's {disfmarker} that 's an interesting question . If we 're getting {pause} three percent error on , uh , u uh , English , uh , nati native speakers , {vocalsound} um , using the Aurora system , and we do some improvements and bring it from three to two , {vocalsound} do those same improvements bring , uh , th you know , the SRI system from one point three to {disfmarker} you know , to {vocalsound} point eight ? Hmm . Mm - hmm . Zero . Well . You know , so that 's {disfmarker} that 's something we can test . Mmm . Right . So . Anyway . OK . I think we 've {disfmarker} {vocalsound} we 've covered that one up extremely well . Mm - hmm . Whew ! OK . So , um {disfmarker} Yeah . So tha so we 'll {disfmarker} you know , maybe you guys 'll have {disfmarker} have one . Uh , you {disfmarker} you and , uh {disfmarker} and Dan have {disfmarker} have a paper that {disfmarker} that 's going in . Yeah . You know , that 's {disfmarker} that 's pretty solid , on the segmentation {pause} stuff . Yeah . Yeah . I will send you the {disfmarker} the final version , Yeah . And the Aurora folks here will {disfmarker} will definitely get something in on Aurora , which is not {disfmarker} Actually this {disfmarker} this , um {disfmarker} So , there 's another paper . so . It 's a Eurospeech paper but not related to meetings . But it 's on digits . So , um , uh , a colleague at SRI developed a improved version of MMIE training . Uh - huh . And he tested it mostly on digits because it 's sort of a {disfmarker} you know , it doesn't take weeks to train it . Right . Um . And got some very impressive results , um , with , you know , discriminative , uh , Gaussian training . Um , you know , like , um , error rates {pause} go from {disfmarker} I don't know , in very noisy environment , like from , uh , uh {disfmarker} I for now I {disfmarker} OK , now I have the order of magnit I 'm not sure about the order of magnitude . Was it like from ten percent to {vocalsound} eight percent or from e e you know , point {disfmarker} you know , from one percent to point eight percent ? H i it got {disfmarker} it got better . I mean , it 's a {disfmarker} Yeah , yeah . Yeah . It got better . That 's the important thing . Hey , that 's the same percent relative , Yeah . But it 's {disfmarker} so {disfmarker} Yeah . Right . Yeah . It 's , uh , something in {disfmarker} Yeah . Twenty percent relative gain . Right . Yeah . Yeah . Yeah . Um , {vocalsound} let 's see . I think the only thing we had left was {disfmarker} unless somebody else {disfmarker} Well , there 's a couple things . Uh , one is {pause} anything that , um , {vocalsound} anybody has to say about Saturday ? Anything we should do in prep for Saturday ? Um {disfmarker} I guess everybody knows about {disfmarker} I mean , u um , Mari was asking {disfmarker} was trying to come up with something like an agenda and we 're sort of fitting around people 's times a bit . But , um , {vocalsound} clearly when we actually get here we 'll {pause} move things around this , as we need to , but {disfmarker} so you can't absolutely count on it . OK . But {disfmarker} but , uh {disfmarker} Yeah . Are we meeting in here probably or {disfmarker} ? OK . Yeah . That was my thought . Yeah . I think this is {disfmarker} Are we recording it ? We won't have enough microphones ,  but {disfmarker} u No . I {disfmarker} I hadn't in intended to . There 's no way . We won we wanna {disfmarker} I mean , they 're {disfmarker} there 's gonna be , uh , Jeff , Katrin , Mari and two students . OK . So there 's five {pause} from there . And Brian . And Brian 's coming , But you know th so that 's six . And plus all of us . Mm - hmm . Uh {disfmarker} Can use the Oprah mike . Depends how fast you can {pause} throw it . It seems like too many {disfmarker} too much coming and going . It 's just {disfmarker} Yeah . Mm - hmm . We don't even have enough channel {disfmarker} Well {disfmarker} Because it would be a different kind of meeting , Yeah . that 's what I 'm {disfmarker} Well {disfmarker} But {disfmarker} Yeah . I hadn't {pause} really thought of it , Maybe just {disfmarker} maybe not the whole day but {disfmarker} but just , you know , maybe some {disfmarker} I mean , Maybe part of it . part of it ? Maybe part of it . Make everyone read digits . At the same time . At the same time . At the same time . Please .  Yeah . We c I don't know . That 's their initiation into our Any w Into our {disfmarker} our {disfmarker} our cult . Yeah , our {disfmarker} Yeah , our {disfmarker} Maybe the sections that are not right afte you know , after lunch when everybody 's still munching and {disfmarker} So can you send out a schedule once you know it , jus ? OK . Well {disfmarker} Is {disfmarker} is there a r ? OK . Yeah . I guess I sent it around a little bit . There 's a res Is it changed now , or {disfmarker} ? But {disfmarker} I hadn't heard back from Mari after I {disfmarker} I u u uh , brought up the point abou about Andreas 's schedule . So , {vocalsound} um , maybe when I get back there 'll be {pause} some {disfmarker} some mail from her . OK . So , I 'll make a {disfmarker} I 'm looking forward to seeing your representation . That 'd be , uh {disfmarker} And w we should get {pause} the two meetings from y I 'd like to see that . Yeah . I mean , I know about the first meeting , um , but the other one that you did , the NSA one , which we {pause} hadn't done cuz we weren't running recognition on it , because the non - native speaker {disfmarker} Mm - hmm . there were five non - native speakers . Mm - hmm . I see . Mm - hmm . But , it would be useful for the {disfmarker} to see what we get {pause} with that one . So . Great . OK . It 's , uh , two thousand eleven twenty - one one thousand . Yeah , three . Right . So {disfmarker} Great . I sent email when I finished the {disfmarker} that one . N S A three , I think . That was sort of son Yeah , that 's right . That 's right . That 's much simpler . I don't know what they said but I know the number . Th - that part 's definitely gonna confuse somebody who looks at these later . Right . I mean , this is {disfmarker} we we 're recording secret NSA meetings ? Um . Not the {disfmarker} I mean , it 's {disfmarker} Yeah . Yeah . Not that NSA . Uh . The {disfmarker} th the {disfmarker} They are hard to understand . It 's network services and applications . Wait . They 're very , uh , out there . The {disfmarker} I have no idea what they 're talking about . Yeah . The , um {disfmarker} th the other good thing about the alignments is that , um , it 's not always the machine 's fault if it doesn't work . So , you can actually find , um , It 's the person 's fault . problem {disfmarker} uh , proble It 's Morgan 's fault . You can find {disfmarker} It 's always Morgan 's fault . You can find , uh , problems with {disfmarker} with the transcripts , um , you know , Oh . Yeah . and go back and fix them . Tha - There are some cases like where the {disfmarker} the wrong speaker {disfmarker} uh , these ca Not a lot , but where the {disfmarker} the wrong person {disfmarker} the {disfmarker} the speech is addre attached to the wrong speaker But {disfmarker} and you can tell that when you run it . Or at least you can get {pause} clues to it . Interesting . So these are from the early transcriptions that people did on the mixed signals , like what you have . I guess it does w Mm - hmm . It also raises the possibility of , um , using that kind of representation {disfmarker} I mean , I don't know , this 'd be something we 'd wanna check , {comment} but maybe using that representation for data entry and then displaying it on the channelized , uh , representation , cuz it {disfmarker} I think that the {disfmarker} I mean , my {disfmarker} my preference in terms of , like , looking at the data is to see it {pause} in this kind of musical score format . Mm - hmm . And also , s you know , Sue 's preference as well . Yeah , if you can get it to {disfmarker} And {disfmarker} and {disfmarker} but , I mean , this {disfmarker} if this is a better interface for making these kinds of , uh , you know , lo clos local changes , then that 'd be fine , too . I don't {disfmarker} I have no idea . I think this is something that would need to be checked . Yeah . OK . Th - the other thing I had actually was , I {disfmarker} I didn't realize this till today , but , uh , this is , uh , Jose 's last day . Yeah . Is my last {disfmarker} my last day . Oh ! Oh . Oh ! You 're not gonna be here tomorrow ? My {disfmarker} {vocalsound} my last meeting {pause} about meetings . Oh , that 's right . Tomorrow {disfmarker} Yeah . The last meeting meeting ? Because , eh , I leave , eh , the next Sunday . It 's off . Oh . Mm - hmm . I will come back to home {disfmarker} to Spain . Yeah . Oh . I d so I {disfmarker} I jus Mm - hmm . And I {disfmarker} I would like to {disfmarker} to {disfmarker} to say thank you very much , eh , to all people {pause} in the group and at ICSI , Mm - hmm . Yeah . It was good having you . Mmm . Yeah . because I {disfmarker} I enjoyed @ @ very much , Mmm . uh . And I 'm sorry by the result of overlapping , because , eh , {vocalsound} I haven't good results , eh , yet but , eh , {vocalsound} I {disfmarker} {vocalsound} I pretend {comment} to {disfmarker} to continuing out to Spain , eh , during the {disfmarker} the following months , Uh - huh . eh , because I have , eh , another ideas but , eh , I haven't enough time to {disfmarker} to {disfmarker} {vocalsound} with six months it 's not enough to {disfmarker} {vocalsound} to {disfmarker} to research , Yep . Yeah . eh , and e i I mean , if , eh , the topic is , eh , so difficult , uh , in my opinion , there isn't {disfmarker} Yeah . Maybe somebody else will come along and will be , uh , interested in working on it and could start off from where you are also , you know . They 'd make use of {disfmarker} of what you 've done . Yeah . Yeah . Yeah . But , eh , I {disfmarker} I will try to recommend , eh , at , eh , {vocalsound} the Spanish government but , eh , the following @ @ scholarship , eh , eh , {vocalsound} eh , will be here {pause} more time , because eh , i in my opinion is {disfmarker} is better , {vocalsound} eh , for us {pause} to {disfmarker} to spend more time here and to work more time i i in a topic . Yeah , it 's a very short time . No ? But , uh {disfmarker} Yeah . Yeah . Yeah , six months is hard . Yeah . It is . I think a year is a lot better . Yeah . Yeah . It 's difficult . You {disfmarker} e you have , eh {disfmarker} you are lucky , and you {disfmarker} you find a solution {comment} in {disfmarker} in {disfmarker} in some few tim uh , months , eh ? OK . But , eh , I think it 's not , eh , common . But , eh , anyway , thank you . Thank you very much . Eh , I {disfmarker} I bring the chocolate , eh , to {disfmarker} {vocalsound} {vocalsound} to tear , uh , with {disfmarker} with you , Oh . Ah . Mmm . Nice . uh . I {disfmarker} I hope if you need , eh , something , eh , from us in the future , I {disfmarker} I will be at Spain , {vocalsound} to you help , uh . Well . Great . Great . Right . Thank you , Jose . Thank you . And , thank you very much . Have a good trip . Yeah . Yeah . Keep in touch . Thank you . Yeah . OK . I guess , uh , unless somebody has something else , we 'll read {disfmarker} read our digits Digits ? and we 'll get our {disfmarker} Uh . get our last bit of , uh , Jose 's {disfmarker} Jose {disfmarker} Jose 's digit {disfmarker} Oops . Are we gonna do them simultaneously or {disfmarker} ? You {disfmarker} eh {disfmarker} Uh , I 'm sorry ? Ye - ye you prefer , eh , to eat , eh , chocolate , eh , at the coffee break , eh , at the {disfmarker} ? {vocalsound} Or you prefer now , before after {disfmarker} ? Well , we have a time {disfmarker} No , we prefer to keep it for ourselves . During {disfmarker} Well , we have a s a time {disfmarker} time constraint . Yeah , yeah . during digits . So keep it away from that end of the table . Yeah . Yeah . Yeah . Why is it that I can read your mind ? Yeah . Well , we 've gotta wait until after di after we take the mikes off . No , no . So are we gonna do digits simultaneously You {disfmarker} This is our reward if we {pause} do our digi Well ? Yeah . OK . Yeah . or what ? Simultaneous digit chocolate task . I {disfmarker} I think , eh , it 's enough , eh , for more peopl for more people {pause} after . We 're gonna {disfmarker} we 're gonna do digits at the same {disfmarker} Oh . Mmm ! That 's nice . But , eh {disfmarker} Mm - hmm . Oh , thanks , Jose . Um . Wow . To Andreas , the idea is {disfmarker} is good . {vocalsound} s To eat here . Well {disfmarker} Mmm . Wow . Very nice . Oh . Oh , wow . Tha - that 's {disfmarker} that looks great . Oh , yeah . Th - it doesn't {disfmarker} it won't leave this room . Alright , so in the interest of getting to the {disfmarker} We could do digits while other people eat . Yeah . So it 's background crunching . Yeah . Yeah . Mmm . We don't have background chewing . Nice . Is , eh , a {disfmarker} another acoustic event . Background crunch . Yeah . No , we don't have any data with background eating . Mmm . Yeah . I 'm serious . You She 's {disfmarker} she 's serious . I am serious . It 's just the rest of the digits {disfmarker} the rest of the digits are very clean , She is serious . Mmm . Well {disfmarker} ? Are you {disfmarker} ? Oh , they 're clean . Yeah ! um , without a lot of background noise , And it {disfmarker} You have to write down , like , while y what you 're {disfmarker} what ch chocolate you 're eating so I 'm just not sure {disfmarker} cuz they might make different sounds , like n nuts {disfmarker} chocolate with nuts , chocolate without nuts . Oh . Um {disfmarker} Crunchy frogs . Chocolate adaptation . Actually {disfmarker} {vocalsound} actually kind of careful cuz I have a strong allergy to nuts , so I have to sort of figure out one without th That w Oh , yeah , they {disfmarker} they might . It 's hard to {disfmarker} hard to say . Maybe those ? They 're so {disfmarker} I don't know . I don't know . Um {disfmarker} This is {disfmarker} You know , this is a different kind of speech , Well {disfmarker} Take {disfmarker} take several . looking at chocolates , deciding {disfmarker} Mmm . you know , it 's another style . Yeah . I may {disfmarker} I may hold off . Mmm . But if I was {disfmarker} eh , but maybe I 'll get some later . Thanks . Mmm . Well {disfmarker} well , why don't we {disfmarker} ? He {disfmarker} he 's worried about a ticket . Why don't we do a simultaneous one ? OK . Simultaneous one ? OK . OK . Mmm . And you laughed at me , too , f the first time I said that . OK . Remember to read the transcript number , please . Right . OK . I have to what ? Oops . Yeah . You laughed at me , too , the first time I sa said {disfmarker} I did , You really shouldn't , uh , te and now I love it so much . OK , everyone ready ? You have to sort of , um {disfmarker} Jose , if you haven't done this , you have to plug your ears while you 're t talking W wait {disfmarker} wait a minute {disfmarker} wait a minute . W we want {disfmarker} we want {disfmarker} so that you don't get confused , I guess . we want it synchronized . Yeah . Oh , you 've done this one before ? Hey , you 've done this before . Haven't you ? Yeah . That 's {disfmarker} Together ? You 've read {pause} digits together with us , haven't you {disfmarker} I mean , at the same time ? I 'm not {disfmarker} we {disfmarker} we {disfmarker} Oh , and you haven't done this either . OK . Oh , you haven't ! No . Oh , OK . Oh , yeah . I the first time is {pause} traumatic , We but {disfmarker} Y {vocalsound} Yeah , bu Oh , and the groupings are important , Mmm . so yo you 're supposed to pause between the groupings . The grouping . Yeah . Yeah . OK . So , uh {disfmarker} You mean that the {disfmarker} the grouping is supposed to be synchronized ? No , no . No . Yeah , sure . No ? That 'd be good . Synchronized digits . No . No ? We - we 'll give everybody the same sheet It 's like a {disfmarker} like a Greek {disfmarker} like a Greek choir ? but they say different {disfmarker} You know ? Yes . Hey , what a good idea . Like {disfmarker} We could do the same sheet for everyone . Yeah . Have them all read them at once . Well , different digits Eh {disfmarker} but same groupings . Or {disfmarker} or just same digits . So they would all be {disfmarker} Yeah . Yeah . That 'd be good . See if anyone notices . There 's so many possibilities . And then {disfmarker} then we can sing them next time . Uh . OK , why don't we go ? Uh , one two three {disfmarker} Go ! OK . Mmm ! And Andreas has the last word . Did you read it twice or what ? He 's try No , he 's trying to get good recognition performance . He had the h Yeah . He had the {disfmarker} the long form . Yeah . And we 're off . No .",
        "summarize": "The group discussed efforts to train and test the Aurora group's HTK-based recognition system on ICSI's digits corpus. Members also discussed efforts to produce forced alignments from a selection of Meeting Recorder data. Performance in both tasks was adversely affected by the manner of recording conditions implemented and difficulties attributing utterances to the appropriate speakers. While debugging efforts resulted in improved forced alignments, dealing with mixed channel speech and speaker overlap remains a key objective for future work. The group is additionally focused on a continued ability to feed different features into the recognizer and then train the system accordingly. "
    }
]