[
    {
        "transcript": "I think for two years we were two months , uh , away from being done . And what was that , Morgan ? What project ? Uh , the , uh , TORRENT chip . Oh . Yeah . We were two {disfmarker} we were {disfmarker} Yeah . Uh , uh , we went through it {disfmarker} Jim and I went through old emails at one point and {disfmarker} and for two years there was this thing saying , yeah , we 're {disfmarker} we 're two months away from being done . It was very {disfmarker} very believable schedules , too . I mean , we went through and {disfmarker} with the schedules {disfmarker} and we {disfmarker} It was true for two years . Yeah . Oh , yeah . It was very true . So , should we just do the same kind of deal where we {pause} go around and do , uh , status report {pause} kind of things ? OK . And I guess when Sunil gets here he can do his last or something . So . Yeah . So we {pause} probably should wait for him to come before we do his . Mm - hmm . OK . That 's a good idea . Yeah . OK . Yeah . Any objection ? Do y OK , M All in favor Do you want to start , Morgan ? Do you have anything , or {disfmarker} ? Uh , I don't do anything . I {disfmarker} No , I mean , I {disfmarker} I 'm involved in discussions with {disfmarker} with people about what they 're doing , but I think they 're {disfmarker} since they 're here , they can talk about it themselves . OK . So should I go so that , uh , Yeah . Why don't you go ahead , Barry ? you 're gonna talk about Aurora stuff , per se ? OK . OK . Um . Well , this past week I 've just been , uh , getting down and dirty into writing my {disfmarker} my proposal . So , um {disfmarker} Mmm . I just finished a section on , uh {disfmarker} on talking about these intermediate categories that I want to classify , um , as a {disfmarker} as a middle step . And , um , I hope to {disfmarker} hope to get this , um {disfmarker} a full rough draft done by , uh , Monday so I can give it to Morgan . When is your , uh , meeting ? Um , my meeting Yeah . with , uh {disfmarker} ? Oh , oh , you mean the {disfmarker} the quals . The quals . Yeah . Uh , the quals are happening in July twenty - fifth . Oh . Soon . Yeah . Uh - huh . D - Day . Yeah . Uh - huh . So , is the idea you 're going to do this paper and then you pass it out to everybody ahead of time and {disfmarker} ? Right , right . So , y you write up a proposal , and give it to people ahead of time , and you have a short presentation . And , um , and then , um {disfmarker} then everybody asks you questions . Hmm . Yeah . I remember now . Yep . So , um . Have you d ? I was just gonna ask , do you want to say any {disfmarker} a little bit about it , Y s or {disfmarker} ? Mmm . Oh . Uh , a little bit about {disfmarker} ? Wh - what you 're {disfmarker} what you 're gonna {disfmarker} You said {disfmarker} you were talking about the , uh , particular features that you were looking at , Oh , the {disfmarker} the {disfmarker} or {disfmarker} Right . Well , I was , um , I think one of the perplexing problems is , um , for a while I was thinking that I had to come up with a complete set of intermediate features {disfmarker} in intermediate categories to {disfmarker} to classify right away . But what I 'm thinking now is , I would start with {disfmarker} with a reasonable set . Something {disfmarker} something like , um , um {disfmarker} like , uh , re regular phonetic features , just to {disfmarker} just to start off that way . And do some phone recognition . Um , build a system that , uh , classifies these , um {disfmarker} these feat uh , these intermediate categories using , uh , multi - band techniques . Combine them and do phon phoneme recognition . Look at {disfmarker} then I would look at the errors produced in the phoneme recognition and say , OK , well , I could probably reduce the errors if I included this extra feature or this extra intermediate category . That would {disfmarker} that would reduce certain confusions over other confusions . And then {disfmarker} and then {vocalsound} reiterate . Um , build the intermediate classifiers . Uh , do phoneme recognition . Look at the errors . And then postulate new {disfmarker} or remove , um , intermediate categories . And then do it again . So you 're gonna use TIMIT ? Um , for that {disfmarker} for that part of the {disfmarker} the process , yeah , I would use TIMIT . Mm - hmm . And , um , then {disfmarker} after {disfmarker} after , uh , um , doing TIMIT . Right ? Mm - hmm . Um , that 's {disfmarker} {vocalsound} that 's , um {disfmarker} that 's just the ph the phone recognition task . Yeah . Uh , I wanted to take a look at , um , things that I could model within word . So , I would mov I would then shift the focus to , um , something like Schw - Switchboard , uh , where I 'd {disfmarker} I would be able to , um {disfmarker} to model , um , intermediate categories that span across phonemes , Mm - hmm . not just within the phonemes , themselves , um , and then do the same process there , um , on {disfmarker} on a large vocabulary task like Switchboard . Uh , and for that {disfmarker} for that part I would {disfmarker} I 'd use the SRI recognizer since it 's already set up for {disfmarker} for Switchboard . And I 'd run some {disfmarker} some sort of tandem - style processing with , uh , my intermediate classifiers . Oh . So that 's why you were interested in getting your own features into the SRI files . Yeah . That 's why I {disfmarker} I was asking about that . Yeah . Yeah . Yeah . Um , and I guess that 's {disfmarker} that 's it . Any {disfmarker} any questions ? Sounds good . So you just have a few more weeks , huh ? Um , yeah . A few more . It 's about a month from now ? It 's a {disfmarker} it 's a month and {disfmarker} and a week . Yeah . Yeah . So , uh , you want to go next , Dave ? And we 'll do {disfmarker} Oh . OK , sure . So , um , last week I finally got results from the SRI system about this mean subtraction approach . And , um , we {disfmarker} we got an improvement , uh , in word error rate , training on the TI - digits data set and testing on Meeting Recorder digits of , um , {vocalsound} six percent to four point five percent , um , on the n on the far - mike data using PZM F , but , um , the near - mike performance worsened , um , from one point two percent to two point four percent . And , um , wh why would that be , um , {vocalsound} considering that we actually got an improvement in near - mike performance using HTK ? And so , uh , with some input from , uh , Andreas , I have a theory in two parts . Um , first of all HTK {disfmarker} sorry , SR - the SRI system is doing channel adaptation , and so HTK wasn't . Um , so this , um {disfmarker} This mean subtraction approach will do a kind of channel {pause} normalization and so that might have given the HTK use of it a boost that wouldn't have been applied in the SRI case . And also , um , the {disfmarker} Andreas pointed out the SRI system is using more parameters . It 's got finer - grained acoustic models . So those finer - grained acoustic models could be more sensitive to the artifacts {pause} in the re - synthesized audio . Um . And me and Barry were listening to the re - synthesized audio and sometimes it seems like you get of a bit of an echo of speech in the background . And so that seems like it could be difficult for training , cuz you could have {pause} different phones {pause} lined up with a different foreground phone , {vocalsound} um , {vocalsound} depending on {pause} the timing of the echo . So , um , I 'm gonna try training on a larger data set , and then , eh , the system will have seen more examples o of these artifacts and hopefully will be more robust to them . So I 'm planning to use the Macrophone set of , um , read speech , and , um {disfmarker} Hmm . I had another thought just now , which is , uh , remember we were talking before about {disfmarker} we were talking in our meeting about , uh , this stuff that {disfmarker} some of the other stuff that Avendano did , where they were , um , getting rid of low - energy {pause} sections ? Um , uh , if you {disfmarker} if you did a high - pass filtering , as Hirsch did in {pause} late eighties to reduce some of the effects of reverberation , uh , uh , Avendano and Hermansky were arguing that , uh , perhaps one of the reasons for that working was ma may not have even been the filtering so much but the fact that when you filter a {disfmarker} an all - positive power spectrum you get some negative values , and you gotta figure out what to do with them if you 're gonna continue treating this as a power spectrum . So , what {disfmarker} what Hirsch did was , uh , set them to zero {disfmarker} set the negative values to zero . So if you imagine a {disfmarker} a waveform that 's all positive , which is the time trajectory of energy , um , and , uh , shifting it downwards , and then getting rid of the negative parts , that 's essentially throwing away the low - energy things . And it 's the low - energy parts of the speech where the reverberation is most audible . You know , you have the reverberation from higher - energy things showing up in {disfmarker} So in this case you have some artificially imposed {pause} reverberation - like thing . I mean , you 're getting rid of some of the other effects of reverberation , but because you have these non - causal windows , you 're getting these funny things coming in , uh , at n And , um , what if you did {disfmarker} ? I mean , there 's nothing to say that the {disfmarker} the processing for this re - synthesis has to be restricted to trying to get it back to the original , according to some equation . I mean , you also could , uh , just try to make it nicer . Uh - huh . And one of the things you could do is , you could do some sort of VAD - like thing Mm - hmm . and you actually could take very low - energy sections and set them to some {disfmarker} some , uh , very low or {disfmarker} or near zero {pause} value . I mean , uh , I 'm just saying if in fact it turns out that {disfmarker} that these echoes that you 're hearing are , uh {disfmarker} Uh - huh . or pre - echoes , whichever they are {disfmarker} are {disfmarker} are , uh , part of what 's causing the problem , you actually could get rid of them . Uh - huh . Be pretty simple . I mean , you do it in a pretty conservative way OK . so that if you made a mistake you were more likely to {pause} keep in an echo than to throw out speech . Hmm . Um , what is the reverberation time {pause} like {pause} there ? In thi in this room ? Uh {disfmarker} On , uh , the {disfmarker} the one what {disfmarker} the s in the speech that you are {disfmarker} you are using like ? Y Yeah . I {disfmarker} I {disfmarker} I {disfmarker} I don't know . So , it 's this room . It 's , uh {disfmarker} It 's {disfmarker} it 's this room . Oh , this room ? So {disfmarker} OK . so it 's {disfmarker} these are just microphone {disfmarker} this micro close microphone and a distant microphone , he 's doing these different tests on . Oh . Uh , we should do a measurement in here . I g think we never have . I think it 's {disfmarker} I would guess , uh , point seven , point eight seconds f uh , R T Hmm ! something like that ? But it 's {disfmarker} you know , it 's this room . Mm - hmm . So . OK . Mm - hmm . Uh . But the other thing is , he 's putting in {disfmarker} w I was using the word \" reverberation \" in two ways . He 's also putting in , uh , a {disfmarker} he 's taking out some reverberation , but he 's putting in something , because he has {pause} averages over multiple windows stretching out to twelve seconds , which are then being subtracted from the speech . And since , you know , what you subtract , sometimes you 'll be {disfmarker} you 'll be subtracting from some larger number and sometimes you won't . And {disfmarker} Mm - hmm . Mm - hmm . So you can end up with some components in it that are affected by things that are seconds away . Uh , and if it 's a low {pause} energy compo portion , you might actually hear some {pause} funny things . Yeah . O o one thing , um , I noticed is that , um , the mean subtraction seems to make the PZM signals louder after they 've been re - synthesized . So I was wondering , is it possible that one reason it helped with the Aurora baseline system is {pause} just as a kind of gain control ? Cuz some of the PZM signals sound pretty quiet if you don't amplify them . Mm - hmm . I don't see why {disfmarker} why your signal is louder after processing , because yo Yeah . I don't know why - y , uh , either . Yeah . I don't think just multiplying the signal by two would have any effect . Mm - hmm . Oh , OK . Yeah . I mean , I think if you really have louder signals , what you mean is that you have {pause} better signal - to - noise ratio . Well , well {disfmarker} So if what you 're doing is improving the signal - to - noise ratio , then it would be better . Mm - hmm . But just it being bigger if {disfmarker} with the same signal - to - noise ratio {disfmarker} It w i i it wouldn't affect things . No . Yeah . OK . Well , the system is {disfmarker} use {pause} the absolute energy , so it 's a little bit dependent on {disfmarker} on the {pause} signal level . But , not so much , I guess . Well , yeah . But it 's trained and tested on the same thing . Mmm . So if the {disfmarker} if the {disfmarker} if you change {vocalsound} in both training and test , the absolute level by a factor of two , it will n have no effect . Mm - hmm . Yeah . Did you add {pause} this data to the training set , for the Aurora ? Or you just tested on this ? Uh {disfmarker} Um . Did I w what ? Well , Morgan was just saying that , uh , as long as you do it in both training and testing , it shouldn't have any effect . Sorry ? Yeah . But I {disfmarker} I was {pause} sort of under the impression that you just tested with this data . I {disfmarker} I b You didn't {pause} train it also . I {disfmarker} Right . I trained on clean TI - digits . I {disfmarker} I did the mean subtraction on clean TI - digits . But I didn't {disfmarker} I 'm not sure if it made the clean ti TI - digits any louder . Oh , I see . I only remember noticing it made the , um , PZM signal louder . OK . Well , I don't understand then . Yeah . Huh . I don't know . If it 's {disfmarker} if it 's {disfmarker} like , if it 's trying to find a {disfmarker} a reverberation filter , it could be that this reverberation filter is making things quieter . And then if you take it out {disfmarker} that taking it out makes things louder . I mean . Uh , no . I mean , {vocalsound} uh , there 's {disfmarker} there 's nothing inherent about removing {disfmarker} if you 're really removing , Nuh - huh . uh , r uh , then I don't {pause} see how that would make it louder . The mean . OK . Yeah , I see . So it might be just some {disfmarker} Yeah . OK . So I should maybe listen to that stuff again . Yeah . It might just be some artifact of the processing that {disfmarker} that , uh , if you 're {disfmarker} Uh , yeah . I don't know . Oh . OK . I wonder if there could be something like , uh {disfmarker} for s for the PZM data , Eh uh , you know , if occasionally , uh , somebody hits the table or something , you could get a spike . Uh . I 'm just wondering if there 's something about the , um {disfmarker} you know , doing the mean normalization where , uh , it {disfmarker} it could cause {pause} you to have better signal - to - noise ratio . Um . Well , you know , there is this . Wait a minute . It {disfmarker} it {disfmarker} i maybe {disfmarker} i If , um {disfmarker} Subtracting the {disfmarker} the mean log spectrum is {disfmarker} is {disfmarker} is like dividing by the spectrum . So , depending what you divide by , if your {disfmarker} if s your estimate is off and sometimes you 're {disfmarker} you 're {disfmarker} you 're getting a small number , you could make it bigger . Mm - hmm . Mm - hmm . So , it 's {disfmarker} it 's just a {disfmarker} a question of {disfmarker} there 's {disfmarker} It {disfmarker} it could be that there 's some normalization that 's missing , or something to make it {disfmarker} Mm - hmm . Uh , y you 'd think it shouldn't be larger , but maybe in practice it is . That 's something to think about . Hmm . I don't know . I had a question about the system {disfmarker} the SRI system . So , {vocalsound} you trained it on TI - digits ? But except this , it 's exactly the same system as the one that was tested before and that was trained on {pause} Macrophone . Right ? So on TI - digits it gives you one point two percent error rate and on Macrophone it 's still O point eight . Uh , but is it {pause} exactly the same system ? Uh . I think so . Hmm . If you 're talking about the Macrophone results that Andreas had about , um , a week and a half ago , I think it 's the same system . Mm - hmm . So you use VTL - uh , vocal tract length normalization and , um , like MLLR transformations also , Mm - hmm . and {disfmarker} I 'm sorry , was his point eight percent , er , a {disfmarker} a result on testing on Macrophone or {disfmarker} or training ? all that stuff . That 's {disfmarker} It was {pause} training on Macrophone and testing {disfmarker} yeah , on {disfmarker} on meeting digits . Oh . So that was done already . So we were {disfmarker} Uh , and it 's point eight ? OK . Mm - hmm . OK . Yeah . I {disfmarker} I 've just been text {comment} testing the new {pause} Aurora front - end with {disfmarker} well , Aurora system actually {disfmarker} so front - end and HTK , um , acoustic models on the meeting digits and it 's a little bit better than the previous system . We have {disfmarker} I have two point seven percent error rate . And before with the system that was proposed , it 's what ? It was three point nine . So . Oh , that 's a lot better . We are getting better . So , what {disfmarker} w ? And {disfmarker} With the {disfmarker} with the HTK back - end ? What we have for Aurora ? Yeah . Two point seven . I know in the meeting , like {disfmarker} On the meeting we have two point seven . Right . Oh . That 's with the new IIR filters ? Uh . Yeah , yeah . So , yeah , OK . we have {pause} the new LDA filters , and {disfmarker} I think , maybe {disfmarker} I didn't look , but one thing that makes a difference is this DC offset compensation . Uh , eh {disfmarker} Do y did you have a look at {disfmarker} at the meet uh , meeting digits , if they have a DC component , or {disfmarker} ? I {disfmarker} I didn't . No . Oh . Hmm . No . The DC component could be negligible . I mean , if you are {pause} recording it through a mike . I mean , any {disfmarker} all of the mikes have the DC removal {disfmarker} some capacitor sitting right in {pause} that bias it . Yeah . But this {disfmarker} uh , uh , uh , no . Because , uh , there 's a sample and hold in the A - toD. And these period these typically do have a DC offset . Oh , OK . And {disfmarker} and they can be surprisingly large . It depends on the electronics . Oh , so it is the digital {disfmarker} OK . It 's the A - toD that introduces the DC in . Yeah . The microphone isn't gonna pass any DC . Yeah . Yeah . Yeah . But {disfmarker} but , OK . typi you know , unless {disfmarker} Actually , there are {pause} instrumentation mikes that {disfmarker} that do pass {disfmarker} go down to DC . But {disfmarker} but , Mm - hmm . uh , no , it 's the electronics . And they {disfmarker} and {disfmarker} Mm - hmm . then there 's amplification afterwards . And you can get , I think it was {disfmarker} I think it was in the {pause} Wall Street Journal data that {disfmarker} that {disfmarker} I can't remember , one of the DARPA things . There was this big DC - DC offset Mm - hmm . we didn't {disfmarker} we didn't know about for a while , while we were {pause} messing with it . And we were getting these terrible results . And then we were talking to somebody and they said , \" Oh , yeah . Didn't you know ? Everybody knows that . There 's all this DC offset in th \" So , yes . You can have DC offset in the data . Oh , OK . Yeah . OK . So was that {disfmarker} was that everything , Dave ? Oh . And I also , um , did some experiments {pause} about normalizing the phase . Um . So I c I came up with a web page that people can take a look at . And , um , the interesting thing that I tried was , um , Adam and Morgan had this idea , um , since my original attempts to , um , take the mean of the phase spectra over time and normalize using that , by subtracting that off , didn't work . Um , so , well , that we thought that might be due to , um , problems with , um , the arithmetic of phases . They {disfmarker} they add in this modulo two pi way and , um , there 's reason to believe that that approach of taking the mean of the phase spectrum wasn't really {pause} mathematically correct . So , {vocalsound} what I did instead is I {vocalsound} took the mean of the FFT spectrum without taking the log or anything , and then I took the phase of that , and I subtracted that phase {pause} off to normalize . But that , um , didn't work either . See , we have a different interpretation of this . He says it doesn't work . I said , I think it works magnificently , but just not for the task we intended . Uh , it gets rid of the speech . What does it leave ? Uh , gets rid of the speech . Uh , it leaves {disfmarker} you know , it leaves the junk . I mean , I {disfmarker} I think it 's {disfmarker} it 's tremendous . Oh , wow . You see , all he has to do is go back and reverse what he did before , and he 's really got something . Well , could you take what was left over and then subtract that ? Ex - exactly . Yeah , you got it . Yeah . Yeah . So , it 's {disfmarker} it 's a general rule . Oh , it 's {disfmarker} Just listen very carefully to what I say and do the opposite . Including what I just said . And , yeah , that 's everything . All set ? Do you want to go , Stephane ? Um . Yeah . Maybe , concerning these d still , these meeting digits . I 'm more interested in trying to figure out what 's still the difference between the SRI system and the Aurora system . And {disfmarker} Um . Yeah . So , I think I will maybe train , like , gender - dependent models , because {pause} this is also one big difference between {pause} the two systems . Um , the other differences were {pause} the fact that maybe the acoustic models of the SRI are more {disfmarker} SRI system are more complex . But , uh , Chuck , you did some experiments with this and It didn't seem to help in the HTK system . it was hard t to {disfmarker} to have some exper some improvement with this . Um . Well , it sounds like they also have {disfmarker} he {disfmarker} he 's saying they have all these , uh , uh , different kinds of adaptation . Mm - hmm . You know , they have channel adaptation . They have speaker adaptation . Yeah . Right . Well , there 's also the normalization . Yeah . Yeah . Yeah . Yeah . Like they do , um {disfmarker} I 'm not sure how they would do it when they 're working with the digits , The vocal tr but , like , in the Switchboard data , there 's , um {disfmarker} conversation - side normalization for the {pause} non - C - zero components , Yeah . Yeah . This is another difference . Their normalization works like on {disfmarker} on the utterance levels . Mm - hmm . But we have to do it {disfmarker} We have a system that does it on - line . Right . So , it might be {disfmarker} it might be better with {disfmarker} it might be worse if the {pause} channel is constant , Yeah . or {disfmarker} Nnn . And the acoustic models are like - k triphone models or {disfmarker} or is it the whole word ? SRI {disfmarker} it 's {disfmarker} it 's tr SRI . Yeah . Yeah . I guess it 's triphones . It 's triphone . I think it 's probably more than that . Huh . I mean , so they {disfmarker} they have {disfmarker} I {disfmarker} I thin think they use these , uh , uh , genone things . So there 's {disfmarker} there 's these kind of , uh , uh , pooled models and {disfmarker} and they can go out to all sorts of dependencies . Oh . It 's like the tied state . So . Mm - hmm . They have tied states and I think {disfmarker} I {disfmarker} I {disfmarker} I don't real I 'm talk I 'm just guessing here . But I think {disfmarker} I think they {disfmarker} they don't just have triphones . OK . I think they have a range of {disfmarker} of , uh , dependencies . Mm - hmm . Mm - hmm . Mm - hmm . Hmm . And {disfmarker} Yeah . Well . Um . Well , the first thing I {disfmarker} that I want to do is just maybe these gender things . Uh . And maybe see with {pause} Andreas if {disfmarker} Well , I {disfmarker} I don't know {pause} how much it helps , what 's the model . So {disfmarker} so the n stuff on the numbers you got , the two point seven , is that using the same training data that the SRI system used and got one point two ? That 's right . So it 's the clean {pause} TI - digits training set . So exact same training data ? Right . OK . Mm - hmm . I guess you used the clean training set . Right . Mm - hmm . For {disfmarker} with the SRI system {disfmarker} Well . You know , the {disfmarker} the Aurora baseline is set up with these , um {disfmarker} {vocalsound} this version of the clean training set that 's been filtered with this G - seven - one - two filter , and , um , to train the SRI system on digits S - Andreas used the original TI - digits , um , under U doctor - speech data TI - digits , which don't have this filter . But I don't think there 's any other difference . Mm - hmm . Mm - hmm . Yeah . So is that {disfmarker} ? Uh , are {disfmarker} are these results comparable ? So you {disfmarker} you were getting with the , uh , Aurora baseline something like two point four percent {pause} on clean TI - digits , when , uh , training the SRI system with clean TR digits {disfmarker} {comment} TI - digits . Right ? And {disfmarker} Um . Uh - huh . Yeah . And , so , is your two point seven comparable , where you 're , uh , uh , using , uh , the submitted system ? Yeah . I think so . OK . Yeah . So it 's {pause} about the same , Mm - hmm . maybe a little worse . W w it was one {disfmarker} one point two Ye with the SRI system , I 'm sorry . Yeah . I {disfmarker} The complete SRI system is one point two . You {disfmarker} you were HTK . Yeah . Right ? OK . That 's right . So {disfmarker} Mm - hmm . OK , so {pause} the comparable number then , uh {pause} for what you were talking about then , since it was HTK , would be the {pause} um , two point f It was four point something . Right ? The HTK system with , uh , b D d Oh , right , right , right , right . MFCC features {disfmarker} Do you mean the b ? The baseline Aurora - two system , trained on TI - digits , tested on Meeting Recorder near , I think we saw in it today , and it was about six point six percent . Right . Right , right , right . Oh . OK . Alright . So {disfmarker} He 's doing some {pause} different things . So {disfmarker} Yeah . The only difference is the features , right now , between this and {disfmarker} Yes . OK , good . So they are helping . Mm - hmm . That 's good to hear . Yeah . They are helping . Yeah . Um . Yeah . And another thing I {disfmarker} I maybe would like to do is to {pause} just test the SRI system that 's trained on Macrophone {disfmarker} test it on , uh , the noisy TI - digits , Yeah . cuz I 'm still wondering {pause} where this {pause} improvement comes from . When you train on Macrophone , it seems better on meeting digits . But I wonder if it 's just because maybe {pause} Macrophone is acoustically closer to the meeting digits than {disfmarker} than TI - digit is , which is {disfmarker} TI - digits are very {pause} clean recorded digits Mm - hmm . and {disfmarker} You know , it would also be interesting to see , uh {disfmarker} to do the regular Aurora test , Uh , f s um , but use the SRI system instead of HTK . That 's {disfmarker} Yeah . That 's what {pause} I wanted , just , uh {disfmarker} Yeah . So , just using the SRI system , test it on {disfmarker} and test it on {pause} Aurora TI - digits . Right . Why not the full Aurora , uh , test ? Um . Yeah . There is this problem of multilinguality yet . Mm - hmm . So we don't {disfmarker} You 'd have to train the SRI system with {disfmarker} with all the different languages . i i Right . We would have to train on {disfmarker} Yeah . That 's what I mean . Yeah . So , like , comple It 'd be a {pause} lot of work . That 's the only thing . Yeah . Mmm . It 's {disfmarker} Well , I mean , Mmm . uh , uh , I guess the work would be into getting the {disfmarker} the files in the right formats , or something . Right ? I mean {disfmarker} Mm - hmm . Because when you train up the Aurora system , you 're , uh {disfmarker} you 're also training on all the data . That 's right . I mean , it 's {disfmarker} Yeah . Yeah . I see . Oh , so , OK . Right . I see what you mean . That 's true , but I think that also when we 've had these meetings week after week , oftentimes people have not done the full arrange of things Mm - hmm . because {disfmarker} on {disfmarker} on whatever it is they 're trying , because it 's a lot of work , even just with the HTK . Mm - hmm . So , it 's {disfmarker} it 's a good idea , but it seems like {pause} it makes sense to do some pruning Mm - hmm . first with a {disfmarker} a test or two that makes sense for you , Yeah . and then {pause} take the likely candidates and go further . Yeah . Mm - hmm . Yeah . But , just testing on TI - digits would already give us some information {pause} about what 's going on . And {disfmarker} mm - hmm . Uh , yeah . OK . Uh , the next thing is this {disfmarker} this VAD problem that , um , um {disfmarker} So , I 'm just talking about the {disfmarker} the curves that I {disfmarker} I sent {disfmarker} {vocalsound} I sent you {disfmarker} so , whi that shows that {vocalsound} when the SNR decrease , {vocalsound} uh , the current {pause} VAD approach doesn't drop much frames {pause} for some particular noises , uh , which might be then noises that are closer to speech , uh , acoustically . I i Just to clarify something for me . I They were supp Supposedly , in the next evaluation , they 're going to be supplying us with boundaries . Mm - hmm . So does any of this matter ? I mean , other than our interest in it . Uh {disfmarker} Uh {disfmarker} Well . First of all , the boundaries might be , uh {disfmarker} like we would have t two hundred milliseconds or {disfmarker} before and after speech . Uh . So removing more than that might still make {pause} a difference {pause} in the results . Do we {disfmarker} ? I mean , is there some reason that we think that 's the case ? And {disfmarker} No . Because we don't {disfmarker} didn't looked {pause} that much at that . Yeah . But , {vocalsound} still , I think it 's an interesting problem . Oh , yeah . And {disfmarker} Um . Yeah . But maybe we 'll get some insight on that when {disfmarker} when , uh , the gang gets back from Crete . Because {pause} there 's lots of interesting problems , of course . Mm - hmm . And then the thing is if {disfmarker} if they really are going to have some means of giving us {pause} fairly tight , uh , boundaries , then that won't be so much the issue . Yeah , yeah . Mm - hmm . Mm - hmm . Um But {vocalsound} I don't know . Because w we were wondering whether that {pause} VAD is going to be , like , a realistic one or is it going to be some manual segmentation . And then , like , if {disfmarker} if that VAD is going to be a realistic one , then we can actually use their markers to shift the point around , I mean , the way we want Mm - hmm . to find a {disfmarker} I mean , rather than keeping the twenty frames , we can actually move the marker to a point which we find more {pause} suitable for us . Right . But if that is going to be something like a manual , uh , segmenter , then we can't {pause} use that information anymore , Mm - hmm . because that 's not going to be the one that is used in the final evaluation . Right . So . We don't know what is the type of {pause} {vocalsound} {pause} VAD which they 're going to provide . Yeah . Yeah . And actually there 's {disfmarker} Yeah . There 's an {disfmarker} uh , I think it 's still for {disfmarker} even for the evaluation , uh , it might still be interesting to {vocalsound} work on this because {pause} the boundaries apparently that they would provide is just , {vocalsound} um , starting of speech and end of speech {pause} uh , at the utterance level . And {disfmarker} Um . With some {disfmarker} some gap . So {disfmarker} I mean , with some pauses in the center , provided they meet that {disfmarker} whatever the hang - over time which they are talking . Yeah . But when you have like , uh , five or six frames , both {disfmarker} Yeah . Then the they will just fill {disfmarker} fill it up . it {disfmarker} it {disfmarker} with {disfmarker} I mean , th {disfmarker} Yeah . Yeah . So if you could get at some of that , uh {disfmarker} So {disfmarker} although that 'd be hard . Yeah . It might be useful for , like , noise estimation , and a lot of other {pause} things that we want to work on . But {disfmarker} but {disfmarker} Yeah . Yeah . Right . OK . But {disfmarker} Mmm . Yeah . So I did {disfmarker} I just {pause} started to test {pause} putting together two VAD which was {disfmarker} was not much work actually . Um , I im re - implemented a VAD that 's very close to the , {vocalsound} um , energy - based VAD {vocalsound} that , uh , the other Aurora guys use . Um . So , which is just putting a threshold on {pause} the noise energy , Mm - hmm . and , detect detecting the first {pause} group of four frames {pause} that have a energy that 's above this threshold , and , uh , from this point , uh , tagging the frames there as speech . So it removes {vocalsound} the first silent portion {disfmarker} portion of each utterance . And it really removes it , um , still o on the noises where {pause} our MLP VAD doesn't {pause} work a lot . Mmm . Uh , Cuz I would have thought that having some kind of spectral {pause} information , and {disfmarker} uh {disfmarker} uh , you know , in the old days people would use energy and zero crossings , for instance {disfmarker} uh , would give you some {pause} better performance . Right ? Cuz you might have low - energy fricatives or {disfmarker} or , uh {pause} stop consonants , or something like that . Mm - hmm . Uh . Yeah . So , your point is {disfmarker} will be to u use whatever {disfmarker} Oh , that if you d if you use purely energy and don't look at anything spectral , then you don't have a good way of distinguishing between low - energy speech components and {pause} nonspeech . And , um , Mm - hmm . just as a gross generalization , most nonsp many nonspeech noises have a low - pass kind of characteristic , some sort of slope . And {disfmarker} and most , um , low - energy speech components that are unvoiced have a {disfmarker} a high - pass kind of characteristic {disfmarker} Mm - hmm . an upward slope . So having some kind of a {disfmarker} Yeah . uh , you know , at the beginning of a {disfmarker} of a {disfmarker} of an S sound for instance , just starting in , it might be pretty low - energy , Mm - hmm . but it will tend to have this high - frequency component . Whereas , {vocalsound} a {disfmarker} a lot of rumble , and background noises , and so forth will be predominantly low - frequency . Uh , you know , by itself it 's not enough to tell you , but it plus energy is sort of {disfmarker} Yeah . it plus energy plus timing information is sort of {disfmarker} Mm - hmm . I mean , if you look up in Rabiner and Schafer from like twenty - five years ago or something , that 's sort of {pause} what they were using then . Mm - hmm . So it 's {disfmarker} it 's not a {disfmarker} Mm - hmm . Hmm . So , yeah . It {disfmarker} it might be that what I did is {disfmarker} so , removes like {vocalsound} low , um , {vocalsound} uh {disfmarker} low - energy , uh , speech frames . Because {pause} the way I do it is I just {disfmarker} I just combine the two decisions {disfmarker} so , the one from the MLP and the one from the energy - based {disfmarker} with the {disfmarker} with the and {pause} operator . So , I only {pause} keep the frames where the two agree {pause} that it 's speech . So if the energy - based dropped {disfmarker} dropped low - energy speech , mmm , they {disfmarker} they are {disfmarker} they are lost . Mmm . Mm - hmm . But s still , the way it 's done right now it {disfmarker} it helps on {disfmarker} on the noises where {disfmarker} it seems to help on the noises where {vocalsound} our VAD was not very {pause} good . Well , I guess {disfmarker} I mean , one could imagine combining them in different ways . But {disfmarker} but , I guess what you 're saying is that the {disfmarker} the MLP - based one has the spectral information . So . Yeah . But {disfmarker} Yeah . But the way it 's combined wi is maybe done {disfmarker} Well , yeah . Well , you can imagine {disfmarker} The way I use a an a \" AND \" operator is {disfmarker} So , it {disfmarker} I , uh {disfmarker} Is {disfmarker} ? The frames that are dropped by the energy - based system are {disfmarker} are , uh , dropped , even if the , um , MLP decides to keep them . Right . Right . And that might not be optimal , But , yeah . but {disfmarker} Mm - hmm . No but {disfmarker} I mean , I guess in principle what you 'd want to do is have a {disfmarker} {vocalsound} uh , a probability estimated by each one and {disfmarker} and put them together . Yeah . Mmm . M Yeah . Something that {disfmarker} that I 've used in the past is , um {disfmarker} when just looking at the energy , is to look at the derivative . And you {pause} make your decision when the derivative is increasing for {pause} so many frames . Then you say that 's beginning of speech . Uh - huh . But , I 'm {disfmarker} I 'm trying to remember if that requires that you keep some amount of speech in a buffer . I guess it depends on how you do it . But {pause} I mean , that 's {disfmarker} that 's been a useful thing . Yeah . Mm - hmm . Mm - hmm . Yeah . Well , every everywhere has a delay associated with it . I mean , you still have to k always keep a buffer , Mm - hmm . then only make a decision because {pause} you still need to smooth the {pause} decision further . Right . Right . So that 's always there . Yeah . OK . Well , actually if I don't {disfmarker} maybe don't want to work too much of {disfmarker} on it right now . I just wanted to {disfmarker} to see if it 's {disfmarker} {vocalsound} what I observed was the re was caused by this {disfmarker} this VAD problem . Mm - hmm . And it seems to be the case . Um . Uh , the second thing is the {disfmarker} this spectral subtraction . Um . Um , which I 've just started yesterday to launch a bunch of , uh , {nonvocalsound} twenty - five experiments , uh , with different , uh , values for the parameters that are used . So , it 's the Makhoul - type spectral subtraction which use {pause} an over - estimation factor . So , we substr I subtract more , {vocalsound} {vocalsound} um , {nonvocalsound} {vocalsound} noise than the noise spectra that {pause} is estimated {pause} on the noise portion of the s uh , the utterances . So I tried several , uh , over - estimation factors . And after subtraction , I also add {pause} a constant noise , and I also try different , uh , {vocalsound} noise , uh , values and we 'll see what happen . Hmm . OK . Mm - hmm . Mm - hmm . But st still when we look at the , um {disfmarker} Well , it depends on the parameters that you use , but for moderate over - estimation factors and moderate noise level that you add , you st have a lot of musical noise . Um . On the other hand , when you {pause} subtract more and when you add more noise , you get rid of this musical noise but {pause} maybe you distort a lot of speech . So . Well . Mmm . Well , it {disfmarker} until now , it doesn't seem to help . But We 'll see . So the next thing , maybe I {disfmarker} what I will {pause} try to {disfmarker} to do is just {pause} to try to smooth mmm , {vocalsound} the , um {disfmarker} to smooth the d the result of the subtraction , to get rid of the musical noise , using some kind of filter , or {disfmarker} Can smooth the SNR estimate , also . Yeah . Right . Mmm . Your filter is a function of SNR . Hmm ? Yeah . So , to get something that 's {disfmarker} would be closer to {pause} what you tried to do with Wiener filtering . Yeah . And {disfmarker} Mm - hmm . Yeah . Actually , it 's , uh {disfmarker} Uh . I don't know , it 's {disfmarker} go ahead . It {disfmarker} And it 's {disfmarker} Maybe you can {disfmarker} go ahead . I think it 's {disfmarker} That 's it for me . OK . So , uh {disfmarker} u th I 've been playing with this Wiener filter , like . And there are {disfmarker} there were some bugs in the program , so I was p initially trying to clear them up . Because one of the bug was {disfmarker} I was assuming that always the VAD {disfmarker} uh , the initial frames were silence . It always started in the silence state , but it wasn't for some utterances . So the {disfmarker} it wasn't estimating the noise initially , and then it never estimated , because I assumed that it was always silence . Mm - hmm . So this is on SpeechDat - Car Italian ? Yeah . So , in some cases s there are also {disfmarker} SpeechDat - Car Italian . Yeah . There 're a few cases , actually , which I found later , that there are . o Uh - huh . So that was one of the {pause} bugs that was there in estimating the noise . And , uh , so once it was cleared , uh , I ran a few experiments with {pause} different ways of smoothing the estimated clean speech and how t estimated the noise and , eh , smoothing the SNR also . And so the {disfmarker} the trend seems to be like , {vocalsound} uh , smoothing the {pause} current estimate of the clean speech for deriving the SNR , which is like {pause} deriving the Wiener filter , seems to be helping . Then updating it quite fast using a very small time constant . So we 'll have , like , a few results where the {disfmarker} estimating the {disfmarker} the {disfmarker} More smoothing is helping . But still it 's like {disfmarker} it 's still comparable to the baseline . I haven't got anything beyond the baseline . But that 's , like , not using any Wiener filter . And , uh , so I 'm {disfmarker} I 'm trying a few more experiments with different time constants for smoothing the noise spectrum , and smoothing the clean speech , and smoothing SNR . So there are three time constants that I have . So , I 'm just playing around . So , one is fixed in the line , like {pause} Smoothing the clean speech is {disfmarker} is helping , so I 'm not going to change it that much . But , the way I 'm estimating the noise and the way I 'm estimating the SNR , I 'm just trying {disfmarker} trying a little bit . So , that h And the other thing is , like , putting a floor on the , uh , SNR , because that {disfmarker} if some {disfmarker} In some cases the clean speech is , like {disfmarker} when it 's estimated , it goes to very low values , so the SNR is , like , very low . And so that actually creates a lot of variance in the low - energy region of the speech . So , I 'm thinking of , like , putting a floor also for the SNR so that it doesn't {pause} vary a lot in the low - energy regions . And , uh . So . The results are , like {disfmarker} So far I 've been testing only with the {pause} baseline , which is {disfmarker} which doesn't have any LDA filtering and on - line normalization . I just want to separate the {disfmarker} the contributions out . So it 's just VAD , plus the Wiener filter , plus the baseline system , which is , uh , just the spectral {disfmarker} I mean , the mel sp mel , uh , frequency coefficients . Um . And the other thing that I tried was {disfmarker} but I just {vocalsound} took of those , uh , {pause} {vocalsound} Carlos filters , which Hynek had , to see whether it really h helps or not . I mean , it was just a {disfmarker} a run to see whether it really degrades or it helps . And it 's {disfmarker} it seems to be like it 's not {vocalsound} hurting a lot by just blindly picking up one filter which is nothing but a {pause} four hertz {disfmarker} a band - pass m m filter on the cubic root of the power spectrum . So , that was the filter that Hy - uh , Carlos had . And so {disfmarker} Yeah . Just {disfmarker} just to see whether it really {disfmarker} it 's {disfmarker} it 's {disfmarker} is it worth trying or not . So , it doesn't seems to be degrading a lot on that . So there must be something that I can {disfmarker} that can be done with that type of noise compensation also , which {disfmarker} {vocalsound} I guess I would ask Carlos about that . I mean , how {disfmarker} how he derived those filters and {disfmarker} and where d if he has any filters which are derived on OGI stories , added with some type of noise which {disfmarker} what we are using currently , or something like that . So maybe I 'll {disfmarker} This is cubic root of power spectra ? Yeah . Cubic root of power spectrum . So , if you have this band - pass filter , you probably get n you get negative values . Right ? Yeah . And I 'm , like , floating it to z zeros right now . OK . So it has , like {disfmarker} the spectrogram has , like {disfmarker} Uh , it actually , uh , enhances the onset and offset of {disfmarker} I mean , the {disfmarker} the begin and the end of the speech . So it 's {disfmarker} there seems to be , like , deep valleys in the begin and the end of , like , high - energy regions , Mm - hmm . because the filter has , like , a sort of Mexican - hat type structure . Mm - hmm . So , those are the regions where there are , like {disfmarker} when I look at the spectrogram , there are those deep valleys on the begin and the end of the speech . But the rest of it seems to be , like , pretty nice . Mm - hmm . So . That 's {pause} something I observe using that filter . And {disfmarker} Yeah . There are a few {disfmarker} very {disfmarker} not a lot of {disfmarker} because the filter doesn't have a {disfmarker} really a deep negative portion , so that it 's not really creating a lot of negative values in the cubic root . So , I 'll {disfmarker} I 'll s may continue with that for some w I 'll {disfmarker} I 'll {disfmarker} Maybe I 'll ask Carlos a little more about how to play with those filters , and {disfmarker} but while {pause} making this Wiener filter better . So . Yeah . That {disfmarker} that 's it , Morgan . Uh , last week you were also talking about building up the subspace {pause} stuff ? Yeah . I {disfmarker} I {disfmarker} I would actually m m didn't get enough time to work on the subspace last week . It was mostly about {pause} finding those bugs and OK . th you know , things , and I didn't work much on that . How about you , Carmen ? Well , I am still working with , eh , VTS . And , one of the things that last week , eh , say here is that maybe the problem was with the diff because the signal have different level of energy . Hmm ? And , maybe , talking with Stephane and with Sunil , we decide that maybe it was interesting to {disfmarker} to apply on - line normalization before applying VTS . But then {vocalsound} we decided that that 's {disfmarker} it doesn't work absolutely , because we modified also the noise . And {disfmarker} Well , thinking about that , we {disfmarker} we then {disfmarker} we decide that maybe is a good idea . We don't know . I don't hav I don't {disfmarker} this is {disfmarker} I didn't {pause} do the experiment yet {disfmarker} to apply VTS in cepstral domain . The other thing {pause} is {disfmarker} So {disfmarker} so , in {disfmarker} i i and {disfmarker} Not {disfmarker} and C - zero would be a different {disfmarker} So you could do a different normalization for C - zero than for other things anyway . I mean , the other thing I was gonna suggest is that you could have {pause} two kinds of normalization with {disfmarker} with , uh , different time constants . So , uh , you could do some normalization {vocalsound} s uh , before the VTS , and then do some other normalization after . I don't know . But {disfmarker} but C - zero certainly acts differently than the others do , Uh . so that 's {disfmarker} Mm - hmm . Well , we s decide to m to {disfmarker} to obtain the new expression if we work in the cepstral domain . And {disfmarker} Well . I am working in that now , Uh - huh . but {vocalsound} I 'm not sure if that will be usefu useful . I don't know . It 's k it 's k It 's quite a lot {disfmarker} It 's a lot of work . Uh - huh . Well , it 's not too much , but this {disfmarker} it 's work . Yeah . And I want to know if {disfmarker} if we have some {pause} feeling that {pause} the result {disfmarker} I {disfmarker} I would like to know if {disfmarker} I don't have any feeling if this will work better than apply VTS aft in cepstral domain will work better than apply in m mel {disfmarker} in filter bank domain . I r I 'm not sure . I don't {disfmarker} I don't know absolutely nothing . Mm - hmm . Yeah . Well , you 're {disfmarker} I think you 're the first one here to work with VTS , so , uh , maybe we could call someone else up who has , ask them their opinion . Uh , Mm - hmm . I don't {disfmarker} I don't have a good feeling for it . Um . Pratibha . Actually , the VTS that you tested before was in the log domain and so {pause} the codebook is e e kind of dependent on the {pause} level of the speech signal . Yeah ? And {disfmarker} So I expect it {disfmarker} If {disfmarker} if you have something that 's independent of this , I expect it to {disfmarker} it {disfmarker} to , uh , be a better model of speech . To have better {disfmarker} And . Well . You {disfmarker} you wouldn't even need to switch to cepstra . Right ? I mean , you can just sort of normalize the {disfmarker} No . We could normali norm I mean , remove the median . Yeah . Yeah . And then you have {pause} one number which is very dependent on the level cuz it is the level , Mm - hmm . and the other which isn't . Mm - hmm . Yeah . But here also we would have to be careful about removing the mean {pause} of speech and not of noise . Ye Because it 's like {pause} first doing general normalization Yea and then noise removal , which is {disfmarker} Yeah . We {disfmarker} I was thinking to {disfmarker} to {disfmarker} to estimate the noise {pause} with the first frames and then apply the VAD , Mm - hmm . Mm - hmm . before the on - line normalization . Mm - hmm . We {disfmarker} we see {disfmarker} Well , I am thinking {vocalsound} about that and working about that , Yeah . but I don't have result this week . Sure . I mean , one of the things we 've talked about {disfmarker} maybe it might be star time to start thinking about pretty soon , is as we look at the pros and cons of these different methods , how do they fit in with one another ? Because {pause} we 've talked about potentially doing some combination of a couple of them . Maybe {disfmarker} maybe pretty soon we 'll have some sense of what their {pause} characteristics are , Mm - hmm . so we can see what should be combined . Mm - hmm . Is that it ? OK ? OK . Why don't we read some digits ? Yep . Want to go ahead , Morgan ? Sure . Transcript L dash two one five . O K .",
        "summarize": "The meeting began with a discussion on the TORRENT project completion being pushed for two years. Grad F then introduced intermediate categorization, which was his topic for his qualification exams. The team then discussed mean subtraction from SRI. Using it had led to an improvement in Meeting Recorder digits though near mic performance worsened. The professor points to pre-echoes as the culprit. The team continued to study differences between SRI and Aurora. The team thought it would be interesting to do the Aurora tests with the SRI system instead of the HTK. The team was also exploring the Wiener filter and VTS. The professor did not seem too excited about the VTS."
    }
]