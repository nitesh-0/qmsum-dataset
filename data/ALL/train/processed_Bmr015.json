[
    {
        "transcript": "OK . OK we 're on and we seem to be working . Yes . OK . We didn't crash {disfmarker} we 're not crashing anymore One , two , three , four , f and it really bothers me . Yeah ? No crashing . I do . I crashed when I started this morning . You crashed {disfmarker} crashed this morning ? I did not crash this morning . Yeah ? Oh ! Well maybe it 's just , you know , how many t u u u u how many times you crash in a day . Really ? Yeah . Maybe , yeah . First time {disfmarker} first time in the day , you know . Or maybe it 's once you 've {pause} done enough meetings {comment} it won't crash on you anymore . Yeah . No ? Yeah . It 's a matter of experience . Yeah . Yeah . Self - learning , yeah . That 's {disfmarker} that 's great . Yeah . Uh . Yeah . Do we have an agenda ? Liz {disfmarker} Liz and Andreas can't sh can't {disfmarker} uh , can't come . I do . So , they won't be here . I have agenda and it 's all me . Did {disfmarker} Cuz no one sent me anything else . Did they send , uh , the messages to you about the meeting today ? I have no idea but I just got it a few minutes ago . Oh . Right when you were in my office it arrived . Oh . OK , cuz I checked my mail . I didn't have anything . So , does anyone have any a agenda items other than me ? I actually have one more also which is to talk about the digits . Uh , right , so {disfmarker} so I {disfmarker} I was just gonna talk briefly about the NSF ITR . Mm - hmm . Yeah . Oh , great . Uh , and then , you have {disfmarker} Can w I mean , I won't say much , but {disfmarker} {comment} uh , but then , uh , you said {disfmarker} wanna talk about digits ? I have a short thing about digits and then uh I wanna talk a little bit about naming conventions , although it 's unclear whether this is the right place to talk about it . So maybe just talk about it very briefly and take the details to the people who {disfmarker} for whom it 's relevant . Right . Yeah . I could always say something about transcription . I 've been {disfmarker} {vocalsound} but {disfmarker} but {disfmarker} uh , well {disfmarker} Well if we {disfmarker} Yeah , we shouldn't add things in just to add things in . I 'm actually pretty busy today , Yeah . so if we can {disfmarker} {comment} {vocalsound} we {disfmarker} Yeah , yeah , yeah . a short meeting would be fine . This does sound like we 're doing fine , yeah . That won't do . So the only thing I wanna say about digits is , we are pretty much done with the first test set . There are probably forms here and there that are marked as having been read that weren't really read . So I won't really know until I go through all the transcriber forms and extract out pieces that are in error . So I wa Uh . Two things . The first is what should we do about digits that were misread ? My opinion is , um , we should just throw them out completely , and have them read again by someone else . You know , the grouping is completely random , Uh - huh . so it {disfmarker} it 's perfectly fine to put a {disfmarker} a group together again of errors and have them re - read , just to finish out the test set . Oh ! By {disfmarker} throw them out completely ? Um , the other thing you could do is change the transcript to match what they really said . So those are {disfmarker} those are the two options . Yeah . Mm - hmm . But there 's often things where people do false starts . I know I 've done it , where I say {disfmarker} say a {disfmarker} What the transcribers did with that is if they did a correction , and they eventually did read the right string , {comment} you extract the right string . Oh , you 're talking about where they completely read the wrong string and didn't correct it ? Yeah . Yeah . And didn't notice . Which happens in a few places . Yeah . Ah . Yeah . So {disfmarker} so {disfmarker} Well , and s and you 're talking string - wise , you 're not talking about the entire page ? Correct . Yeah . I get it . And so the {disfmarker} the two options are change the transcript to match what they really said , but then {disfmarker} but then the transcript isn't the Aurora test set anymore . I don't think that really matters because the conditions are so different . And that would be a little easier . Well how many are {disfmarker} how {disfmarker} how often does that happen ? Mmm , five or six times . Oh , so it 's not very much . No , it 's not much at all . Seems like we should just change the transcripts Yeah . OK . to match . Yeah , it 's five or six times out of {pause} thousands ? Yeah . Four thousand . Four thousand ? Four thous Ah ! Four thousand . Yeah , it 's {disfmarker} Yeah , I would , uh , {vocalsound} tak do the easy way , Yeah . yeah . OK . Yeah . It {disfmarker} it 's kinda nice {disfmarker} I mean , wh who knows what studies people will be doing on {disfmarker} on speaker - dependent things Mmm . and so I think having {disfmarker} having it all {disfmarker} Yeah . the speakers who we had is {disfmarker} is at least interesting . So you {disfmarker} um , how many digits have been transcribed now ? Four thousand lines . And each line is between one and about ten digits . Four thousand lines ? I didn't {disfmarker} I didn't compute the average . I think the average was around four or five . So that 's a couple hours of {disfmarker} of , uh , speech , probably . Wow . Yep . Yep . Which is a yeah reasonable {disfmarker} reasonable test set . Mm - hmm . Mm - hmm . And , Jane , I do have a set of forms which I think you have copies of somewhere . Mm - hmm . Yeah , true . Oh you do ? Oh OK , good , good . Mm - hmm . Mm - hmm . Yeah , I was just wond I thought I had {disfmarker} had all of them back from you . And then the other thing is that , uh , the forms in front of us here that we 're gonna read later , were suggested by Liz No , not yet . because she wanted to elicit some different prosodics from digits . And so , uh , I just wanted people to , take a quick look at the instructions Mm - hmm .  Eight eight two two two nine . and the way it wa worked and see if it makes sense and if anyone has any comments on it . I see . And the decision here , uh , was to continue with uh the words rather than the {disfmarker} the numerics . Uh , yes , although we could switch it back . The problem was O and zero . Although we could switch it back and tell them always to say \" zero \" or always to say \" O \" . Oh {disfmarker} Or neither . Yeah . But it 's just two thing {disfmarker} ways that you can say it . Mm - hmm . Right ? Sure . Oh . Um {disfmarker} um , Yeah . that 's the only thought I have because if you t start talking about these , you know u tr She 's trying to get at natural groupings , but it {disfmarker} there 's {disfmarker} there 's nothing natural about reading numbers this way . Right . I mean if you saw a telephone number you would never see it this way . The {disfmarker} the problem also is she did want to stick with digits . I mean I 'm speaking for her since she 's not here . Yeah . But , um , the other problem we were thinking about is if you just put the numerals , {comment} they might say forty - three instead of four three . Yeah . Mmm . Yeah . Yeah . Yeah . Well , if there 's space , though , between them . I mean , you can {disfmarker} With {disfmarker} when you space them out they don't look like , uh , forty - three anymore . Yeah . Well , she and I were talking about it , Yeah . and she felt that it 's very , very natural to do that sort of chunking . She 's right . It 's {disfmarker} it {disfmarker} it 's a different problem . I mean it 's a {disfmarker} it 's a {disfmarker} it 's an interesting problem {disfmarker} I mean , we 've done stuff with numbers before , and yeah sometimes people {disfmarker} If you say s \" three nine eight one \" sometimes people will say \" thirty - nine eighty - one \" or \" three hundred {disfmarker} three hundred eighty - nine one \" , or {disfmarker} I don't think they 'd say that , Yeah . but {disfmarker} but th Not very frequently no {disfmarker} but , {vocalsound} they certainly could . But {disfmarker} Yeah . Uh , th thirty - eight ninety - one is probably how they 'd do it . So . I mean , this is something that Liz and I spoke about But {disfmarker} I see . and , since this was something that Liz asked for specifically , I think we need to defer to her . Mm - hmm . Yeah . OK . Well , we 're probably gonna be collecting meetings for a while and if we decide we still wanna do some digits later we might be able to do some different ver different versions , Do something different , but this is the next suggestion , yeah . so . OK . OK , so uh e l I guess , let me , uh , get my {disfmarker} my short thing out about the NSF . I sent this {disfmarker} actually this is maybe a little side thing . Um , I {disfmarker} I sent to what I thought we had , uh , in some previous mail , as the right joint thing to send to , which was \" M {disfmarker} MTG RCDR hyphen joint \" . It was . Joint . Yep . But then I got some sort of funny mail saying that the moderator was going to {disfmarker} It 's {disfmarker} That 's because they set the one up at UW {disfmarker}  that 's not on our side , that 's on the U - dub {comment} side . Oh . And so U - UW set it up as a moderated list . Yeah . Oh , OK . And , I have no idea whether it actually ever goes to anyone so you might just wanna mail to Mari No {disfmarker} no , th I got {disfmarker} I got , uh , little excited notes from Mari and Jeff and so on , and {disfmarker} so it 's {disfmarker} OK , good . Yeah . So the moderator actually did repost it . Yeah . Cuz I had sent one earlier {disfmarker} Actually the same thing happened to me {disfmarker} I had sent one earlier . The message says , \" You 'll be informed \" and then I was never informed but I got replies from people indicating that they had gotten it , so . Right . It 's just to prevent spam . I see . Yeah so O {disfmarker} OK . Well , anyway , I guess {disfmarker} everybody here {disfmarker} Are y are {disfmarker} you are on that list , right ? So you got the note ? Mm - hmm . Yeah ? OK . Yeah . Um , so this was , uh , a , uh , proposal that we put in before on {disfmarker} on more {disfmarker} more higher level , uh , issues in meetings , from {disfmarker} I guess higher level from my point of view . Uh , {vocalsound} and , uh , meeting mappings , and , uh {disfmarker} so is i for {disfmarker} it was a {vocalsound} proposal for the ITR program , uh , Information Technology Research program 's part of National Science Foundation . It 's the {pause} second year of their doing , uh , these grants . They 're {disfmarker} they 're {disfmarker} a lot of them are {disfmarker} some of them anyway , are larger {disfmarker} larger grants than the usual , small NSF grants , and . So , they 're very competitive , and they have a first phase where you put in pre - proposals , and we {disfmarker} we , uh , got through that . And so th the {disfmarker} the next phase will be {disfmarker} we 'll actually be doing a larger proposal . And I 'm {disfmarker} I {disfmarker} I hope to be doing very little of it . And {disfmarker} uh , {vocalsound} which was also true for the pre - proposal , so . Uh , there 'll be bunch of people working on it . So . When 's {disfmarker} when 's the full proposal due ? Uh , I think April ninth , or something . So it 's about a month . p s Um {disfmarker} Yep . And they said end of business day you could check on the reviewer forms , u is that {disfmarker} Tomorrow . Tomorrow . March second , I said . Tomorrow ? I 've been a day off all week . Tomorrow . Yeah . I guess that 's a good thing cuz that way I got my papers done early . It would be interesting {disfmarker} So that 's amazing you showed up at this meeting ! It is . It is actually quite amazing . Yeah . It 'll be interesting to see the reviewer 's comments . Yeah . Yeah . My favorite is was when {disfmarker} when {disfmarker} when one reviewer says , uh , \" you know , this should be far more detailed \" , and the nex the next reviewer says , \" you know , there 's way too much detail \" . Yep . Or \" this is way too general \" , and the other reviewer says , \" this is way too specific \" . Yeah . Yeah . Yeah . Yeah . \" This is way too hard \" , \" way too easy \" . We 'll see . Maybe there 'll be something useful . And {disfmarker} and , uh {disfmarker} Well it sounded like they {disfmarker} they {disfmarker} the first gate was pretty easy . Is that right ? That they didn't reject a lot of the pre - proposals ? Do you know anything about the numbers ? No . Just {disfmarker} just th It 's just from his message it sounded like that . Yeah . Yeah . I said something , yeah . Gary Strong 's {disfmarker} I there was a sentence at the end of one of his paragraphs Yeah . I {disfmarker} I should go back and look . I didn't {disfmarker} I don't think that 's true . Yeah , OK . Mmm . He said the next phase 'll be very , competitive Very {disfmarker} very , because we didn't want to weed out much in the first phase . yeah . Yeah . Well we 'll have to see what the numbers are . Or something like that , Mm - hmm . so . Hmm . Yeah . But they {disfmarker} they have to weed out enough so that they have enough reviewers . Right . Yeah . So , uh , you know , maybe they didn't r weed out as much as usual , but it 's {disfmarker} it 's usually a pretty {disfmarker} But it {disfmarker} Yeah . It 's {disfmarker} it 's certainly not {disfmarker} I 'm sure that it 's not down to one in two or something of what 's left . Right . I 'm sure it 's , you know {disfmarker} How {disfmarker} how many awards are there , do you know ? Well there 's different numbers of w awards for different size {disfmarker} They have three size grants . This one there 's , um {disfmarker} See the small ones are less than five hundred thousand total over three years and that they have a fair number of them . Um , and the large ones are , uh , boy , I forget , I think , more than , uh , more than a million and a half , more than two million or something like that . And {disfmarker} and we 're in the middle {disfmarker} middle category . Mm - hmm . I think we 're , uh , uh , I forget what it was . But , um {disfmarker} Uh , I don't remember , but it 's {pause} pr probably along the li I {disfmarker} I could be wrong on this yeah , but probably along the lines of fifteen or {disfmarker} that they 'll fund , or twenty . I mean when they {disfmarker} Do you {disfmarker} do you know how many they funded when they f in {disfmarker} in Chuck 's , that he got last year ? I don't {disfmarker} I don't know . Yeah . I thought it was smaller , that it was like four or five , wasn't it ? Well they fund {disfmarker} I {disfmarker} I 'm {disfmarker} they {disfmarker} I don't remember . yeah . I mean {disfmarker} Uh it doesn't matter , we 'll find out one way or another . Yeah . I mean last time I think they just had two categories , small and big , Mm - hmm . and this time they came up with a middle one , so it 'll {disfmarker} there 'll be more of them that they fund than {disfmarker} of the big . If we end up getting this , um , what will it mean to ICSI in terms of , w wh where will the money go to , what would we be doing with it ? Uh . Exactly what we say in the proposal . I {disfmarker} I mean uh which part is ICSI though . You know , it {disfmarker} i None of it will go for those yachts that we 've talking about . I mean {disfmarker} Dang ! Um , well , no , I mean it 's {disfmarker} u It {disfmarker} It 's just for the research {disfmarker} to continue the research on the Meeting Recorder stuff ? It 's extending the research , right ? Because the other {disfmarker} Yeah . Yeah it 's go higher level stuff than we 've been talking about for Meeting Recorder . Yeah . Yeah the other things that we have , uh , been working on with , uh , the c with Communicator {disfmarker} uh , especially with the newer things {disfmarker} with the more acoustically - oriented things are {disfmarker} are {disfmarker} are {disfmarker} are lower level . And , this is dealing with , uh , mapping on the level of {disfmarker} of , um , the conversation {disfmarker} of mapping the conversations Mm - hmm . Right , right . to different kind of planes . So . Um . But , um . So it 's all it 's all stuff that none none of us are doing right now , or none of us are funded for , so it 's {disfmarker} so it 's {disfmarker} it would be new . So assuming everybody 's completely busy now , it means we 're gonna hafta , hire more students , or , something ? Well there 's evenings , and there 's weekends , and {disfmarker} Uh . Yeah , there {disfmarker} there would be {disfmarker} there would be new hires , and {disfmarker} and there {disfmarker} there would be expansion , but , also , there 's always {disfmarker} {vocalsound} for everybody there 's {disfmarker} there 's always things that are dropping off , grants that are ending , or other things that are ending , so , Right . there 's {disfmarker} there 's a {vocalsound} continual need to {disfmarker} to bring in new things . Mm - hmm . Yep . Right . But {disfmarker} but there definitely would be new {disfmarker} new {disfmarker} new , uh , students , I see . and so forth , both at {disfmarker} at UW and here . Are there any students in your class who are {vocalsound} expressing interest ? Um , not {pause} clear yet . Not clear yet . Other than the one who 's already here . I mean we got {vocalsound} {disfmarker} we have {disfmarker} yeah , two of them are {disfmarker} two in the c There 're {pause} two in the class already here , and then {disfmarker} and {disfmarker} and , uh {disfmarker} uh , then there 's a third who 's doing a project here , who , uh {disfmarker} But he {disfmarker} he {disfmarker} he won't be in the country that long , Mm - hmm . and , maybe another will end up . Yep . Actually there is one other guy who 's looking {disfmarker} that {disfmarker} that 's that guy , uh , Jeremy ? {comment} I think . Mm - hmm .  Anyway , yeah that 's {disfmarker} that 's all I was gonna say is that {disfmarker} that that 's {disfmarker} you know , that 's nice and we 're sorta preceding to the next step , and , {vocalsound} it 'll mean some more work , uh , you know , in {disfmarker} in March in getting the proposal out , and then , it 's , uh , you know {disfmarker} We 'll see what happens . Uh , the last one was {disfmarker} that you had there , {comment} was about naming ? Yep . It just , uh {disfmarker} we 've been cutting up sound files , in {disfmarker} for ba both digits and for , uh , doing recognition . And Liz had some suggestions on naming and it just brought up the whole issue that hasn't really been resolved about naming . So , uh , one thing she would like to have is for all the names to be the same length so that sorting is easier . Um , Yeah . same number of characters so that when you 're sorting filenames you can easily extract out bits and pieces that you want . And that 's easy enough to do . And I don't think we have so many meetings that that 's a big deal just to change the names . So that means , uh , instead of calling it \" MR one \" , \" MR two \" , you 'd call it \" MRM zero zero one \" , \" MRM zero zero two \" , things like that . Just so that they 're {disfmarker} they 're all the same length . But , you know , when you , do things like that you can always {disfmarker} as long as you have {disfmarker} uh , you can always search from the beginning or the end of the string . The problem is that they 're a lot of fields . You know , so \" zero zero two \" {disfmarker} Alright , Yeah . so we {disfmarker} we have th we 're gonna have the speaker ID , the session , uh {disfmarker} uh , information on the microphones , Yeah , well , your example was really {disfmarker} information on the speak on the channels and all that . Uh - huh . i And so if each one of those is a fixed length , the sorting becomes a lot easier . OK . She wanted to keep them {vocalsound} the same lengths across different meetings also . So like , the NSA meeting lengths , {comment} all filenames are gonna be the same length as the Meeting Recorder meeting names ? Yep . And as I said , the it 's {disfmarker} we just don't have that many that that 's a big deal . Cuz of digits . And so , uh , um , at some point we have to sort of take a few days off , let the transcribers have a few days off , make sure no one 's touching the data and reorganize the file structures . And when we do that we can also rationalize some of the naming . I {disfmarker} I would think though that the transcribe {disfmarker} the transcripts themselves wouldn't need to have such lengthy names . Right . So , I mean , you 're dealing with a different domain there , and with start and end times and all that , and channels and stuff , Right . So the only thing that would change with that is just the directory names , so , it 's a different {pause} set . I would change them to match . So instead of being MR one it would be MRM zero zero one . But I don't think that 's a big deal . Fine . Fine . So for {disfmarker} for m the meetings we were thinking about three letters and three numbers for meeting I Ds . Uh , for speakers , M or F and then three numbers , For , uh {disfmarker} and , uh , that also brings up the point that we have to start assembling a speaker database so that we get those links back and forth and keep it consistent . Um , and then , uh , the microphone issues . We want some way of specifying , more than looking in the \" key \" file , what channel and what mike . What channel , what mike , and what broadcaster . Or {disfmarker} I don't know how to s say it . So I mean with this one it 's this particular headset with this particular transmitter w {pause} as a wireless . Yeah . Yep . And you know that one is a different headset and different channel . And so we just need some naming conventions on that . Yeah . And , uh , Uh - huh . that 's gonna become especially important once we start changing the microphone set - up . We have some new microphones that I 'd like to start trying out , um , once I test them . And then we 'll {disfmarker} we 'll need to specify that somewhere . So I was just gonna do a fixed list of , uh , microphones and types . Yeah . So , as I said {disfmarker} OK . That sounds good . Yeah . Um , {pause} {vocalsound} since we have such a short agenda list I guess I wi I will ask how {disfmarker} how are the transcriptions going ? Yeah . The {disfmarker} the news is that I 've {disfmarker} I uh {disfmarker} s So {disfmarker} in s um {disfmarker} So I 've switched to {disfmarker} Start my new sentence . I {disfmarker} I switched to doing the channel - by - channel transcriptions to provide , uh , the {disfmarker} uh , tighter time bins for {disfmarker} partly for use in Thilo 's work and also it 's of relevance to other people in the project . And , um , I discovered in the process a couple of {disfmarker} of interesting things , which , um , one of them is that , um , it seems that there are time lags involved in doing this , uh , uh , using an interface that has so much more complexity to it . And I {disfmarker} and I wanted to maybe ask , uh , Chuck to help me with some of the questions of efficiency . Maybe {disfmarker} I was thinking maybe the best way to do this in the long run may be to give them single channel parts and then piece them together later . And I {disfmarker} I have a script , I can piece them together . I mean , so it 's like , I {disfmarker} I know that I can take them apart and put them together and I 'll end up with the representation which is where the real power of that interface is . Mm - hmm . And it may be that it 's faster to transcribe a channel at a time with only one , uh , sound file and one , uh , set of {disfmarker} of , uh , utterances to check through . Yeah . I 'm a little confused . I thought that {disfmarker} that one of the reason we thought we were so much faster than {disfmarker} than , uh , the {disfmarker} the other transcription , uh , thing was that {disfmarker} that we were using the mixed {pause} file . Oh , yes . OK . But , um , with the mixed , when you have an overlap , you only have a {disfmarker} a choice of one start and end time for that entire overlap , which means that you 're not tightly , uh , tuning the individual parts th of that overlap by different speakers . Mm - hmm . Yeah . So someone may have only said two words in that entire big chunk of overlap . Yeah . And for purposes of {disfmarker} of , uh , things like {disfmarker} well , so things like training the speech - nonspeech segmentation thing . Yeah . Th - it 's necessary to have it more tightly tuned than that . OK . And w and w and , you know , is a It would be wonderful if , uh , it 's possible then to use that algorithm to more tightly tie in all the channels after that but , um , you know , I 've {disfmarker} th the {disfmarker} So , I I don't know exactly where that 's going at this point . But m I was experimenting with doing this by hand and I really do think that it 's wise that we 've had them start the way we have with , uh , m y working off the mixed signal , um , having the interface that doesn't require them to do the ti uh , the time bins for every single channel at a t uh , through the entire interaction . Mm - hmm . Um , I did discover a couple other things by doing this though , and one of them is that , um , um , once in a while a backchannel will be overlooked by the transcriber . Mm - hmm . As you might expect , Sure . because when it 's a b backchannel could well happen in a very densely populated overlap . And if we 're gonna study types of overlaps , which is what I wanna do , an analysis of that , then that really does require listening {comment} to every single channel all the way through the entire {comment} length for all the different speakers . Now , for only four speakers , that 's not gonna be too much time , but if it 's nine speakers , then that i that is more time . So it 's li you know , kind of wondering {disfmarker} And I think again it 's like this {disfmarker} it 's really valuable that Thilo 's working on the speech - nonspeech segmentation because maybe , um , we can close in on that wi without having to actually go to the time that it would take to listen to every single channel from start to finish through every single meeting . Yeah , but those backchannels will always be a problem I think . Uh especially if they 're really short and they 're not very loud and so it {disfmarker} it can {disfmarker} it {disfmarker} it will always happen that also the automatic s detection system will miss some of them , so . OK . Well so then {disfmarker} then , maybe the answer is to , uh , listen especially densely in places of overlap , Yeah . just so that they 're {disfmarker} they 're not being overlooked because of that , and count on accuracy during the sparser phases . Yeah . Cuz there are large s spaces of the {disfmarker} That 's a good point . There are large spaces where there 's no overlap at all . Someone 's giving a presentation , Yeah . or whatever . That 's {disfmarker} that 's a good {disfmarker} that 's a good thought . And , um , let 's see , there was one other thing I was gonna say . I {disfmarker} I think it 's really interesting data to work with , I have to say , it 's very enjoyable . I really , not {disfmarker} not a problem spending time with these data . Really interesting . And not just because I 'm in there . No , it 's real interesting . Uh , well I think it 's a short meeting . Uh , you 're {disfmarker} you 're {disfmarker} you 're still in the midst of what you 're doing from what you described last time , I assume , Is true .  and {disfmarker} I haven't results , eh , yet Yeah . but , eh , I {disfmarker} I 'm continue working with the mixed signal now , {comment} after the {disfmarker} the last experience . Yeah . Yeah . And {disfmarker} and I 'm tried to {disfmarker} to , uh , adjust the {disfmarker} to {disfmarker} to improve , eh , an harmonicity , eh , detector that , eh , I {disfmarker} I implement . Yeah . But I have problem because , eh , I get , eh , eh , very much harmonics now . Yeah . Um , harmonic {disfmarker} possi possible harmonics , uh , eh , and now I 'm {disfmarker} I 'm {disfmarker} I 'm trying to {disfmarker} to find , eh , some kind of a , um {disfmarker} {vocalsound} of h of help , eh , using the energy to {disfmarker} to distinguish between possible harmonics , and {disfmarker} and other fre frequency peaks , that , eh , corres not harmonics . And , eh , I have to {disfmarker} to talk with y with you , with the group , eh , about the instantaneous frequency , because I have , eh , an algorithm , and , I get , mmm , eh , t t results {disfmarker} similar results , like , eh , the paper , eh , that I {disfmarker} I am following . But , eh , the {disfmarker} the rules , eh , that , eh , people used in the paper to {disfmarker} to distinguish the harmonics , is {disfmarker} doesn't work well . Mm - hmm . And I {disfmarker} I {disfmarker} I {disfmarker} I not sure that i {vocalsound} eh , the {disfmarker} the way {disfmarker} o to {disfmarker} ob the way to obtain the {disfmarker} the instantaneous frequency is {pause} right , or it 's {disfmarker} it 's not right . Eh , Yeah . I haven't enough file feeling to {disfmarker} to {disfmarker} to distinguish what happened . Yeah , I 'd like to talk with you about it . If {disfmarker} if {disfmarker} if , uh {disfmarker} If I don't have enough time and y you wanna discuss with someone else {disfmarker} some someone else besides us that you might want to talk to , uh , might be Stephane . Yeah . I talked with Stephane and {disfmarker} and Thilo Yeah and {disfmarker} and Thilo , yeah . and , Yeah , but {disfmarker} they {disfmarker} nnn they {disfmarker} {vocalsound} they {comment} {disfmarker} {vocalsound} they {vocalsound} didn't {disfmarker} I 'm not too experienced with {vocalsound} harmonics I see . they think that {comment} the experience is not enough to {disfmarker} and {disfmarker} Is {disfmarker} is this the algorithm where you hypothesize a fundamental , and then get the energy for all the harmonics of that fundamental ? No , no it 's {disfmarker} No {disfmarker} No . No . And then hypothesize a new fundamental and get the energy {disfmarker} Yeah , that 's wh No . I {disfmarker} I {disfmarker} I {disfmarker} I don't proth process the {disfmarker} the fundamental . I {disfmarker} {vocalsound} I , ehm {disfmarker} I calculate the {disfmarker} the phase derivate using the FFT . Yeah . And {disfmarker} The algorithm said that , eh , {vocalsound} if you {disfmarker} if you change the {disfmarker} the {disfmarker} {vocalsound} the , eh , nnn {disfmarker} the X - the frequency \" X \" , eh , using the in the instantaneous frequency , you can find , eh , how , eh , in several frequencies that proba probably the {disfmarker} the harmonics , eh , Uh - huh . the errors of peaks {disfmarker} the frequency peaks , eh , eh , move around {pause} these , eh {disfmarker} eh frequency harmonic {disfmarker} the frequency of the harmonic . And , {vocalsound} eh , if you {disfmarker} if you compare the {disfmarker} the instantaneous frequency , {vocalsound} eh , {vocalsound} of the {disfmarker} of the , eh , continuous , eh , {vocalsound} eh , filters , that , eh {disfmarker} that , eh , they used eh , to {disfmarker} {vocalsound} to {disfmarker} to get , eh , the {disfmarker} the instantaneous frequency , Mm - hmm . it probably too , you can find , {vocalsound} eh , that the instantaneous frequency {vocalsound} for the continuous , eh , {vocalsound} eh {disfmarker} the output of the continuous filters are very near . And in {pause} my case {disfmarker} i in {disfmarker} equal with our signal , {vocalsound} it doesn't happened . Yeah . I 'd hafta look at that and think about it . And {disfmarker} It 's {disfmarker} it 's {disfmarker} it 's {disfmarker} I haven't worked with that either so I 'm not sure {disfmarker} The way {disfmarker} {vocalsound} the simple - minded way I suggested was what Chuck was just saying , is that you could make a {disfmarker} a sieve . You know , y you actually say that here is {disfmarker} Yeah . Let 's {disfmarker} let 's hypothesize that it 's this frequency or that frequency , and {disfmarker} and , uh , maybe you {disfmarker} maybe you could use some other cute methods to , uh , short cut it by {disfmarker} by uh , making some guesses , Yeah . but {disfmarker} but uh {disfmarker} uh {disfmarker} uh , I would , uh {disfmarker} I mean you could make some guesses from , uh {disfmarker} from the auto - correlation or something but {disfmarker} but then , given those guesses , try , um , uh , only looking at the energy at multiples of the {disfmarker} of that frequency , and {disfmarker} and see how much of the {disfmarker} take the one that 's maximum . Call that the {disfmarker} Yeah . But {disfmarker} Using the energy of the {disfmarker} of the multiple of the frequency . Of all the harmonics of that . Yeah . Yeah . Do you hafta do some kind of , uh , low - pass filter before you do that ? I don't use . Or {disfmarker} But , I {disfmarker} I know many people use , eh , low - pass filter to {disfmarker} to {disfmarker} to get , eh , the pitch . No . To get the pitch , yes . I don't use . To get the pitch , yes . To get the pitch , yeah . But the harmonic , no . But i But the harmonics are gonna be , uh , uh , I don't know what the right word is . Um , they 're gonna be dampened by the uh , vocal tract , right ? The response of the vocal tract . Yeah ? Yeah ? And so {disfmarker} just looking at the energy on those {disfmarker} at the harmonics , is that gonna {disfmarker} ? Well so the thing is that the {disfmarker} This is for , uh , a , um {disfmarker} I m what you 'd like to do is get rid of the effect of the vocal tract . Right ? Yeah . And just look at the {disfmarker} at {disfmarker} at the signal coming out of the glottis . Yeah . Uh , well , yeah that 'd be good . Yeah . But , uh {disfmarker} but I {disfmarker} but {disfmarker} {vocalsound} but I don't know that you need to {disfmarker} Open wide ! but I don't need you {disfmarker} know if you need to get rid of it . I mean that 'd {disfmarker} that 'd be nice but I don't know if it 's ess if it 's essential . Um , I mean {disfmarker} cuz I think the main thing is that , uh , you 're trying {disfmarker} Uh - huh . wha what are you doing this for ? You 're trying distinguish between the case where there is , uh {disfmarker} where {disfmarker} where there are more than {disfmarker} uh , where there 's more than one speaker and the case where there 's only one speaker . Sorry . So if there 's more than one speaker , um {disfmarker} yeah I guess you could {disfmarker} I guess {disfmarker} yeah you 're {disfmarker} so you 're not distinguished between voiced and unvoiced , so {disfmarker} so , i if you don't {disfmarker} if you don't care about that {disfmarker} Yeah . See , if you also wanna {vocalsound} just determine {disfmarker} if you also wanna determine whether it 's unvoiced , {vocalsound} then I think you want to {pause} look {disfmarker} look at high frequencies also , because the f the fact that there 's more energy in the high frequencies is gonna be an ob sort of obvious cue that it 's unvoiced . Yeah . But , i i uh {disfmarker} {vocalsound} I mean i i but , um , other than that I guess as far as the one person versus two persons , it would be {pause} primarily a low frequency phenomenon . And if you looked at the low frequencies , yes the higher frequencies are gonna {disfmarker} there 's gonna be a spectral slope . The higher frequencies will be lower energy . But so what . I mean {disfmarker} {vocalsound} that 's {disfmarker} that 's w I will prepare for the next week eh , all my results about the harmonicity and {pause} will {disfmarker} will try to come in and to discuss here , because , eh , I haven't enough feeling to {disfmarker} {vocalsound} to u {vocalsound} many time to {disfmarker} {vocalsound} to understand what happened with the {disfmarker} with , eh , so many peaks , eh , eh , and {vocalsound} I {disfmarker} I see the harmonics there many time but , eh , {vocalsound} there are a lot of peaks , eh , that , eh , they are not harmonics . Yeah . Um , I have to discover what {disfmarker} what is the {disfmarker} the w the best way to {disfmarker} to {comment} {disfmarker} to {comment} c to use them Well , but {disfmarker} yeah I don't think you can {disfmarker} I mean you 're not gonna be able to look at every frame , so I mean {disfmarker} I {disfmarker} I mean I {disfmarker} I really {disfmarker} I I really thought that the best way to do it , and I 'm speaking with no experience on this particular point , but , {vocalsound} my impression was that the best way to do it was however you {disfmarker} You 've used instantaneous frequency , whatever . {comment} However you 've come up {disfmarker} you {disfmarker} with your candidates , you wanna see how much of the energy is in that Yeah . Yeah . as coppo as opposed to all of the {disfmarker} all {disfmarker} the total energy . And , um , if it 's voiced , I guess {disfmarker} so {disfmarker} so y I think maybe you do need a voiced - unvoiced determination too . But if it 's voiced , Yeah . um , and the , uh {disfmarker} e the fraction of the energy that 's in the harmonic sequence that you 're looking at is relatively low , then it should be {disfmarker} then it 's more likely to be an overlap . Is height . Yeah . This {disfmarker} this is the idea {disfmarker} the idea I {disfmarker} I {disfmarker} I had to {disfmarker} to compare the {disfmarker} the ratio of the {disfmarker} {vocalsound} the energy of the harmonics with the {disfmarker} eh , with the , eh , total energy in the spectrum and try to get a ratio to {disfmarker} to distinguish between overlapping and speech . Mmm . But you 're looking a y you 're looking at {disfmarker} Let 's take a second with this . Uh , uh , you 're looking at f at the phase derivative , um , in {disfmarker} in , uh , what domain ? I mean this is {disfmarker} this is in {disfmarker} in {disfmarker} in {disfmarker} in bands ? Or {disfmarker} or {disfmarker} No , no , no . Just {disfmarker} just overall {disfmarker} It 's a {disfmarker} it 's a {disfmarker} o i w the band {disfmarker} the band is , eh , from zero to {disfmarker} to four kilohertz . And I {disfmarker} I ot I {disfmarker} And you just take the instantaneous frequency ? Yeah . I u m t I {disfmarker} I used two m two method {disfmarker} two methods . Eh , one , eh , based on the F {disfmarker} eh , FTT . to FFT to {disfmarker} to obtain the {disfmarker} or to study the harmonics from {disfmarker} from the spectrum directly , Yeah . and to study the energy and the multiples of Yeah . frequency . And another {disfmarker} another algorithm I have is the {disfmarker} in the {pause} instantaneous frequency , based on {disfmarker} on {disfmarker} on the FFT to {disfmarker} to {disfmarker} to calculate the {disfmarker} the phase derivate in the time . Eh , uh n the d I mean I {disfmarker} I have two {disfmarker} two algorithms . Right . But , eh , in m {pause} i in my opinion the {disfmarker} the {disfmarker} the instantaneous frequency , the {disfmarker} the {disfmarker} the behavior , eh , was {disfmarker} th it was very interesting . Because I {disfmarker} I saw {vocalsound} eh , how the spectrum {pause} concentrate , eh , Oh ! around the {disfmarker} the harmonic . But then when I apply the {disfmarker} the rule , eh , of the {disfmarker} in the {disfmarker} {pause} the instantaneous frequency of the ne of the continuous filter in the {disfmarker} the near filter , the {disfmarker} the rule that , eh , people propose in the paper doesn't work . And I don't know why . But the instantaneous frequency , wouldn't that give you something more like the central frequency of the {disfmarker} you know , of the {disfmarker} where most of the energy is ? I mean , I think if you {disfmarker} Does i does it {disfmarker} Why would it correspond to pitch ? Yeah . I {disfmarker} I {disfmarker} I not sure . I {disfmarker} I {disfmarker} I try to {disfmarker} to {disfmarker} Yeah . When {vocalsound} first I {disfmarker} {pause} {vocalsound} I calculate , eh , using the FFT , Di - digital camera . the {disfmarker} the {disfmarker} Keep forgetting . I get the {disfmarker} {pause} the spectrum , Yeah . and I represent all the frequency . Yeah . And {disfmarker} when ou I obtained the instantaneous frequency . And I change {vocalsound} the {disfmarker} the {disfmarker} the @ @ , using the instantaneous frequency , here . Oh , so you scale {disfmarker} you s you do a {disfmarker} a scaling along that axis according to instantaneous {disfmarker} I use {disfmarker} Yeah . It 's a kinda normalization . Yeah . Yeah . Because when {disfmarker} when {disfmarker} OK . eh , when i I {disfmarker} I use these {disfmarker} these frequency , eh , the range is different , and the resolution is different . Yeah . And I observe more {disfmarker} more or less , thing like this . And the paper said that , eh , these frequencies are probably , eh , harmonics . I see . Huh . But , eh , they used , eh , a rule , eh , based in the {disfmarker} in the {disfmarker} because to {disfmarker} to calculate the instantaneous frequency , they use a Hanning window . Yeah . And , they said that , eh , if {pause} these {pause} peak are , eh , harmonics , the f instantaneous frequency , of the contiguous , eh {disfmarker} w eh eh , filters are very near , or have to be very near . But , eh , phh ! I don't {disfmarker} I {disfmarker} I {disfmarker} I {disfmarker} I don I I {disfmarker} and I don't know what is the {disfmarker} what is the distance . And I tried to {disfmarker} to put different distance , eh , to put difference , eh {disfmarker} eh , length of the window , eh , different front sieve , Pfff ! and I {disfmarker} I not sure what happened . OK , yeah well I {disfmarker} I guess I 'm not following it enough . I 'll {comment} probably gonna hafta look at the paper , but {disfmarker} which I 'm not gonna have time to do in the next few days , but {disfmarker} {vocalsound} but I 'm {disfmarker} I 'm curious about it . Yeah . Um , uh , OK . I I did i it did occur to me that this is {disfmarker} uh , the return to the transcription , that there 's one third thing I wanted to {disfmarker} to ex raise as a to as an issue which is , um , how to handle breaths . So , I wanted to raise the question of whether people in speech recognition want to know where the breaths are . And the reason I ask the question is , um , aside from the fact that they 're obviously very time - consuming to encode , uh , the fact that there was some {disfmarker} I had the indication from Dan Ellis in the email that I sent to you , Yeah . and you know about , that in principle we might be able to , um , handle breaths by accessi by using cross - talk from the other things , be able that {disfmarker} in principle , maybe we could get rid of them , so maybe {disfmarker} And I was {disfmarker} I {disfmarker} I don't know , I mean we had this an and I didn't {disfmarker} couldn't get back to you , Yeah . but the question of whether it 'd be possible to eliminate them from the audio signal , which would be the ideal situation , I don't know {disfmarker} think it 'd be ideal . cuz {disfmarker} Uh - uh . We - See , we 're {disfmarker} we 're dealing with real speech and we 're trying to have it be as real as possible Yeah . and breaths are part of real speech . Well , except that these are really truly {disfmarker} I mean , ther there 's a segment in o the one I did {disfmarker} n the first one that I did for {disfmarker} i for this , Yeah . where truly w we 're hearing you breathing like {disfmarker} as if we 're {disfmarker} you 're in our ear , you know , and it 's like {disfmarker} it 's like {disfmarker} Yeah . I y i I mean , breath is natural , but not It is {disfmarker} but it is if you record it . Yeah . Except that we 're {disfmarker} we 're trying to mimic {disfmarker} Oh , I see what you 're saying . You 're saying that the PDA application would have {disfmarker} uh , have to cope with breath . Yeah . Well No . But {disfmarker} An - any application may have to . The P D A might not have to , No {disfmarker} i but more people than just PDA users are interested in this corpus . Yeah . So {disfmarker} so mean you 're right OK , then the {disfmarker} then {disfmarker} I have two questions . we could remove it , Yeah ? but I {disfmarker} I think {disfmarker} we don't wanna w remove it from the corpus , {pause} in terms of delivering it because the {disfmarker} people will want it in there . Yeah . If it gets {disfmarker} OK , so maybe the question is notating it . Yeah ? Yeah {disfmarker} i Right . If {disfmarker} if it gets in the way of what somebody is doing with it then you might wanna have some method which will allow you to block it , but you {disfmarker} it 's real data . You don't wanna b but you don't {disfmarker} OK , well {disfmarker} If s you know , if there 's a little bit of noise out there , and somebody is {disfmarker} is talking about something they 're doing , that 's part of what we accept as part of a real meeting , even {disfmarker} And we have the f uh {disfmarker} the uh {disfmarker} the {disfmarker} the fan and the {disfmarker} in the projector up there , and , uh , this is {disfmarker} it 's {disfmarker} this is actual stuff that we {disfmarker} we wanna work with . Well this is in very interesting So . because i it basically has a i it shows very clearly the contrast between , uh , speech recognition research and discourse research because in {disfmarker} in discourse and linguistic research , what counts is what 's communit communicative . Mm - hmm . And {disfmarker} breath , you know , everyone breathes , they breathe all the time . And once in a while breath is communicative , but r very rarely . OK , so now , I had a discussion with Chuck about the data structure Mm - hmm . and the idea is that the transcripts will {disfmarker} that {disfmarker} get stored as a master there 'll be a master transcript which has in it everything that 's needed for both of these uses . Mm - hmm . And the one that 's used for speech recognition will be processed via scripts . You know , like , Don 's been writing scripts Mm - hmm . and {disfmarker} and , uh , to process it for the speech recognition side . Discourse side will {vocalsound} have this {disfmarker} this side over he the {disfmarker} we we 'll have a s ch Sorry , not being very fluent here . But , um , this {disfmarker} the discourse side will have a script which will stri strip away the things which are non - communicative . OK . So then the {disfmarker} then {disfmarker} let 's {disfmarker} let 's think about the practicalities of how we get to that master copy with reference to breaths . So what I would {disfmarker} r r what I would wonder is would it be possible to encode those automatically ? Could we get a breath detector ? Oh , just to save the transcribers time . Well , I mean , you just have no idea . I mean , if you 're getting a breath several times every minute , Mm - hmm . and just simply the keystrokes it takes to negotiate , to put the boundaries in , to {disfmarker} to type it in , i it 's just a huge amount of time . Mm - hmm . Oops . Wh - what {disfmarker} Yeah . And you wanna be sure it 's used , and you wanna be sure it 's done as efficiently as possible , and if it can be done automatically , that would be ideal . what if you put it in but didn't put the boundaries ? Well , but {disfmarker} So you just know it 's between these other things , Well , OK . So now there 's {disfmarker} there 's another {disfmarker} another possibility right ? which is , um , the time boundaries could mark off words {comment} from nonwords . And that would be extremely time - effective , if that 's sufficient . Yeah I mean I 'm think if it 's too {disfmarker} if it 's too hard for us to annotate the breaths per se , {vocalsound} we are gonna be building up models for these things and these things are somewhat self - aligning , so if {disfmarker} so , {vocalsound} we {disfmarker} i i if we say there is some kind of a thing which we call a \" breath \" or a \" breath - in \" or \" breath - out \" , {vocalsound} the models will learn that sort of thing . Uh , so {disfmarker} but you {disfmarker} but you do want them to point them at some region where {disfmarker} where the breaths really are . So {disfmarker} OK . But that would maybe include a pause as well , Well , there 's a there 's {disfmarker} and that wouldn't be a problem to have it , uh , pause plus breath plus laugh plus sneeze ? Yeah , i You know there is {disfmarker} there 's this dynamic tension between {disfmarker} between marking absolutely everything , as you know , and {disfmarker} and {disfmarker} and marking just a little bit and counting on the statistical methods . Basically the more we can mark the better . But if there seems to be a lot of effort for a small amount of reward in some area , and this might be one like this {disfmarker} Although I {disfmarker} I {disfmarker} I 'd be interested to h get {disfmarker} get input from Liz and Andreas on this to see if they {disfmarker} Cuz they 've - they 've got lots of experience with the breaths in {disfmarker} in , uh , uh , their transcripts . They have lots of experience with breathing ? I {disfmarker} Actually {disfmarker} Well , {vocalsound} yes they do , but we {disfmarker} {vocalsound} we can handle that without them here . But {disfmarker} but {disfmarker} but , uh , you were gonna say something about {disfmarker} Yeah , I {disfmarker} I think , um , one possible way that we could handle it is that , um , you know , as the transcribers are going through , and if they get a hunk of speech that they 're gonna transcribe , u th they 're gonna transcribe it because there 's words in there or whatnot . If there 's a breath in there , they could transcribe that . Yeah . Yeah . That 's what they 've been doing . So , within an overlap segment , they {disfmarker} they do this . Right . But {disfmarker} Right . But if there 's a big hunk of speech , let 's say on Morgan 's mike where he 's not talking at all , um , don't {disfmarker} don't worry about that . Yeah . So what we 're saying is , there 's no guarantee that , um {disfmarker} So for the chunks that are transcribed , everything 's transcribed . But outside of those boundaries , there could have been stuff that wasn't transcribed . So you just {disfmarker} somebody can't rely on that data and say \" that 's perfectly clean data \" . Uh {disfmarker} do you see what I 'm saying ? Yeah , you 're saying it 's {disfmarker} uncharted territory . So I would say don't tell them to transcribe anything that 's outside of a grouping of words . That sounds like a reasonable {disfmarker} reasonable compromise . Yeah , and that 's {disfmarker} that {disfmarker} that quite co corresponds to the way I {disfmarker} I try to train the speech - nonspeech detector , as I really try to {disfmarker} not to detect those breaths which are not within a speech chunk but with {disfmarker} which are just in {disfmarker} in a silence region . Yeah . And they {disfmarker} so they hopefully won't be marked in {disfmarker} in those channel - specific files . u I {disfmarker} I wanted to comment a little more just for clarification about this business about the different purposes . But {disfmarker} Yeah , so {disfmarker} Mm - hmm . See , in a {disfmarker} in a way this is a really key point , that for speech recognition , uh , research , uh , um , e a {disfmarker} it 's not just a minor part . In fact , the {disfmarker} I think I would say the core thing that we 're trying to do is to recognize the actual , meaningful components in the midst of other things that are not meaningful . So it 's critical {disfmarker} it 's not just incidental it 's critical for us to get these other components that are not meaningful . Because that 's what we 're trying to pull the other out of . That 's our problem . If we had nothing {disfmarker} Yeah . if we had only linguistically - relevant things {disfmarker} if {disfmarker} if we only had changes in the spectrum that were associated with words , with different spectral components , and , uh , we {disfmarker} we didn't have noise , we didn't have convolutional errors , we didn't have extraneous , uh , behaviors , and so forth , and {vocalsound} moving your head and all these sorts of things , then , actually speech recognition i i isn't that bad right now . I mean you can you know it 's {disfmarker} {vocalsound} it 's {disfmarker} the technology 's come along pretty well . Yeah . The {disfmarker} the {disfmarker} the reason we still complain about it is because is {disfmarker} when {disfmarker} when you have more realistic conditions then {disfmarker} then things fall apart . OK , fair enough . I guess , um , I {disfmarker} uh , what I was wondering is what {disfmarker} what {disfmarker} at what level does the breathing aspect enter into the problem ? Because if it were likely that a PDA would be able to be built which would get rid of the breathing , so it wouldn't even have to be processed at thi at this computational le well , let me see , it 'd have to be computationally processed to get rid of it , but if there were , uh , like likely on the frontier , a good breath extractor then , um , and then you 'd have to {disfmarker} But that 's a research question , you know ? And so {disfmarker} Yeah , well , see and that 's what I wouldn't know . that {disfmarker} And we don't either . I mean so {disfmarker} so the thing is it 's {disfmarker} it {disfmarker} right now it 's just raw d it 's just data that we 're collecting , and so {vocalsound} we don't wanna presuppose that people will be able to get rid of particular degradations because that 's actually the research that we 're trying to feed . So , you know , an and maybe {disfmarker} maybe in five years it 'll work really well , OK . and {disfmarker} and it 'll only mess - up ten percent of the time , but then we would still want to account for that ten percent , so . I guess there 's another aspect which is that as we 've improved our microphone technique , we have a lot less breath in the {disfmarker} in the more recent , uh , recordings , so it 's {disfmarker} in a way it 's an artifact that there 's so much on the {disfmarker} on the earlier ones . Uh - huh . I see . One of the {disfmarker} um , just to add to this {disfmarker} one of the ways that we will be able to get rid of breath is by having models for them . I mean , that 's what a lot of people do nowadays . Right . Right . Yeah . And so in order to build the model you need to have some amount of it marked , so that you know where the boundaries are . Hmm . Yeah . So {disfmarker} I mean , I don't think we need to worry a lot about breaths that are happening outside of a , you know , conversation . We don't have to go and search for them to {disfmarker} to mark them at all , but , I mean , if they 're there while they 're transcribing some hunk of words , I 'd say put them in if possible . OK , and it 's also the fact that they differ a lot from one channel to the other because of the way the microphone 's adjusted . Yeah . Mm - hmm . OK . Should we do the digits ? Yep . OK . OK . Mmm . Alright .",
        "summarize": "The group talked about the status of the first test set of digits data, naming conventions for files, speaker identification tags, and encoding files with details about the recording. The group also discussed a proposal for a grant from the NSF's ITR (Information Technology Research) program, transcriptions, and efforts by speaker mn005 to detect speaker overlap using harmonicity-related features. Particular focus was paid to questions about transcription procedures, i.e. how to deal with overlooked backchannels, and audible breaths."
    }
]