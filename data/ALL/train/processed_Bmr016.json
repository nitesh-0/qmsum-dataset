[
    {
        "transcript": "And we already got the crash out of the way . It did crash , so I feel much better , earlier .  Yeah . Interesting . Hmm . Will you get the door , and {disfmarker} ?  OK , so um . OK . You collected an agenda , huh ? I did collect an agenda . So I 'm gonna go first . Mwa - ha - ha ! It shouldn't take too long . Yeah . Um , so we 're pretty much out of digits . We 've gone once through the set . Um , so the only thing I have to do No there 's only ten . Yeah , that 's right . so I {disfmarker} I just have to go through them Well , OK . and uh pick out the ones that have problems , and either correct them or have them re - read . So we probably have like four or five more forms to be read , to be once through the set . I 've also extracted out about an hour 's worth . We have about two hours worth . I extracted out about an hour 's worth which are the f digits with {disfmarker} for which whose speaker have speaker forms , have filled out speaker forms . Not everyone 's filled out a speaker form . So I extracted one for speakers who have speaker forms and for meetings in which the \" key \" file and the transcript files are parsable . Some of the early key files , it looks like , were done by hand , and so they 're not automatically parsable and I have to go back and fix those . So what that means is we have about an hour of transcribed digits that we can play with . Um , Liz {disfmarker} So you think two {disfmarker} you think two hours is the {disfmarker} is the total that we have ? Yep , yeah . And you think we th uh , I {disfmarker} I didn't quite catch all these different things that are not quite right , but you think we 'll be able to retrieve the other hour , reasonably ? Yes , absolutely . OK . So it 's just a question of a little hand - editing of some files and then waiting for more people to turn in their speaker forms . I have this web - based speaker form , and I sent mail to everyone who hadn't filled out a speaker form , and they 're slowly s trickling in . So the relevance of the speaker form here , s It 's for labeling the extracted audio files . Oh , OK . By speaker ID and microphone type . Wasn't like whether they were giving us permission to use their digits or something . No , I spoke with Jane about that and we sort of decided that it 's probably not an issue that {disfmarker} We edit out any of the errors anyway . Right ? So the there are no errors in the digits , Yeah . you 'll always read the string correctly . So I can't imagine why anyone would care . So the other topic with digits is uh , Liz would like to elicit different prosodics , and so we tried last week with them written out in English . And it just didn't work at all because no one grouped them together . So it just sounded like many many more lines instead of anything else . So in conversations with Liz and uh Jane we decided that if you wrote them out as numbers instead of words it would elicit more phone number , social security number - like readings . The problem with that is it becomes numbers instead of digits . When I look at this , that first line is \" sixty one , sixty two , eighteen , eighty six , ten . \" Um , and so the question is does anyone care ? Um , I 've already spoken with Liz and she feels that , correct me if I 'm wrong , that for her , connected numbers is fine , Mm - hmm . as opposed to connected digits . Um , I think two hours is probably fine for a test set , but it may be a little short if we actually wanna do training and adaptation and all that other stuff . Yeah Um , do um you want different prosodics , so if you always had the same groupings you wouldn't like that ? Is that correct ? Well , we actually figured out a way to {disfmarker} Yeah , the {disfmarker} the {disfmarker} the {disfmarker} the groupings are randomly generated . No but , I was asking if that was something you really cared about because if it wasn't , it seems to me if you made it really specifically telephone groupings that maybe people wouldn't , uh , go and do numbers so much . You know if it if it 's {disfmarker} Uh {disfmarker} I think they may still do it , um , Maybe some , but I probably not so much . What about putting a hyphen between the numbers in the group ? And {disfmarker} Right ? So if you {disfmarker} if {disfmarker} if you have uh Six dash one , you mean ? if you go six six six uh dash uh two nine three one . I {disfmarker} well OK {disfmarker} I {disfmarker} it might help , I would like to g get away from having only one specific grouping . That 's what I was asking , yeah . Um , so if that 's your question , Yeah . but I mean it seems to me that , at least for us , we can learn to read them as digits Yeah . if that 's what people want . I {disfmarker} I 'm Yeah . don't think that 'd be that hard to read them as single digits . I agree . Um , and it seems like that might be better for you guys since then you 'll have just more digit data , Right . and that 's always a good thing . Yep . It 's a little bit better for me too because the digits are easier to recognize . They 're better trained than the numbers . So we could just , uh , put in the instructions \" read them as digits \" . Right . Right . Right , read them as single digits , so sixty - one w is read as six one , Mm - hmm . and if people make a mistake we {disfmarker} How about \" O \" versus \" zero \" ? I mean , the other thing is we could just bag it because it 's {disfmarker} it 's {disfmarker} it 's - I 'm not worrying about it I mean , because we do have digits training data that we have from uh from OGI . I 'm sorry , digits {disfmarker} numbers training that we have from OGI , we 've done lots and lots of studies with that . And um . But it 's nice to get it in this room with the acous Yeah . I mean {disfmarker} for {disfmarker} it 's {disfmarker} No , no , I guess what I 'm saying is that Just let them read it how they read it . to some extent maybe we could just read them {disfmarker} have them read how {disfmarker} how they read it and it just means that we have to expand our {disfmarker} our vocabulary out to stuff that we already have . Right . Well that 's fine with me as long as {disfmarker} It 's just that I didn't want to cause the people who would have been collecting digits the other way to not have the digits . Yeah . We can go back to the other thing later . So {disfmarker} I mean we s we {disfmarker} we 've {disfmarker} We can do this for awhile OK . and then go back to digits for awhile , or um . Do yo I mean , do you want {disfmarker} do you want this {disfmarker} Do you need training data or adaptation data out of this ? OK . How much of this do you need ? with uh the {disfmarker} It 's actually unclear right now . I just thought well we 're {disfmarker} if we 're collec collecting digits , and Adam had said we were running out of the TI forms , I thought it 'd be nice to have them in groups , and probably , all else being equal , it 'd be better for me to just have single digits OK . since it 's , you know , a recognizer 's gonna do better on those anyway , um , and it 's more predictable . So we can know from the transcript what the person said and the transcriber , in general . OK , well if you pre But if they make mistakes , it 's no big deal if the people say a hundred instead of \" one OO \" . and also w maybe we can just let them choose \" zero \" versus \" O \" as they {disfmarker} as they like because even the same person c sometimes says \" O \" and sometimes says \" zero \" in different context , Yeah . and that 's sort of interesting . So I don't have a Specific need cuz if I did I 'd probably try to collect it , you know , without bothering this group , but If we can try it {disfmarker} OK so {disfmarker} so I can just add to the instructions to read it as digits not as connected numbers . Mm - hmm . Right , and you can give an example like , you know , \" six {disfmarker} sixty - one would be read as six one \" . Right . Mm - hmm . And i actually it 's no more artificial than what we 've been doing with words . And I think people will get it . I 'm sure people can adapt to this , read it single . Right , right . The spaces already bias it toward being separated . It 's just easier to read . And I know I 'm gonna find this easier than words . Right . Oh yeah , absolutely , cognitively it 's much easier . OK I also had a hard {disfmarker} hard time with the words , Yeah . but then we went back and forth on that . OK , so let 's give that a try OK . And is the spacing alright or do you think there should be more space between digits and groups ? OK . and {disfmarker} Or is that alright ? I mean what do other people think cuz you guys are reading {comment} them . I think that i it 's fine . OK . I it {disfmarker} it {disfmarker} to me it looks like you 've got the func the idea of grouping and you have the grou the idea of separation OK . and , you know , it 's just a matter of u i the instructions , that 's all . Great . OK . And I think there are about ten different gouping patterns Let 's try it . Well let 's give it a try . isn't that right , Liz ? That we did . Righ - right , and you just {disfmarker} they 're randomly {nonvocalsound} generated and randomly assigned to digits . I did {disfmarker} Mm - hmm . So we have {disfmarker} Go ahead . Sorry , I {disfmarker} I was just gonna say , so we have in the vicinity of forty hours of {disfmarker} of recordings now . And you 're saying two hours , uh , is digits , so that 's roughly the ratio then , Yep . something like twenty {disfmarker} twenty to one . Which I guess makes {disfmarker} makes sense . So if we did another forty hours of recordings then we could get another couple hours of this . Right . Um , yeah like you say , I think a couple hours for a {disfmarker} for a {disfmarker} for a test {disfmarker} test set 's OK . It 'd be nice to get , you know , more later because we 'll {disfmarker} we might use {disfmarker} use this up , uh , in some sense , Mm - hmm . Right . but {disfmarker} but uh {disfmarker} Yeah , I also would like to argue for that cuz it {disfmarker} it seems to me that , um , there 's a real strength in having the same test replicated in {disfmarker} a whole bunch of times and adding to that basic test bank . Right . Hmm ? Cuz then you have , you know , more and more , u chances to get away from random errors . And I think , um , the other thing too is that right now we have sort of a stratified sample with reference to dialect groups , and it might be {disfmarker} there might be an argument to be made for having uh f for replicating all of the digits that we 've done , which were done by non - native speakers so that we have a core that totally replicates the original data set , which is totally American speakers , and then we have these stratified additional language groups overlapping certain aspects of the database . Right . I think that uh trying to duplicate , spending too much effort trying to duplicate the existing TI - digits probably isn't too worthwhile because the recording situation is so different . Yeah . It 's gonna be very hard to be comparable . Except that if you have the stimuli {pause} comparable , then it says something about the {disfmarker} the contribution of setting No it 's {disfmarker} it 's not the same . and {disfmarker} A little bit , but the other differences are so major . Yeah I mean read versus not . OK . They 're such major sources of variance that it 's {disfmarker} it 's {disfmarker} it 's uh {disfmarker} What 's an example of a {disfmarker} of m some of the other differences ? Any other a difference ? Well i i individual human glottis {vocalsound} is going to be different for each one , OK . you know , it 's just {disfmarker} There 's so many things . Well , and not just that , OK . it 's {disfmarker} it {disfmarker} and {disfmarker} and enunciation . I mean the uh the corpus itself . I mean , we 're collecting it in a read digit in a particular list , and I 'm sure that they 're doing more specific stuff . I mean if I remember correctly it was like postman reading zipcodes and things like that . TI - digits was ? I thought so . I thought {disfmarker} I thought it was read . Was it read ? Yeah , I think the reading zipcode stuff you 're thinking of would be OGI . Oh , I may well be . Yeah , no TI - digits was read in th in read in the studio I believe . I haven't ever listened to TI - digits . So I don't really know how it compares . Yeah . Yeah . But {disfmarker} but regardless it 's gonna {disfmarker} it 's hard to compare cross - corpus . But it {disfmarker} but {disfmarker} It - it 's different people {pause} is the {disfmarker} is the core thing . So . OK , fine . And they 're different circumstances with different recording environment and so forth , so it 's {disfmarker} it 's {disfmarker} it 's really pretty different . But I think the idea of using a set thing was just to give you some sort of framework , so that even though you couldn't do exact comparisons , it wouldn't be s valid scientifically at least it 'd give you some kind of uh frame of reference . Uh , you know it 's not {disfmarker} Hey Liz , What {disfmarker} what do the groupings represent ? OK . You said there 's like ten different groupings ? Right , just groupings in terms of number of groups in a line , and number of digits in a group , and the pattern of groupings . Mm - hmm . Are the patterns {disfmarker} like are they based on anything or Um , I {disfmarker} I just roughly looked at what kinds of digit strings are out there , and they 're usually grouped into either two , three , or four , four digits at a time . Oh . And they can have , I mean , actually , things are getting longer and longer . In the old days you probably only had three sequences , and telephone numbers were less , and so forth . So , there 's between , um {disfmarker} Well if you look at it , there are between like three and five groups , and each one has between two and four groupings and {disfmarker} I purposely didn't want them to look like they were in any kind of pattern . Mmm . So And which group appears is picked randomly , and what the numbers are are picked randomly . Mm - hmm . So unlike the previous one , which I d simply replicated TI - digits , this is generated randomly . Right . Oh OK . Mmm , oh , OK . But I think it 'd be great i to be able to compare digits , whether it 's these digits or TI - digits , to speakers , um , and compare that to their spontaneous speech , and then we do need you know a fair amount of {disfmarker} of digit data because you might be wearing a different microphone Mm - hmm . and , I mean {disfmarker} so it 's {disfmarker} it 's nice to have the digits you know , replicated many times . Especially for speakers that don't talk a lot . Yeah . So {vocalsound} um , for adaptation . No , I 'm serious , Yeah . Yeah all we have for some people is digits . Yeah . so we have a problem with acoustic adaptation , and we 're not using the digit data now , but you know {disfmarker} Oh , you 're not . Not for adaptation , nope . v W we 're not {disfmarker} we were running adaptation only on the data that we ran recognition on and I 'd {disfmarker} As soon as someone started to read transcript number , that 's read speech and I thought \" well , we 're gonna do better on that , Oh I see . that 's not fair to use \" . Oh yeah that 's true , absolutely . OK . But , it might be fair to use the data for adaptation , so . So those speakers who are very quiet , {comment} shy {disfmarker} That would be interesting to see whether that helps . r Right {disfmarker} Like Adam ? Do you think that would help adapting on {disfmarker} Yeah . Yeah , I have a real problem with that . Yeah . Well , it sh I mean it 's the same micropho see the nice thing is we have that in the {disfmarker} in the same meeting , Right . Same {disfmarker} same acoustics , Yeah . and so you don't get {disfmarker} same microphone , Yeah . same channel . Right , and so I still like the idea of having some kind of {pause} digit data . OK . Good . Yeah I mean , for the {disfmarker} for the um acoustic research , for the signal - processing , farfield stuff , I see it as {disfmarker} as {disfmarker} as the place that we start . But , th I mean , it 'd be nice to have twenty hours of digits data , but {disfmarker} but uh the truth is I 'm hoping that we {disfmarker} we through the {disfmarker} the stuff that {disfmarker} that you guys have been doing as you continue that , we get , uh , the best we can do on the spontaneous stuff uh , uh nearfield , and then um , we do a lot of the testing of the algorithms on the digits for the farfield , and at some point when we feel it 's mature and we understand what 's going on with it then we {disfmarker} we have to move on to the spontaneous data with the farfield . So . Great . The only thing that we don't have , I know this sounds weird , and maybe it 's completely stupid , but we don't have any overlapping digits . Yeah , we talked about that a couple times . An - yea I know it 's weird , but um {disfmarker} Overlapping digits ! The {disfmarker} the problem I see with trying to do overlapping digits is the cognitive load . Alright everybody 's laughing . OK . Dueling digits . No it 's {disfmarker} it 's not stupid , it 's just {disfmarker} I mean , try to do it . I 'm just talkin for the stuff that like Dan Ellis is gonna try , I mean , here , let 's try it . you know , cross - talk cancellation . You read the last line , I 'll read the first line . Let 's try it . OK . Oh ! Wait {disfmarker} oh it {disfmarker} these are all the same forms . Sixty - one . OK {comment} So but {disfmarker} So {disfmarker} so you read the last line , I 'll read the first line . No , I 'll p So you plu you plug your ears . Oh I guess if you plug you 're ears you could do it , but then you don't get the {disfmarker} the same effects . Yeah . Well , what I mean is actually no not the overlaps that are well - governed linguistically , but the actual fact that there is speech coming from two people Yeah . and the beam - forming stuf all the acoustic stuff that like Dan Ellis and {disfmarker} and company want to do . Oh I see . Digits are nice and well behaved , I mean I guess we could try . Anyway , it 's just a thought . We could try doing some . It {disfmarker} it would go faster . Parallel . It would take one around {comment} amount of ti It 's the P - make of digit reading . Well {disfmarker} Well OK . Well let 's try it . That 's right . I {disfmarker} I mea I 'm {disfmarker} I was sort of serious , but I really , I mean , I 'm {disfmarker} I don't feel strongly enough that it 's a good idea , See , y You do the last line , I 'll do the first line . so . OK . O . {comment} That 's not bad . No , I can do it . I couldn't understand a single thing you guys were saying . A and that prosody was great , by the way . I think it was numbers , but I 'm not sure . It {disfmarker} it sort of sounded like a duet , or something . Yeah . Performance art . Alright , let 's try three at once you {disfmarker} you pick one in the middle . The Aurora theater . OK . Go . I 'm sorry . I 'm mean I think it 's doable , The poor transcribers I 'm just {disfmarker} they 're gonna hate us . So , we {disfmarker} we could have a round like where you do two at a time , and then the next person picks up when the first guy 's done , or something . So pairwise . Oh like a round , yeah , like in a {disfmarker} a {disfmarker} Like a , Yeah , just pairwise , yeah . what do you call it ? or yeah . Round . A round . Row , row , row your boat . Li - a r like {disfmarker} Mm - hmm . Yeah . yeah , like that . OK . It 's gonna require some coordination . Then it would go like h twice as fast , or {pause} a third as fast . You have to have a similar pace . Anyway , it 's just a thought . Yeah . I 'm actually sort of serious if it would help people do that kind o but the people who wanna work on it we should talk to them . I don't think we 're gonna collect vast amounts of data that way , So . Mmm . but I think having a little bit might at least be fun for somebody like Dan to play around with , OK . I think maybe if we wanted to do that we would do it as a separate session , yeah . Yeah . something like that rather than doing it during a real meeting and you know , do two people at a time then three people at a time and things like that . So . Can try it out . See {disfmarker} see what Dan thinks . If we have nothing {disfmarker} if we have no agenda we could do it some week . Yeah , right . Yeah , yeah . Spend the whole time reading digits with different qu quantities . OK . I thought this was gonna be fast . c c Can I can I have an another {disfmarker} another question w about this ? Oh well . So , um , there are these digits , which are detached digits , but there are other words that contain the same general phon phoneme sequences . Like \" wonderful \" has \" one \" in it and {disfmarker} and Victor Borge had a {disfmarker} had a piece on this where he inflated the digits . Well , I wonder if there 's , um , an if there would be a value in having digits that are in essence embedded in real words to compare in terms of like the articulation of \" one \" in \" wonderful \" versus \" one \" as a digit being read . That 's \" two \" bad . Yeah . I 'm all \" four \" it . There you go . Not after I \" eight \" though . Uh , they don't all work as well , do they ? Hmm . What does nine work in ? Nein ! Uh . Uh , You scream it . Nein ! You have to be German , Oh . In German , That 's German , yeah . It 's great for the Germans . yeah . yeah . Oh , oh ! Nein . That 's right ! Yeah . Oh ! It only sounds w good when you scream it , though . So . I think everybody 's a little punchy here {vocalsound} today . Well , I mean , I just wanted to offer that as a possible task Yes . because , you know , if we were to each read his embedded numbers words in sent in sentences cuz it 's like an entire sketch he does and I wouldn't take the inflated version . So he talks about the woman being \" two - derful \" , and {disfmarker} and {disfmarker} a But , you know , if it were to be deflated , just the normal word , it would be like a little story that we could read . Mm - hmm . I don't know if it would be useful for comparison , but it 's embedded numbers . I think for something like that we 'd be better off doing like uh TIMIT . Well I don't know . Well I think the question is what the research is , so I mean , I presume that the reason that you wanted to have these digits this way is because you wanted to actually do some research looking at the prosodic form here . Hmm . Yeah OK . Right , yeah . So if somebody wanted to do that , if they wanted to look at the {disfmarker} the {disfmarker} the difference of the uh phones in the digits in the context of a word versus uh the digits {disfmarker} a {disfmarker} a non - digit word versus in digit word , uh that would be a good thing to do , but I think someone would have to express interest in that . I see . OK . I think , to {disfmarker} I mean if you were interested in it then we could do it , for instance . OK , thank you . OK , are we done with digits ? Huh . Um , We have ASR results from Liz , transcript status from Jane , and disk space and storage formats from Don . Does {disfmarker} do we have any prefer preference on which way we wanna {disfmarker} we wanna go ? Well I was actually gonna skip the ASR results part , in favor of getting the transcription stuff talked about Mm - hmm . since I think that 's more important to moving forward , but I mean Morgan has this paper copy and if people have questions , um , it 's pretty preliminary in terms of ASR results because we didn't do anything fancy , but I think e just having the results there , and pointing out some main conclusions like it 's not the speaking style that differs , it 's the fact that there 's overlap that causes recognition errors . And then , the fact that it 's almost all insertion errors , which you would expect but you might also think that in the overlapped regions you would get substitutions and so forth , um , leads us to believe that doing a better segmentation , like your channel - based segmentation , or some kind of uh , echo cancellation to get basically back down to the individual speaker utterances would be probably all that we would need to be able to do good recognition on the {disfmarker} on the close - talking mikes . So these {disfmarker} Um , why don't you , if you have a hard copy , why don't you email it to the list . So , that 's about the summary {disfmarker} But this is {disfmarker} Morgan has this paper . Yeah , yeah . Oh it 's in the paper . Yeah , so it 's the same thing ? I mean he {disfmarker} he {disfmarker} It 's the same thing I mailed to every everybody that w where it was , it {disfmarker} it 's that paper . OK . Yeah , yeah . OK then , it 's already been mailed . So , we basically , um , did a lot of work on that yeah . and it 's {disfmarker} Let 's see , th I guess the other neat thing is it shows for sure w that the lapel , you know within speaker is bad . Horrible ? And it 's bad because it picks up the overlapping speech . So , your {disfmarker} your ASR results were run on the channels synchronized , Yes , cuz that 's all that w had been transcribed at the time , OK . OK . OK . um but as we {disfmarker} I mean I wanted to here more about the transcription . If we can get the channel asynchronous or the {disfmarker} Yeah . the closer t that would be very interesting for us So if {disfmarker} because we {disfmarker} Yeah , that 's {disfmarker} that 's why I only used the part from use Yeah . which we had uh about uh about the alt over all the channels Yeah . Right . That 's {disfmarker} Yeah sure . Yeah . or mixed channel Yeah . rather mixed signal . So if there was a segment of speech this long cuz {disfmarker} Yeah . and oh and someone said \" oh , \" the whole thing was passed to the recognizer ? And someone said \" oh \" in the front {disfmarker} in the middle . There were several speakers in it , yeah . That 's right . In fact I {disfmarker} I pulled out a couple classic examples in case you wanna u use them in your talk of That 's why there 's so many insertion errors ? Mm - hmm . Chuck on the lapel , so Chuck wore the lapel three out of four times . Mmm . I noticed that Chuck was wearing the lapel a lot . Early on , yeah . Um , yeah , and I wore the lapel once , and for me the lapel was OK . I mean I still {disfmarker} and I don't know why . I 'm {disfmarker} But um , Probably how you wear it {disfmarker} wore it I would guess . for you it was {disfmarker} Or who was next to me or something like that . Yeah , where you were sitting probably affected it . Yeah . Right , but when Chuck wore the lapel and Morgan was talking there 're a couple really long utterances where Chuck is saying a few things inside , and it 's picking up all of Morgan 's words pretty well and so the rec you know , there 're error rates because of insertion {disfmarker} Insertions aren't bounded , so with a one - word utterance and ten insertions you know you got huge error rate . Uh - huh . Yeah . And that 's {disfmarker} that 's where the problems come in . So I this is sort of what we expected , but it 's nice to be able to {disfmarker} to show it . Right . And also I just wanted to mention briefly that , um , uh Andreas and I called up Dan Ellis who 's still stuck in Switzerland , and we were gonna ask him if {disfmarker} if there 're {disfmarker} you know , what 's out there in terms of echo cancellation and things like that . Not that we were gonna do it , but we wanted to know what would need to be done . And he said , \" Lots lots lots lots . \" And he {disfmarker} We 've given him the data we have so far , so these sychronous cases where there are overlap . Yep . And he 's gonna look into trying to run some things that are out there and see how well it can do So {disfmarker} because right now we 're not able to actually report on recognition in a real paper , like a Eurospeech paper , because it would look sort of premature . So {disfmarker} So the idea is that you would take this big hunk where somebody 's only speaking a small amount in it , and then try to figure out where they 're speaking {comment} based on the other peopl Right . Or who 's {disfmarker} At any point in time who 's the foreground speaker , who 's the background speaker . So yeah {disfmarker} I thought we were just gonna move the boundaries in . Yeah , should it {disfmarker} So . Well that 's with the hand stuff . So there 's like {disfmarker} But how would you do that automatically ? Well ther there 's {disfmarker} Uh , I 've actually done some experiments with cross - correlation Right . and it seems to work pretty well to {disfmarker} to get rid of those {disfmarker} those overlaps , I mean that that 's the sort of thing that you would do . Mm - hmm . Yeah . yeah . So . Yeah . Exactly , so it 's {disfmarker} it 's a {disfmarker} So why do you want to do echo cancellation ? Um , it would be techniques used from adaptive {disfmarker} adaptive echo cancellation which I don't know enough about to talk about . Uh - huh . It {disfmarker} just {disfmarker} it just to r to remove cross - talk . Um . Yeah . Yeah . But , right , um , and that would be similar to what you 're also trying to do , but using um , you know , more than energy {disfmarker} Yeah . I {disfmarker} I don't know what exactly would go into it . Yeah , sure . So it would be {disfmarker} So the idea is to basically run this on the whole meeting . and get the locations , which gives you also the time boundaries of the individual speak OK . So do sort of what he 's already {disfmarker} what he 's trying to do . Right . Except that there are many techniques for the kinds of cues , um , that you can use to do that . Yeah , in another way , OK , I s I see . yeah . Yeah . Yeah . I see . Yeah , Dave {disfmarker} Dave uh is , um , also gonna be doin usin playing around with echo cancellation for the nearfield farfield stuff , So . so we 'll be {disfmarker} And I guess Espen ? This {disfmarker} is {disfmarker} uh {disfmarker} is he here too ? Yeah . May also be working {disfmarker} So it would just be ver that 's really the next step because we can't do too much , you know , on term in terms of recognition results knowing that this is a big problem Mm - hmm . um , until we can do that kind of processing . And so , once we have some {disfmarker} some of yours , OK . Yeah I 'm working on it . and @ @ we 'll move on . I think this also ties into one of the things that Jane is gonna talk about too . Um , OK . I also wanted to say I have done all this chopping up of digits , Mm - hmm . Mm - hmm . so I have some naming conventions that we should try to agree on . So let 's do that off - line , Oh right . we don't need to do it during the meeting . Yeah . OK . Right . Definitely {disfmarker} And {disfmarker} and I have scripts that will extract it out from \" key \" files Uh , and Don should {disfmarker} and {disfmarker} and do all the naming automatically , OK . Alright . so you don't have to do it by hand . Great . You 've compiled the list of , uh , speaker names ? So that that 's it for the {disfmarker} Mm - hmm . Speakers and {disfmarker} OK . Not names , but I Ds . Yep . Yeah , names {disfmarker} names in the {disfmarker} names to I Ds , OK . so you Great . and it does all sorts of matches because the way people filled out names is different on every single file so it does a very fuzzy sort of match . Right . Cool . So at this point we can sort of finalize the naming , and so forth , Mm - hmm . Yep . and we 're gonna basically re rewrite out these waveforms that we did because as you notice in the paper your \" M O in one meeting and \" M O - two \" in another meeting and it 's {disfmarker} we just need to standardize the Yeah . That was my fault . um , no it 's {disfmarker} it 's {disfmarker} No , I didn't notice that actually .  um , that 's why those comments are s {vocalsound} are in there . Yeah . Then disregard it then . Yep . So th I now have a script that you can just say basically look up Morgan , So {disfmarker} Yeah . Right . OK . and it will give you his ID . Great , great . OK . So . Um , Terrific . alright . Do we {disfmarker} Don , you had disk space and storage formats . Is that something we need to talk about at the meeting , or should you just talk with Chuck at some other time ? Um , I had some general questions just about the compression algorithms of shortening waveforms and I don't know exactly who to ask . I thought that maybe you would be the {disfmarker} the person to talk to . So , is it a lossless compression {comment} when you compress , Mm - hmm . so {disfmarker} Entropy coding . It just uses entropy coding ? So . OK . So , I mean , I guess my question would be is I just got this new eighteen gig drive installed . Um , yeah , which is {disfmarker} And I assume half of it is scratch and half of it is {disfmarker} ? I 'm not exactly sure how they partitioned it . Probably , yeah . But um , That 's typical , huh . yeah , I don't know what 's typical here , but um , it 's local though , so {disfmarker} That doesn't matter . But {disfmarker} You can access it from anywhere in ICSI . N {disfmarker} OK . Alright . How do you do that ? In fact , this is an eighteen gig drive , {comment} or is it a thirty six gig drive with eighteen {disfmarker} N {disfmarker} Eighteen . Eigh - eighteen . It was a spare that Dave had around {disfmarker} Slash N slash machine name , slash X A in all likelihood . Oh OK . Oh I see . OK . Alright , I did know that . Um , so the {disfmarker} the only question is how much of it {disfmarker} The distinction between scratch and non - scratch is whether it 's backed up or not . Mm - hmm . Right . So what you wanna do is use the scratch for stuff that you can regenerate . OK . So , the stuff that isn't backed up is not a big deal because disks don't crash very frequently , Right . as long as you can regenerate it . Right . I mean all of this stuff can be regenerated , Yeah it 's {disfmarker} it 's just a question {disfmarker} Then put it all on scratch Well the {disfmarker} because we 're {disfmarker} ICSI is {disfmarker} is bottlenecked by backup . Mm - hmm , very good point . Yeah . OK . So we wanna put {disfmarker} Well I 'd leave all the {disfmarker} All the transcript stuff shouldn't {disfmarker} should be backed up , Mm - hmm . but all the waveform {disfmarker} {comment} Sound files should not be backed up , Yeah , I guess {disfmarker} Right . the ones that you write out . OK . So , I mean , I guess th the other question was then , should we shorten them , downsample them , or keep them in their original form ? Um {disfmarker} It just depends on your tools . I mean , because it 's not backed up and it 's just on scratch , if your sc tools can't take shortened format , I would leave them expanded , Right . so you don't have to unshorten them every single time you wanna do anything . OK . We can downsample them , Do you think that 'd be OK ? so . To downsample them ? Yeah . Yeah , we get the same performance . OK . I mean the r the front - end on the SRI recognizer just downsamples them on the fly , Yeah , I guess the only argument against downsampling is to preserve just the original files in case we want to experiment with different filtering techniques . so {disfmarker} So that 's {disfmarker} I {disfmarker} I {disfmarker} I 'm sorry {disfmarker} Yeah , if Yeah , l I mean over all our data , we {disfmarker} we want to not downsample . fe You 'd {disfmarker} you wanna not . OK . Yeah . So we 're {disfmarker} what we 're doing is we 're writing out {disfmarker} I mean , this is just a question . We 're writing out these individual segments , that wherever there 's a time boundary from Thilo , or {disfmarker} or Jane 's transcribers , you know , we {disfmarker} we chop it {pause} there . Yeah . Mm - hmm . And the reason is so that we can feed it to the recognizer , Mm - hmm . and throw out ones that we 're not using and so forth . Yeah . And those are the ones that we 're storing . Yeah , as I said , since that 's {disfmarker} it 's regeneratable , what I would do is take {disfmarker} downsample it , So {disfmarker} Yeah . and compress it however you 're e the SRI recognizer wants to take it in . Yeah . ye So we can't shorten them , Right . but we can downsample them . Yeah , I mean {disfmarker} yeah , I 'm sorry . So . As {disfmarker} yeah , as long as there is a {disfmarker} a form that we can come from again , that is not downsampled , {comment} then , r Yeah . Oh yeah th Yeah those are gonna be kept . Yeah . Yeah . That {disfmarker} that 's why we need more disk space uuu cuz we 're basically duplicating the originals , um {disfmarker} Yeah . Right . Then it 's fine . But for {disfmarker} for {disfmarker} fu future research we 'll be doing it with different microphone positions and so on Oh yeah . Right . Yep . No . We always have the original long ones . we would like to {disfmarker} So the SRI front - end won't take a uh {disfmarker} an {disfmarker} an {disfmarker} a large audio file name and then a {disfmarker} a list of segments to chop out {comment} from that large audio file ? Yeah . They actually have to be chopped out already ? Um , it 's better if they 're chopped out , Uh - huh . and {disfmarker} and it {disfmarker} it will be {disfmarker} yeah , y we could probably write something to do that , but it 's actually convenient to have them chopped out cuz you can run them , you know , in different orders . You c you can actually move them around . And that 's the whole point about the naming conventions Uh , you can get rid of is that you could run all the English speaking , Yeah , it it 's a lot faster . all the native speakers , and all the non - native speakers , Right . You can grab everything with the word \" the \" in it , and all the men , and all the women . Yeah . and it 's {disfmarker} That 's a lot quicker than actually trying to access the wavefile each time , find the time boundaries and {disfmarker} So in principle , yeah , you could do that , I don't {disfmarker} I don't think that 's really right . but it 's {disfmarker} but it 's um {disfmarker} \" That 's just not right , man . \" The {disfmarker} the point {disfmarker} These are long {disfmarker} These are long {disfmarker} So {disfmarker} so s For example , what if you wanted to run {disfmarker} run all the native speakers . You know . This is an hour of speech . Right , so if {disfmarker} if you did it that way you would have to generate a program that looks in the database somewhere , extracts out the language , finds the time - marks for that particular one , do it that way . The way they 're doing it , you have that already extracted and it 's embedded in the file name . And so , you know , you just say {disfmarker} We - yeah that 's {disfmarker} so that 's part of it y so you just say you know \" asterisk E asterisk dot wave \" , and you get what you want . is {disfmarker} Right . And the other part is just that once they 're written out it {disfmarker} it is a lot faster to {disfmarker} to process them . Rather than doing seeks through the file . So . Otherwise , you 're just accessing {disfmarker} This is all just temporary access , so I don't {disfmarker} I think {disfmarker} it 's all just {disfmarker} It 's fine . You know . Fine to do it however is convenient . Right . I mean it just depends how big the file is . If the file sits in memory you can do extremely fast seeks Right . The other thing is that , believe it or not {disfmarker} I mean , we have some {disfmarker} but . Yeah and they don't . Two gig ? So we 're also looking at these in Waves like for the alignments and so forth . You can't load an hour of speech into X Waves . Yeah . You need to s have these small files , and in fact , even for the Transcriber program Um {disfmarker} Yes you can . Yeah , you {disfmarker} you can give Waves a start and an end time . And middle . Yeah , if you try to load s really long waveform into X Waves , you 'll be waiting there for {disfmarker} No , I {disfmarker} I 'm not suggesting you load a long wave file , Oh I 'm just saying you give it a start and an end time . And it 'll just go and pull out that section . I th w The transcribers didn't have any problem with that did they Jane ? What 's th u w in what respect ? Loading the long {disfmarker} No , with the Transcriber tool , it 's no problem . They loaded {disfmarker} they loaded the long long files into X Waves . It takes a very long ti Yeah just to load a transcription In the {disfmarker} in Mm - hmm .  Right . takes a long time , It takes a l very long time . but not for the wavefile . The wavefile is there immediately . Mm - hmm . Yeah . Are you talking about Transcriber or X Waves ? Huh . Yeah . Oh , I 'm tr talking about Transcriber . Actually , you 're talking about Transcriber , right ? Yeah . Because {disfmarker} because i we used X Waves to do the digits . It was also true of the digits task which was X Waves . And they were loading the full mixed files then , Yeah . Very quickly . and it didn't seem to be any problem . I agree . Huh . Well we {disfmarker} we have a problem with that , you know , time - wise on a {disfmarker} It - it 's a lot slower to load in a long file , Hmm . Seemed really fast . and also to check the file , so if you have a transcript , um , Well regardless , it 's {disfmarker} Yeah . I mean it 's {disfmarker} I {disfmarker} I think overall you could get everything to work by accessing the same waveform and trying to find two {disfmarker} you know , the begin and end times . Um , but I think it 's more efficient , if we have the storage space , to have the small ones . and , it 's no problem , right ? Yeah , it 's {disfmarker} Because it 's not backed up . Yeah . So we just {disfmarker} It 's {disfmarker} it 's just {disfmarker} If we don't have a spare disk sitting around we go out and we buy ourselves an eighty gigabyte drive and make it all scratch space . You know , it 's not a big deal . You 're right about the backup being {pause} a bottleneck . Right . It 's good to think towards scratch . Yeah , so these wouldn't be backed up , the {disfmarker} Yeah . Yep . Right . So remind me afterward And {disfmarker} and I 'll {disfmarker} and we 'll look at your disk and see where to put stuff . OK . Alright . I mean , I could just u do a DU on it right ? And just see which {disfmarker} how much is on each {disfmarker} So . Yep . Each partition . And you wanna use , either XA or scratch . OK . Well X question mark , anything starting with X is scratch . OK . With two {disfmarker} two digits . Two digits , right , XA , XB , XC . OK ? So , @ @ . Jane ? OK . So I got a little print - out here . So three on this side , three on this side . And I stapled them . OK . Alright so , first of all , um , there was a {disfmarker} an interest in the transcribe transcription , uh , checking procedures and {disfmarker} {vocalsound} and I can {vocalsound} tell you first , uh , to go through the steps although you 've probably seen them . Um , as you might imagine , when you 're dealing with , um , r really c a fair number of words , and uh , @ @ {comment} natural speech which means s self - repairs and all these other factors , that there 're lots of things to be , um , s standardized and streamlined and checked on . And , um , so , I did a bunch of checks , and the first thing I did was obviously a spell - check . And at that point I discovered certain things like , um , \" accommodate \" with one \" M \" , that kind of thing . And then , in addition to that , I did an exhaustive listing of the forms in the data file , which included n detecting things like f faulty punctuation and things {disfmarker} I 'm {disfmarker} I 'm sorry to interrupt Yeah ? you could {disfmarker} could I just back up a little bit Sure , please , and {disfmarker} yeah , please , please . So you 're doing these {disfmarker} So {pause} the whole process is that the transcribers get the conversation Yeah , yeah , yeah . and they do their pass over it . Yes . And then when they 're finished with it , it comes to you , That 's right . and you begin these sanit these quality checks . Exactly . I do these checks . OK . Uh - huh . OK . Exactly . Yeah . Thank you . And so , uh , I do a {disfmarker} an exhaustive listing of the forms {disfmarker} Actually , I will go through this in {disfmarker} in order , so if {disfmarker} if we could maybe wait and stick keep that for a second cuz we 're not ready for that . So on the fifth page , seven down {disfmarker} Yeah , yeah , yeah , yeah . Exactly ! Exactly ! Alright so , {vocalsound} a spelling check first then an exhaustive listing of the , uh {disfmarker} all the forms in the data with the punctuation attached and at that point I pick up things like , oh , you know , word followed by two commas . And th and then another check involves , uh , being sure that every utterance has an identifiable speaker . And if not , then that gets checked . Then there 's this issue of glossing s w so - called \" spoken - forms \" . So there {disfmarker} mo for the most part , we 're keeping it standard wo word level transcription . But there 's {disfmarker} w And that that 's done with the assumption that {pause} pronunciation variants can be handled . So for things like \" and \" , the fact that someone doesn't say the \" D \" , uh that 's not important enough to capture in the transcription because a {disfmarker} a good pronunciation , uh , you know , model would be able to handle that . However , things like \" cuz \" where you 're lacking an entire very prominent first syllable , and furthermore , it 's a form that 's specific to spoken language , those are r reasons {disfmarker} f for those reasons I {disfmarker} I kept that separate , and used the convention of using \" CUZ \" for that form , however , glossing it so that it 's possible with the script to plug in the full orthographic form for that one , and a couple of others , not many . So \" wanna \" is another one , \" going {disfmarker} \" uh , \" gonna \" is another one , with just the assumption , again , that this {disfmarker} th these are things which it 's not really fair to a c consider {disfmarker} expect that {disfmarker} a pronunciation model , to handle . And Chuck , you in you indicated that \" cuz \" is {disfmarker} is one of those that 's handled in a different way also , didn't you ? Did I {disfmarker} I don't remember . OK . So {disfmarker} so it might not have been {disfmarker} {vocalsound} It might not have been you , Hmm . but someone told me that in fact \" cuz \" is treated differently in , um , i u in this context because of that r reason that , um , it 's a little bit farther than a pronunciation variant . OK , so after that , let 's see , So that was part of the spell - check , {comment} or was that {disfmarker} that was after the spell - check ? um . Well so when I get the exhau So the spell - check picks up those words because they 're not in the dictionary . Uh - huh . So it gets \" cuz \" and \" wanna \" and that {disfmarker} And then you gloss them ? Yeah , mm - hmm . Run it through {disfmarker} I have a sed {disfmarker} You know , so I do sed script saying whenever you see \" gonna \" you know , \" convert it to gonna \" , you know , \" gloss equals quote going - to quote \" , you know . And with all these things being in curly brackets Mm - hmm . so they 're always distinctive . OK , I also wrote a script which will , um , retrieve anything in curly brackets , {vocalsound} or anything which I 've classified as an acronym , and {disfmarker} a pronounced acronym . And the way I tag ac pronounced acronyms is that I have underscores between the components . So if it 's \" ACL \" then it 's \" A \" underscore \" C \" underscore \" L \" . And so {disfmarker} so your list here , are these ones that actually occurred in the meetings ? And the th Yes . Uh - huh , yeah . Whew ! OK , so now . Uh and {disfmarker} a We are acronym - loaded . Um , can I ask a question about the glossing , uh before we go on ? Yeah . So , for a word like \" because \" is it that it 's always predictably \" because \" ? I mean , is \" CUZ \" always meaning \" because \" ? Yes , but not the reverse . So sometimes people will say \" because \" in the meeting , and if {disfmarker} if they actually said \" because \" , then it 's written as \" because \" with no {disfmarker} w \" cuz \" doesn't even figure into the equation . But {disfmarker} but in our meetings people don't say \" hey cuz how you doing ? \" Beca - because {disfmarker} Right . {comment} {vocalsound} Right . Except right there . Yeah . Yeah . Um , so , I guess {disfmarker} So , from the point of view of {disfmarker} That 's a good point . The {disfmarker} the only problem is that with {disfmarker} for the recognition we {disfmarker} we map it to \" because \" , Well , and so if we know that \" CUZ \" {disfmarker} That 's fine . but they have the gloss . Well Don has a script . Yeah . but , we don't {disfmarker} You have the gloss form so you always replace it . Exactly . If that 's how {disfmarker} what you wanna do . Uh - huh . And Don knows this , Yeah . and he 's bee he has a glo he has a script that {disfmarker} I replace the \" cuz \" with \" because \" if it 's glossed . S Right . But , if it 's {disfmarker} OK . And {disfmarker} But then there are other glosses that we don't replace , right ? Because {disfmarker} Yes . And that 's why there 're different tags on the glosses , OK . So , then it 's fine . on the different {disfmarker} on the different types of comments , which we 'll {disfmarker} which we 'll see in just a second . Right . OK . So the pronounceable acronyms get underscores , the things in curly brackets are viewed as comments . There 're comments of four types . So this is a good time to introduce that . The four types . w And maybe we 'll expand that Um {disfmarker} but the {disfmarker} but the comments are , um , of four types mainly right now . One of them is , um , the gloss type we just mentioned . Can {disfmarker} ca Another type is , um {disfmarker} So a are we done with acronyms ? Cuz I had a question on what {disfmarker} what this meant . I 'm still doing the overview . I haven't actually gotten here yet . Oh I 'm sorry . OK so , gloss is things like replacing the full form u with the , um , more abbreviated one to the left . Uh , then you have if it 's {disfmarker} uh , there 're a couple different types of elements that can happen that aren't really properly words , and wo some of them are laughs and breathes , so we have {disfmarker} uh that 's prepended with a v a tag of \" VOC \" . Whew !  And the non - vocal ones are like door - slams and tappings , and that 's prepended with a no non - vocalization . So then it {disfmarker} just an ending curly brace there , or is there something else in there . Oh yeah , so i e this would {disfmarker} A comment , basically . Let 's just take one example . Oh , oh , oh . And then the no non - vocalization would be something like a door - slam . They always end . So it 's like they 're paired curly brackets . And then the third type right now , {vocalsound} uh , is {pause} m things that fall in the category of comments about what 's happening . So it could be something like , you know , \" referring to so - and - so \" , \" talking about such - and - such \" , uh , you know , \" looking at so - and - so \" . So on the m Yeah . on the middle t So , in the first case that gloss applies to the word to the left . But in the middle two {disfmarker} Th - it 's not applying to anything , right ? Yeah , and this gets substituted here . They 're impulsive . OK . Huh - uh . No , they 're events . OK . Well the \" QUAL \" can be {disfmarker} The \" QUAL \" is applying to the left . They 're actually {disfmarker} They have the status of events . Right , I just meant the middle two ones , yeah . Yep . Well , and actually , um , it is true that , with respect to \" laugh \" , there 's another one which is \" while laughing \" , \" While laughing \" . and that is , uh , i i An argument could be made for this {disfmarker} tur turning that into a qualitative statement because it 's talking about the thing that preceded it , but at present we haven't been , um , uh , coding the exact scope of laughing , you know , and so to have \" while laughing \" , you know that it happened somewhere in there which could well mean that it occurred separately and following , or , you know , including some of the utterances to the left . Haven't been awfully precise about that , but I have here , now we 're about to get to the {disfmarker} to this now , I have frequencies . So you 'll see how often these different things occur . But , um , uh , the very front page deals with this , uh , final c pa uh , uh , aspect of the standardization which has to do with the spoken forms like \" mm - hmm \" and \" mm - hmm \" and \" ha \" and \" uh - uh \" and all these different types . And , um , uh , someone pointed out to me , this might have been Chuck , {comment} about , um {disfmarker} about how a recognizer , if it 's looking for \" mm - hmmm \" with three M 's , {vocalsound} and it 's transcribed with two M 's , {vocalsound} that it might {disfmarker} uh , that it might increase the error rate which is {disfmarker} which would really be a shame because um , I p I personally w would not be able to make a claim that those are dr dramatically different items . So , right now I 've standardized across all the existing data with these spoken forms . Oh good . I {disfmarker} I should say So it 's a small list . all existing data except thirty minutes which got found today . So , I 'm gonna {disfmarker} {vocalsound} I 'm gonna {disfmarker} {vocalsound} I 'm gonna check {disfmarker} That {disfmarker} that 's known as \" found data \" . Yeah , yeah . Acsu - actually yeah . I got {disfmarker} It was stored in a place I didn't expect , It 's like the z Zapruder Film . so {disfmarker} and {disfmarker} and um , w we , uh , sh yea reconstructed how that happened . I wanna work with lost data . Yeah . It 's much easier . And this is {disfmarker} this 'll be great . So I 'll {disfmarker} I 'll be able to get through that tonight , and then everyth i well , actually later today probably . Hmm . And so then we 'll have everything following these conventions . But you notice it 's really rather a small set of these kinds of things . Yeah . And I made it so that these are , um , with a couple exceptions but , things that you wouldn't find in the spell - checker so that they 'll show up really easily . And , um {disfmarker} Jane , can I ask you a question ? What 's that very last one correspond to ? Sure . I don't even know how to pronounce that . Well , yeah . Now that {disfmarker} that s only occurs once , Yeah . and I 'm thinking of changing that . Right . Uh , is that like someone 's like burning or some such thing ? So - c I haven't listened to it so I don't know . Like their hair 's on fire ? I haven't heard it actually . I n I need to listen to that one . Ah ! It 's the Castle of Ah ! Actually we {disfmarker} we gave this to our pronunciation person , Uh , it looks like that . she 's like , \" I don't know what that is either \" . So . Did she hear the th did she actually hear it ? Cuz I haven't heard it . No , we just gave her a list of words that , you know , weren't in our dictionary and so of course it picked up stuff like this , and she just didn't listen so she didn't know . We just {disfmarker} we 're waiting on that {pause} just to do the alignments . Yeah . Yeah I 'm curious to se hear what it is , but I didn't know {disfmarker} wanna change it to something else until I knew . Right . Maybe it 's \" argh \" ? Well , sss , {comment} you know {disfmarker}  But that 's not really like {disfmarker} Hhh . No one really says \" argh , \" you know ,  Yeah . Right , no one say it 's not {disfmarker} Well , you just did . Except for now ! Well , there 's another {disfmarker} there 's another word error .  Yeah . That 's right . Yes , that 's right . We 're gonna have a big problem when we talk about that . Cha - ching . Ah . We 're gonna never recognize this meeting . In Monty Python you say \" argh \" a lot . OK . Oh yeah ? So . Well , or if you 're a C programmer . Mmm . You say arg - C and arg - V all the time . Yeah , that 's right . Yeah . That 's right . That 's true . Yeah . Yeah But it has a different prosody . Arg . It does . Mm - hmm . Arg {disfmarker} arg - max , arg - min , yeah . Ah ! Uh , So , Jane , what 's the {disfmarker} d Maybe he died while dictating . so . I have one question about the the \" EH \" versus like the \" AH \" and the \" UH \" . That 's partly a nonnative - native thing , OK . but I have found \" EH \" in native speakers too .  But it 's mostly non - native {disfmarker} H That 's \" eh \" versus \" ah \" ? S OK . Eh . Eh ? \" Eh , \" yeah right , cuz there were {disfmarker} were some speakers that did definite \" eh 's \" Mm - hmm . but right now we {disfmarker} They were the Canadians , right ? Canadians , yeah , yeah , yeah . That 's right . So , it {disfmarker} it 's actually probably good for us to know the difference between the real \" eh \" and the one that 's just like \" uh \" or transcribed \" aaa \" Exactly . cuz in {disfmarker} like in Switchboard , you would see e all of these forms , but they all were like \" uh \" . You mean just the single letter \" a \" {comment} as in the particle ? The transcription or {disfmarker} Article . No , no , I mean like the {disfmarker} the \" UH \" , \" UH \" . Oh . or {disfmarker} the \" UH \" , \" EH \" , \" AH \" were all the same . And then , we have this additional non - native version of {disfmarker} uh , like \" eeh \" . All the \" EH \" 's I 've seen have been like that . They 've been like \" eh \" like that have bee has been transcribed to \" EH \" . And sometimes it 's stronger , Mm - hmm , that 's right . like \" eeh \" {comment} which is like closer to \" EH \" . Mmm . Right . But . I 'm just {disfmarker} these poor transcribers , they 're gonna hate this meeting . Yeah . I know . We should go off - line . Well , {vocalsound} we 're not doing {disfmarker} We 're not doing length . Quick Thilo , do a {disfmarker} do a filled pause for us . Yeah , that 's right . Ooo {comment} no . But you 're a native German speaker so it 's not a {disfmarker} not a issue for {disfmarker} Yeah . It 's only {disfmarker} Them Canadians . Onl yeah . No , only if you don't have lax vowels , I guess . Oh . Right . This makes sense . So it 's {disfmarker} like Japanese and Spanish Yeah I {disfmarker} I think you 've {disfmarker} uh - huh , yeah . Oh I see . Uh - huh . and {disfmarker} I didn't get that , That makes sense . OK . Yeah , and so , you know , I mean , th th I have {disfmarker} there are some , um , Americans who {disfmarker} who are using this \" eh \" too , and I haven't listened to it systematically , maybe with some of them , uh , they 'd end up being \" uh 's \" but , uh , I my spot - checking has made me think that we do have \" eh \" in also , um , American e e data represented here . But any case , that 's the {disfmarker} this is reduced down from really quite a long a much longer list , Yeah this is great . Mm - hmm . Yeah , it 's good , and this is yeah . This is really really helpful . functionally pretty , you know , also {disfmarker} It was fascinating , I was listening to some of these , uh , I guess two nights ago , and it 's just hilarious to liste to {disfmarker} to do a search for the \" mm - hmm 's \" . And you get \" mm - hmm \" and diff everybody 's doing it . And just listen to them ? Yeah . Just {disfmarker} I wanted to say {disfmarker} I w think it would be fun to make a montage of it because there 's a \" Mm - hmm . Mm - hmm . Performance art , Mm - hmm . \" just extract them all . Right . It 's really {disfmarker} it 's really fun to listen to . Morgan can make a song out of it . All these different vocal tracts , you know , but it 's {disfmarker} it 's the same item . It 's very interesting . OK . Uh , then the acronyms y and the ones in parentheses are ones which the transcriber wasn't sure of , Oh I see . and I haven't been able to listen to to {disfmarker} to clarify , but you can see that the parenthesis convention makes it very easy to find them o How about question mark ? cuz it 's the only place where {disfmarker} where they 're used . The question marks , yeah . What are those ? Question mark is punctuation . So it {disfmarker} they said that @ @ {disfmarker} Mm - hmm . Oh . um , \" DC ? \" Ah . So they {disfmarker} so it 's \" PLP ? \" Exactly . Exactly . Yeah , so the only {disfmarker} Well , and I do have a stress marker here . Sometimes the contrastive stress is showing up , and , um {disfmarker} I 'm sorry , I {disfmarker} I got lost here . What - w what 's the difference between the parenthesized acronym and the non - parenthesized ? The parenthesized is something that the transcriber thought was ANN , but wasn't entirely sure . So I 'd need to go back or someone needs to go back , and say , you know , yes or no , Ah . and then get rid of the parentheses . Right . But the parentheses are used only in that context in the transcripts , of of noti noticing that there 's something uncertain . Yeah , P - make is {disfmarker} Yeah I mean cuz they {disfmarker} they have no idea , That 's a good one . That 's correct . right . If you hear CTPD , I mean , they do pretty well Yeah . Mm - hmm . but it 's {disfmarker} I {disfmarker} I don't recognize a lot of these . you know how are {disfmarker} how are they gonna know ? Yeah . I know ! I {disfmarker} I was saying that I think a lot of them are the Networks meeting . I {disfmarker} I think that 's true . Maybe . Yeah , absolutely . I see a few . NSA , Yeah . a lot of these are {disfmarker} are coming from them . I listened to some of that . Yeah , we don't have that many acronyms comparatively in this meeting . Although I see {disfmarker} I see plenty of uh Yeah . Yeah . I agree . It 's not so bad . Right . And Robustness has a fair amount , Yeah . Mmm . but the NSA group is just very very many . The recognizer , it is funny . Kept getting PTA for PDA . Yeah , that 's pretty close . Yeah . This is close , right , That 's not bad . and the PTA was in these , uh , topics about children , Yeah . so , anyway . That 's interesting . Is the P - PTA working ? Right and sometimes , I mean , you see a couple of these that are actually \" OK 's \" so it 's {disfmarker} it 's {disfmarker} may be that they got to the point where {disfmarker} I mean it was low enough understandable {disfmarker} understandability that they weren't entirely sure the person said \" OK . \" You know , so it isn't really necessarily a an undecipherable acronym , There 's a lot of \" OK 's \" . but just n needs to be double checked . Now we get to the comments . This {disfmarker} The number to the left is the number of incidences ? Count . Yep . Number of times out of the entire database , Uh - huh . w except for that last thirty minutes I haven't checked yet . So CTS is really big here , Yeah , I wonder what it is . yeah . Yeah . So what is the difference between \" papers rustling \" and \" rustling papers \" ? IP , I know what IP is . I 'd have to listen . I {disfmarker} I I agree . I w I 'd like to standardize these down farther but , um , uh , uh , to me that sounds equivalent . Yeah . But , I {disfmarker} I 'm a little hesitant to {disfmarker} to collapse across categories unless I actually listen to them . Seems so . OK . Oh I 'm sure we 've said XML more than five times . Well , then , at least now . Now it 's at least six times , yeah . S s six now , yeah . Yeah . Six . OK well {disfmarker} Wh - the self - referential aspect of these {disfmarker} these p I 'm wai Yeah . Yes , it 's very bad . Well this is exactly how people will prove that these meetings do differ because we 're recording , right ? Yes . Y no normally you don't go around saying , \" Now you 've said it six times . Yeah {comment} that 's right . Now you 've said \" But did you notice that there were seven hundred and eighty five instances of \" OK \" ? Seven hundred eighty - five instances . And that 's just without the {disfmarker} without punc punctuation . Yeah . Yep . No , I didn't . Yeah . And that 's an underestimate Extra forty one if it 's questioned . Where 's that ? cuz they 're Yep . So th On the page two of acronyms . Is this after {disfmarker} like did you do some uh replacements for all the different form of \" OK \" to this ? Yeah . Seven hundred eighty . Yeah . Of \" OK \" , yes . OK . Mm - hmm . So that 's the single existing convention for \" OK \" . Wait a minute , w s So now we 're up to seven hundred and eighty eight . Yeah that 's {disfmarker} Although , what 's {disfmarker} there 's one with a slash after it . That 's kind of disturbing . Yeah . Yeah , we 'll have to look at it you know . That 's {disfmarker} that 's {disfmarker} I looked for that one . Yeah . Anyway . I actually explicitly looked for that one , Mm - hmm . and I think that , um , I {disfmarker} I 'm not exactly sure about that . Was that somewhere where they were gonna say \" new speaker \" or something ? No , I looked for that , but that doesn't actually exist . And it may be , I don't {disfmarker} I can't explain that . That 's alright . I 'm just pointing that out . I i it 's the only {disfmarker} There 's {disfmarker} it 's the only pattern that has a slash after it , and I think it 's {disfmarker} it 's an epiphenomenon . Well there 's not @ @ . So I 'll just {disfmarker} I was just looking at the bottom of page three there , is that \" to be \" or \" not to be \" . Yeah . There 's no tilde in front of it , Oh that 's cute . so . That 's funny . Yeah . OK anyways , sorry . OK . \" Try to stay on topic , Adam . \" There is th one {disfmarker} Y well , no , that 's r that 's legitimate . So now , uh , comments , you can see they 're listed again , same deal , with exhaustive listing of everything found in everything except for these final th thirty minutes . OK so , um , on some of these QUALs , Yeah . are they really QUALs , or are they glosses ? So like there 's a \" QUAL TCL \" . \" TCL \" . Where do you see that ? Uh Oh , oh . The reason is because w it was said \" tickle \" . What 's a QUAL ? Oh I see , I see . Hmm . So it 's not gloss . OK , I see . Yep . Sh - shouldn't it be \" QUAL TICKLE \" or something ? It wasn't said \" TCL \" . Of course . Like {disfmarker} it 's not {disfmarker} On the {disfmarker} in the actual script {disfmarker} in the actual transcript , I s I {disfmarker} So this {disfmarker} this happens in the very first one . Mm - hmm . I actually wrote it as \" tickle \" . OK . Because we {disfmarker} they didn't say \" TCL \" , they said \" tickle \" . Yeah . And then , following that is \" QUAL TCL \" . Right . Oh I see . OK . I f I forget , what 's QUAL ? Qual - qualifier . It 's just comment about what they said . Yeah . Comment . It 's not something you wanna replace {pause} with Comment or contextual comment . So they didn't mean \" tickle \" as in Elmo , but {disfmarker} Tickle ? Yeah . they meant \" tickle \" as in {disfmarker} Yeah . Huh . Right . But at some point {disfmarker} I mean , we probably shoul We 'll probably add it to the language model . But we should add it to the dictionar Yeah . No , to the pronunciation model . What did I say ? To the language model {disfmarker} model . Language , uh {disfmarker} Well both . Add what , Liz ? We can go on lan lan add it to both dictionary and language model . Oh lan Oh OK - we OK Yeah . it 's in the language model , w yeah , but it so it 's the pronunciation model that has to have a pronunciation of \" tickle \" . Well \" tickle \" was pronounced \" tickle \" . Right ? \" tickle \" is pronounced \" tickle \" ? What are you saying ? It 's pronounced the same {disfmarker} it 's pronounced the same as the verb . I 'm sorry ! So I think it 's the language model that makes it different . Oh , sorry . What I meant is that there should be a pronunciation \" tickle \" for TCL as a word . Yeah . Oh I see . And that word in the {disfmarker} in , you know , it stays in the language model wherever it was . Mm - hmm . Right . Right . Right . Yeah you never would put \" tickle \" in the language model in that form ,  Right . yeah . Right . There 's actually a bunch of cases like this with people 's names and {disfmarker} So how w there 'd be a problem for doing the language modeling then with our transcripts the way they are . Yes . Yeah . Yeah so th th there there 's a few cases like that where the um , the word needs to be spelled out in {disfmarker} in a consistent way as it would appear in the language , but there 's not very many of these . Tcl 's one of them . And {disfmarker} and you 'll ha you 'll have to do it sychronously . Um , y yeah . Right , so y so , whoever 's creating the new models , will have to also go through the transcripts and change them synchronously . It 's just disturbing . Right . Hmm . Right . We have this {disfmarker} there is this thing I was gonna talk to you about at some point about , you know , what do we do with the dictionary as we 're up updating the dictionary , these changes have to be consistent with what 's in the {disfmarker} Like spelling people 's names and so forth . If we make a spelling correction to their name , like someone had Deborah Tannen 's name mispelled , and since we know who that is , you know , we could correct it , You can correct it . Yeah . but {disfmarker} but we need to make sure we have the mispel If it doesn't get corrected we have to have a pronunciation as a mispelled word in the dictionary . Mm - hmm . Things like that . These are so funny to read . Well , of course now the {disfmarker} the Tannen corre the spelling c change . So . Uh , that 's what gets {disfmarker} I {disfmarker} I picked those up in the frequency check . Right . Right . So if there 's things that get corrected before we get them , it 's {disfmarker} it 's not an issue , Mm - hmm . but if there 's things that um , we change later , then we always have to keep our {disfmarker} the dictionary up to date . And then , yeah , in the case of \" tickle \" I guess we would just have a , you know , word \" TCL \" which {disfmarker} Mm - hmm . You add it to the dictionary . which normally would be an acronym , you know , \" TCL \" Right . but just has another pronunciation . Yep . \" ICSI \" is {disfmarker} is one of those that sometimes people pronounce and sometimes they say \" ICSI . \" Mm - hmm . So , those that are l are listed in the acronyms , I actually know Oh yeah . they were said as letters . The others , um , e those really do need to be listened to cuz I haven't been able to go to all the IC ICSI things , Right , exactly . and {disfmarker} {comment} and until they 've been listened to they stay as \" ICSI \" . Mm - hmm . Right . Don and I were just noticing , love this one over on page three , \" vocal {disfmarker} vocal gesture mimicking sound of screwing something into head to hold mike in place . \" That 's great . It 's this , \" rrre - rrre - rrre \" . It was me . It was ! In fact , it was ! Yeah ! A lot of these are me the {disfmarker} the \" beep is said with a high pit high pitch and lengthening . \" He {disfmarker} he s he said {disfmarker} he said get {disfmarker} To head . That was the {disfmarker} I was imitating uh , beeping out {disfmarker} Yeah , that 's it . Beep . Perfect . Yeah that 's it . Yeah . Oh there is something spelled out \" BEEEEEEP \" Um {disfmarker} That 's it . Yeah . Yeah , that 's {disfmarker} that 's been changed . in the old {disfmarker} Thank you . Because he was saying , \" How many E 's do I have to allow for ? \" You need a lot of {disfmarker} What I meant was \" beep \" . You need a lot of qualification Adam . I guess so . That 's been changed . So , exactly , that 's where the lengthening comment c came in . Subtext . Anyway . s chan brought it down . Right , thanks , yeah . So they 're vocalization , Right . And those of course get {disfmarker} get picked up in the frequency check glosses . because you see \" beep \" Right . and you know {disfmarker} I mean it gets kicked out in the spelling , and it also gets kicked out in the , uh , freq frequency listing . Right . Right . I have the {disfmarker} there 're various things like \" breathe \" versus \" breath \" versus \" inhale \" and , hhh , you know , I don't know . I {disfmarker} I think they don't have any implications for anything else so it 's like I 'm tempted to leave them for now an and {disfmarker} It 's easy enough to find them when they 're in curly brackets . We can always get an exhaustive listing of these things and find them and change them . Yeah . \" Sings finale - type song \" Yeah , that was in the first meeting . that 's {disfmarker} that 's good . Yeah . Um , Yeah , but I don't actually remember what it was . But that was {disfmarker} Eric did that . Yeah . So on {disfmarker} Yeah . Tah - dah ! I don't know . I think maybe something like that . Something like that maybe , yeah . Well , that 'd qualify . On the glosses for numbers , Yeah . it seems like there are lots of different ways it 's being done . OK . Interesting question . There 's a {disfmarker} Yes . OK , now first of all {disfmarker} Ooo - ooo ! Very important . \" Ooo - ooo . \" Uh Chuck {disfmarker} Chuck led to a refinement here which is to add \" NUMS \" if these are parts of the read numbers . Now you already know i that I had , uh , in places where they hadn't transcribed numbers , I put \" numbers \" in place of any kind of numbers , but there are places where they , um , it {disfmarker} th this convention came later an and at the very first digits task in some transcripts they actually transcribed numbers . And , um , d Chuck pointed out that this is read speech , and it 's nice to have the option of ignoring it for certain other prob uh p uh , things . And that 's why there 's this other tag here which occurs a hundred and five {disfmarker} or three hundred and five times right now which is just {disfmarker} well n n \" NUMS \" by itself \" NUMS \" , yeah . which means this is part of the numbers task . I may change it to \" digits \" . I mean , i with the sed command you can really just change it however you want because it 's systematically encoded , you know ? Yep . Have to think about what 's the best for {disfmarker} for the overall purposes , but in any case , um , \" numbers \" and \" NUMS \" are a part of this digits task thing . Um , now th Then I have these numbers that have quotation marks around them . Um , I didn't want to put them in as gloss comments because then you get the substitution . And actually , th um , {vocalsound} the reason I b did it this way was because I initially started out with the other version , you have the numbers and you have the full form and the parentheses , however sometimes people stumble over these numbers they 're saying . So you say , \" Seve - seventy eight point two \" , or whatever . And there 's no way of capturing that if you 're putting the numbers off to the side . You can't have the seven and {disfmarker} So what 's to the left of these ? The left is i so example the very first one , Mm - hmm . it would be , spelled out in words , \" point five \" . OK , that 's what I was asking . Right . Only it 's spelled out in words . Point FIVE , yeah . So i this is also spelled out in {disfmarker} in words . \" Point five . \" Good . And then , in here , \" NUMS \" , so it 's not going to be mistaken as a gloss . It comes out as \" NUMS quote dot five \" . OK now , the other example is , in the glosses right there , Thank you . \" gloss one one one dash one three zero \" . Right . What {disfmarker} what 's to the left of that ? Well now {disfmarker} In that case it 's people saying things like \" one one one dash so - and - so \" or they 're saying uh \" two {disfmarker} I mean zero \" whatever . OK . And in that case , it 's part of the numbers task , and it 's not gonna be included in the read digits anyway , So there will be a \" NUMS \" tag on those lines ? so {disfmarker} I m in the uh {disfmarker} There is . Yeah . Yeah . I 've added that all now too . There 's a \" numbers \" tag {disfmarker} Good . I 'm sorry I 'm {disfmarker} I didn't follow that last thing . Wait . So , so gloss {disfmarker} in the same line that would have \" gloss quote one one one dash one thirty \" , you 'd have a gloss at the end of the line saying , uh , \" curly bracket NUMS curly bracket \" . Right . So if you {disfmarker} if you did a , uh , a \" grep minus V nums \" Oh , so you could do \" grep minus V nums \" . and you get rid of anything that was read . So that 's the {disfmarker} yeah . OK . So there wouldn't be something like i if somebody said something like , \" Boy , I 'm really tired , OK . \" and then started reading that would be on a separate line ? Yes . OK great . Cuz I was doing the \" grep minus V \" quick and dirty and looked like that was working OK , Mm - hmm . Good . but {disfmarker} Yep . Great . Now why do we {disfmarker} what 's the reason for having like the point five have the \" NUMS \" on it ? Is that just like when they 're talking about their data or something ? This is more because {disfmarker} Or {disfmarker} Yeah . Oh these are all these , the \" NUMS point \" , this all where they 're saying \" point \" something or other . These are all like inside the spontaneous {disfmarker} And the other thing too is for readability of the transcript . I mean if you 're trying to follow this while you 're reading it it 's really hard to read , you know {disfmarker} eh , \" so in the data column five has \" , you know , \" one point five compared to seventy nine point six \" , it 's like when you see the words it 's really hard to follow the argument . And this is just really a {disfmarker} a way of someone who would handle th the data in a more discourse - y way to be able to follow what 's being said . Label it . Oh OK . So this is where Chuck 's , um , overall h architecture comes in , I see . where we 're gonna have a master file of the channelized data . Um , there will be scripts that are written to convert it into these t these main two uses and th some scripts will take it down th e into a f a for ta take it to a format that 's usable for the recognizer an uh , other scripts will take it to a form that 's usable for the {disfmarker} for linguistics an and discourse analysis . And , um , the implication that {disfmarker} that I have is that th the master copy will stay unchanged . These will just be things that are generated , Right and e by using scripts . OK . Master copies of superset . When things change then the {disfmarker} the script will cham change but the {disfmarker} but there won't be stored copies of {disfmarker} in different versions of things . Good . So , I guess I 'd have one request here which is just , um , maybe to make it more robust , th that the tag , whatever you would choose for this type of \" NUMS \" {comment} where it 's inside the spontaneous speech , is different than the tag that you use for the read speech . Right . Right . That would argue for changing the other ones to be \" digits \" or something . Um , that way w if we make a mistake parsing , or something , we don't see the \" point five \" , or {disfmarker} or it 's not there , then we Mm - hmm . a Just {disfmarker} an And actually for things like \" seven eighths \" , or people do fractions too I guess , you {disfmarker} maybe you want one overall tag for sort of that would be similar to that , Except {disfmarker} or {disfmarker} As long as they 're sep as they 're different strings that we {disfmarker} that 'll make our p sort of processing more robust . Well {disfmarker} Cuz we really will get rid of everything that has the \" NUMS \" string in it . I suppose what you could do is just make sure that you get rid of everything that has \" curly brace NUMS curly brace \" . Well {disfmarker} Ex - exactly . I mean that would be the {disfmarker} Exactly . That was {disfmarker} that was my motivation . And i these can be changed , like I said . Yeah . You know , I mean , as I said I was considering changing it to \" digits \" . And , it just {disfmarker} i you know , it 's just a matter of deciding on whatever it is , and being sure the scripts know . Right . It would probably be safer , if you 're willing , to have a separate tag just because um , then we know for sure . And we can also do counts on them without having to do the processing . But you 're right , we could do it this way , it {disfmarker} it should work . Um , Yeah , and it makes it {disfmarker} I guess the thing about {disfmarker} but it it 's probably not hard for a person to tell the difference Yeah . because one 's in the context of a {disfmarker} you know , a transcribed word string , Right . The other thing is you can get really so minute with these things and {disfmarker} So {disfmarker} and increase the size of the files and the re and decrease the readability to such an extent by simply something like \" percent \" . Now I {disfmarker} I could have adopted a similar convention for \" percent \" , but somehow percent is not so hard , you know ? Hmm . i It 's just when you have these points and you 're trying to figure out where the decimal places are {disfmarker} And we could always add it later . Percent 's easy to detect . Point however is {disfmarker} is uh a word that has a couple different meanings . And you 'll find both of those in one of these meetings , where he 's saying \" well the first point I wanna make is so - and - so \" and he goes through four points , and also has all these decimals . So Liz , what does the recognizer do , So . uh , Hmm . what does the SRI recognizer output for things like that ? \" seven point five \" . Does it output the word {disfmarker} \" Seven point five \" . Right , the word \" seven \" ? Well , the numbers ? The number \" seven \" ? The word . The word \" seven \" , OK . Yeah . Yeah . So I 'd {disfmarker} so \" I 'd like {disfmarker} I 'd like to talk about point five \" . And {disfmarker} and actually , you know the language {disfmarker} Yeah . it 's the same point , actually , the {disfmarker} the p you know , the word \" to \" and the word y th \" going to \" and \" to go to \" those are two different \" to 's \" and so there 's no distinction there . Mm - hmm . It 's just {disfmarker} just the word \" point \" has {disfmarker} Yeah , every word has only one , yeah e one version even if {disfmarker} even if it 's {disfmarker} A actually even like the word \" read \" {comment} and \" read \" Those are two different words . They 're spelled the same way , right ? Mm - hmm . And they 're still gonna be transcribed as READ . Mm - hmm . Right . So , yeah , I {disfmarker} I like the idea of having this in there , I just {disfmarker} I was a little bit worried that , um , the tag for removing the read speech {disfmarker} because i What if we have like \" read letters \" or , I don't know , We might wanna {disfmarker} just a separate tag that says it 's read . like \" read something \" like \" read \" Mm - hmm . yeah , basically . But other than that I it sounds great . Yeah . OK ? Are we done ? Well I wanted to say also regarding the channelized data , Oh , I guess we 're not done . Yeah . that , um , Thilo requested , um , that we ge get some segments done by hand to e e s reduce the size of the time bins wh like was Chuc - Chuck was mentioning earlier that , um , that , um , if you {disfmarker} if you said , \" Oh \" and it was in part of a really long , s complex , overlapping segment , that the same start and end times would be held for that one Well {disfmarker} as for the longer utterances , We did that for one meeting , right , and {disfmarker} so you have that data don't you ? Yeah , that 's the training data . And he requested that there be , uh , similar , uh , samples done for five minute stretches c involving a variety of speakers and overlapping secti sections . Yeah . He gave me {disfmarker} he did the {disfmarker} very nice , he {disfmarker} he did some shopping through the data and found segments that would be useful . And at this point , all four of the ones that he specified have been done . In addition the I 've {disfmarker} I have the transcribers expanding the amount that they 're doing actually . Oh great . So right now , um , I know that as of today we got an extra fifteen minutes of that type , and I 'm having them expand the realm on either side of these places where they 've already started . Oh great . OK . But if {disfmarker} if {disfmarker} you know , and I {disfmarker} and he 's gonna give me some more sections that {disfmarker} that he thinks would be useful for this purpose . Yeah . Yeah . Because it 's true , I mean , if we could do the {disfmarker} the more fine grained tuning of this , uh , using an algorithm , that would be so much more efficient . And , um . So this is gonna be {pause} useful to expand this . So I {disfmarker} I thought we {disfmarker} we sh we sh perhaps we should try to {disfmarker} to start with those channelized versions just to {disfmarker} just to try it . Give it {disfmarker} Give one tr transcriber the {disfmarker} the channelized version of {disfmarker} of my speech - nonspeech detection and look if {disfmarker} if that 's helpful for them , or just let them try if {disfmarker} if that 's better or If they {disfmarker} if they can {disfmarker} You mean to start from scratch f in a brand new transcript ? Yeah . Yeah . Yeah . That 'd be excellent . Yeah , that 'd be really great . As it stands we 're still in the phase of sort of , um , cleaning up the existing data getting things , uh , in i m more tight tightly time {disfmarker} uh , aligned . I also wanna tell {disfmarker} um , I also wanted to r raise the issue that {disfmarker} OK so , there 's this idea we 're gonna have this master copy of the transcript , it 's gonna be modified by scripts t into these two different functions . And actually the master {disfmarker} Two or more . Two or more different functions . Two {disfmarker} two or more . And that the master is gonna be the channelized version . Right . So right now we 've taken this i initial one , it was a single channel basically the way it was input . And now , uh , thanks to the advances made in the interface , we can from now on use the channelized part , and , um , any changes that are made get made in the channelized version kind of thing . But I wanted to get all the finished {disfmarker} all the checks {disfmarker} Yeah , so that has implications for your script . Yeah . So , uh , have those {disfmarker} e e the vis the ten hours that have been transcribed already , have those been channelized ? And I know {disfmarker} I 've seen @ @ {disfmarker} I 've seen they 've been channelized , Yes , they have . All ten hours ? but Except for the missing thirty minutes . have they uh {disfmarker} have they been {disfmarker} has the time {disfmarker} have the time markings been adjusted , uh , p on a per channel {disfmarker} Great . Uh , for {disfmarker} for a total of like twenty m f for a total of {disfmarker} Let 's see , four times {disfmarker} total of about an {disfmarker} {pause} thirty minutes . That 's {disfmarker} that 's been the case . So , And plus the training , whatever you have . I guess , I mean , I don't know if we should talk about this now , or not , but I Well it 's just we 're {pause} missing tea . Yeah , I know . So . No , but I mean my question is like should I wait until all of those are processed , and channelized , like the time markings are adjusted before I do all the processing , and we start like branching off into the {disfmarker} into the {disfmarker} our layer of uh transcripts . Well , you know the problem {disfmarker} the problem is that some {disfmarker} some of the adjustments that they 're making are to bring {disfmarker} are to combine bins that were {disfmarker} time bins which were previously separate . And the reason they do that is sometimes there 's a word that 's cut off . Right . And so , i i i it 's true that it 's likely to be adjusted in the way that the words are more complete . And , OK . No I know {disfmarker} I know that adjusting those things are gonna {disfmarker} is gonna make it better . so I {disfmarker} it 's gonna be a more reliable thing and I 'm not sure {disfmarker} I mean I 'm sure about that , Yeah . but do you have like a time frame when you can expect like all of it to be done , or when you expect them to finish it , or {disfmarker} Well partly it depends on how {disfmarker} um , how e effective it will be to apply an algorithm because i this takes time , Yeah . Yeah . you know , it takes a couple hours t to do , uh , ten minutes . Yeah , I don't doubt it . Um , so . So right now the {disfmarker} what you 're doing is you 're taking the {disfmarker} uh , the o original version and you 're sort of channelizing yourself , right ? Yeah . I 'm doing it myself . I mean i if the time markings aren't different across channels , like the channelized version really doesn't have any more information . Mm - hmm . So , I was just {disfmarker} I mean , originally I had done before like the channelized versions were coming out . Right . Right . Um , So I {disfmarker} I th I think probably the way it 'll go is that , you know , when we make this first general version and then start working on the script , that script @ @ that will be ma you know primarily come from what you 've done , um , we 'll need to work on a channelized version of those originals . and so it 's a question of like what {disfmarker} Mm - hmm . Mm - hmm . Mm - hmm . And so it should be pretty much identical to what you have t except for the one that they 've already tightened the boundaries on . Yep . Mm - hmm . Right . Um , So Yeah , I mean {disfmarker} uh , and then probably what will happen is as the transcribers finish tightening more and more , you know , that original version will get updated yeah . and then we 'll rerun the script and produce better uh versions . OK . But the {disfmarker} I guess the ef the effect for you guys , because you 're pulling out the little wave forms into separate ones , that would mean these boundaries are constantly changing you 'd have to constantly re rerun that , I know . so , maybe {disfmarker} Right . But that {disfmarker} But that {disfmarker} that 's not hard . Mm - hmm . No . I I think the harder part is making sure that the transc the transcription {disfmarker} OK . So if you b merge two things , then you know that it 's the sum of the transcripts , but if you split inside something , you don't where the word {disfmarker} which words moved . Mm - hmm . Mm - hmm . And that 's wh that 's where it becomes a little bit {disfmarker} uh , having to rerun the processing . Mm - hmm . The cutting of the waveforms is pretty trivial . Yeah . I mean as long as it can all be done automatically , I mean , then that 's not a concern . Mm - hmm . You know , if I just have to run three scripts to extract it all and let it run on my computer for an hour and a half , or however long it takes to parse and create all the reference file , that 's not a problem . Right . Yeah . Uh - huh . Mm - hmm . Um , so yeah . As long as we 're at that point . And I know exactly like what the steps will work {disfmarker} what 's going on , in the editing process , Yeah . so . OK . So that 's {disfmarker} I I mean I could {disfmarker} there were other checks that I did , but it 's {disfmarker} I think that we 've {disfmarker} unless you think there 's anything else , I think that I 've covered it . Yeah . I can't think of any of the {disfmarker} other ones . OK . Great . OK . Oop ! Man !",
        "summarize": "The group discussed digits data, recent ASR results, the status of transcriptions, and disk space and storage format issues. Approximately two hours of digits have been recorded, half of which have been extracted. Researchers doing ASR are looking into methods for generating a better channel-based segmentation to improve recognition results for close-talking microphone data. Transcription checking procedures were reviewed, and efforts to coordinate the channelization and presegmention of data with the tightening of time bins were discussed. The group also talked about downsampling and strategies for coping with low disk space."
    }
]