[
    {
        "transcript": "st So we 're on . Yeah . That 's better . And , {comment} somewhere is my agenda . I think the most important thing is Morgan wanted to talk about , uh , the ARPA {pause} demo . Well , so , here 's the thing . Um , why don't we s again start off with {disfmarker} with , uh , Yeah , I 'll get it . I 'll get the door . Um , I think we want to start off with the agenda . And then , given that , uh , Liz and Andreas are gonna be {pause} ten , fifteen minutes late , we can try to figure out what we can do most effectively without them here . So {disfmarker} {vocalsound} So {disfmarker} so , one thing is , yeah , talk about demo , OK . So , uh {disfmarker} uh , IBM transcription status , IBM transcription . Uh , what else ?   What 's SmartKom ? SmartKom ? Uh , we wanna talk about if w if we wanna add the data to the mar Meeting Recorder corpus . The data . The data which we are collecting here . What {disfmarker} what {disfmarker} what are we collecting here ? Data ? So why don't we have that on the agenda and we 'll {disfmarker} we 'll get to it and talk about it ? The SmartKom data ? Yeah , right . Yeah . Uh , right . Uh . Uh , reorganization status . Reorganization status . Oh . Files and directories ? Files and directories . Yep . Uh - huh . Absinthe , which is the multiprocessor UNIX {disfmarker} Linux . I think it was {pause} Andreas wanted to talk about segmentation and recognition , and update on SRI recognition experiments . Um {disfmarker} And then if ti if there 's time I wanted to talk about digits , but it looked like we were pretty full , so I can wait till next week . Right . OK . Well , let 's see . I think the a certainly the segmentation and recognition we wanna maybe focus on when An - Andreas is here since that was particularly his thing . And also the SmartKom thing should b SmartKom also , Andreas . Absinthe , I think also he has sort of been involved in a lot of those things . At least , Yeah . yeah , he 'll t he 'll probably be interested . Yeah . But . Um So , I mean , I think they 'll be inter I 'll be interested in all this , but {disfmarker} but , uh , probably , if we had to pick something {pause} that we would talk on for ten minutes or so while they 're coming here . Or I guess it would be , you think , reorganization status , or {disfmarker} ? Yeah . I mean , I think , Chuck was the one who added out the agenda item . I don't really have anything to say other than that we still haven't done it . Well , I mean , I uh {disfmarker} {vocalsound} just basically that {disfmarker} So . maybe I said {disfmarker} maybe we said this before {disfmarker} just that we met and we talked about it and we sort of have a plan for getting things organized and {disfmarker} And I {disfmarker} and I think a crucial part of that is the idea of {disfmarker} of not wanting to do it until right before the next level zero back - up so that there won't be huge number of {disfmarker} of added , Right . uh {disfmarker} Right . That {disfmarker} that was basically it . Not {disfmarker} not much @ @ {disfmarker} Although Dave basically said that if we wanna do it , just tell him and he 'll do a d level zero then . Yeah . Uh - huh . Oh , excellent . So . Oh , good . Oh , so maybe we should just go ahead and get everything ready , and {disfmarker} Yep . So , I think we do need to talk a little bit about {disfmarker} Well , we don't need to do it during this meeting . Yeah . We have a little more to discuss . But , uh , we 're {disfmarker} we 're basically ready to do it . And , uh , I have some web pages on ts {comment} more of the background . So , naming conventions and things like that , that I 've been trying to keep actually up to date . So . And I 've been sharing them with U - d UW folks also . I 'm sorry , you 've been what ? Showing them ? OK . Sharing them . Sharing them with the UW folks . OK . OK . OK . Well , maybe uh , since that {disfmarker} that was a pretty short one , maybe we should talk about the IBM transcription status . Someone can {vocalsound} fill in Liz and Andreas later . Uh OK . So , we , uh {disfmarker} we did another version of the beeps , where we separated each beeps with a spoken digit . Chuck came up here and recorded some di himself speaking some digits , and so it just goes \" beep one beep \" and then the phrase , and then \" beep two beep \" and then the phrase . And that seems pretty good . Um , I think they 'll have a b easier time keeping track of where they are in the file . And we have done that on the {pause} automatic segmentations . And we did it with the automatic segmentation , and I don't think {disfmarker} We ne we didn't look at it in detail . We just sent it to IBM . We {disfmarker} we sorta spot - checked it . I listened to {pause} probably , uh , five or ten minutes of it from the beginning . Yeah . Oh , really ? Yeah . OK . And {disfmarker} I sorta spot - checked here and there and it sounded pretty good . So . I think it 'll work . OK . And , uh , we 'll just hafta see what we get back from them . Uh {disfmarker} And the main thing will be if we can align what they give us with what we sent them . I mean , that 's the crucial part . Right . And I think we 'll be able to do that at {disfmarker} with this new beep format . Yep . Well , I think it 's also they are much less likely to d have errors . Mm - hmm . I mean , so the problem wi last time is that there were errors in the transcripts where they put beeps where there weren't any , or {disfmarker} and they put in extraneous beeps . Right . Yeah . And with the numbers there , it 's much less likely . Yeah , one interesting note is {disfmarker} uh , or problem {disfmarker} I dunno if this was just because of how I play it back , I say , uh , SND - play and then the file , every once in a while , @ @ {comment} uh , like a beep sounds like it 's cut into two beeps . Yeah . Into two pieces . Yeah , and I {disfmarker} I dunno if that 's an , uh , artifact of playback {disfmarker} Yeah . Yep . bu uh , I don't think it 's probably in the original file . Um , but , uh {disfmarker} I recognize that , too . Yeah . Ha . That 's interesting . I didn't hear that . Yeah . But with this new format , um , that hopefully they 're not hearing that , and if they are , it shouldn't throw them . Yep . So . Well , maybe we better listen to it again , make sure , but , I mean , certainly the software shouldn't do that , Yeah . That 's what I thought . so . Mm - hmm . I it 's probably just , you know , mmm , somehow the audio {pause} device gets hung for a second , Yeah . Some latency or something . Hiccups . Yeah ? As long as they have one number , and they know that there 's only one beep maximum {vocalsound} that goes with that number . or {disfmarker} Yeah . Yeah . Right . Yeah . The only {disfmarker} the only part that might be confusing is when Chuck is reading digits . Right . Yep . Well , you know , actually , are we having them {disfmarker} So {vocalsound} th \" Seven four eight beep seven beep {vocalsound} eight three two \" . Yeah , but are we having them do digits ? Yes . Because , uh , we don't {disfmarker} we didn't {disfmarker} In order to cut them out we 'd have to listen to it . We {disfmarker} we didn't cut those out . Yeah . They are not transcribed yet . So . Yeah . OK . Yeah . And we wanted to avoid doing that , OK . so we {disfmarker} they are transcribing the digits . OK . We can {disfmarker} we can ignore it when we get it back , Although we could tell them {disfmarker} {comment} {vocalsound} we could tell them , if you hear someone reading a digits string just say \" bracket digit bracket \" huh . and don't bother actually computing the di writing down the digits . Yeah . That 'd be great . That 'd be what I 'm having the transcribers here do , cuz it can be extracted later . Yep . And then I wanted to talk about {disfmarker} but as I said I {disfmarker} we may not have time {disfmarker} what we should do about digits . We have a whole pile of digits that haven't been transcribed . Le - let 's talk about it , because that 's {disfmarker} that 's something that I {disfmarker} I know Andreas is less interested in than Liz is , OK . so , you know . It 's good {disfmarker} Do we have anything else to say about transcription ? About IBM stuff ? Uh , Brian {disfmarker} I {disfmarker} I {vocalsound} sent bresset {disfmarker} {vocalsound} {vocalsound} sent Brian a message about {pause} {vocalsound} the meeting and I haven't heard back yet . So . I g hope he got it and hopefully he 's {disfmarker} OK . Hmm . maybe he 's gone , I dunno . He didn't even reply to my message . So . I should probably ping him just to make sure that he got it .  Alright . So , we have a whole bunch of digits , if we wanna move on to digits . Actually , maybe I {disfmarker} One {disfmarker} one relate more related thing in transcription . So that 's the IBM stuff . We 've got that sorted out . Um , how 're we doing on the {disfmarker} on the rest of it ? We 're doing well . I {disfmarker} I hire {disfmarker} I 've hired two extra people already , expect to hire two more . Hmm . And , um , {vocalsound} I 've prepared , um , uh , a set of five which I 'm {disfmarker} which I 'm calling set two , which are now being edited by my head transcriber , {vocalsound} in terms of spelling errors and all that . She 's also checking through and mar and {disfmarker} {vocalsound} and monitoring , um , the transcription of another transcriber . You know , I mean , she 's going through and doing these kinds of checks . Uh - huh . And , I 've moved on now to what I 'm calling set three . I sort of thought if I do it in sets {disfmarker} groups of five , then I can have , like , sort of a {disfmarker} a parallel processing through {disfmarker} through the {disfmarker} the current . Uh - huh . And {disfmarker} and you indicated to me that we have a g a goal now , {vocalsound} for the {disfmarker} for the , um , {nonvocalsound} {vocalsound} the , uh , DARPA demo , of twenty hours . So , I 'm gonna go up to twenty hours , be sure that everything gets processed , and released , and {disfmarker} {pause} {comment} and that 's {disfmarker} that 's what my goal is . Package of twenty hours right now , {vocalsound} and then once that 's done , move on to the next . Yeah , uh , so twenty hours . But I guess the other thing is that , um , that {disfmarker} that 's kinda twenty hours ASAP because the longer before the demo we actually have the twenty hours , the more time it 'll be for people to actually do cool things with it . Mm - hmm . Good . I 'm {disfmarker} I 'm hiring people who , {vocalsound} uh , really are {disfmarker} So . OK . They would like to do it full - time , several of these people . And {disfmarker} and I don't think it 's {vocalsound} possible , really , to do this full - time , but , that {disfmarker} what it shows is motivation to do as many hours as possible . Mm - hmm . It 'll keep your accuracy up . Yep . Yeah . And they 're really excellent . Yeah . Well , that 's good . Yeah . Got a good core group now . Yeah , I mean , I guess the {disfmarker} So the difference if {disfmarker} if , um , if the IBM stuff works out , the difference in the job would be that they p primarily would be checking through things that were already done by someone else ? Again . Mm - hmm . Is that most of what it {disfmarker} ? And correcting . I mean {disfmarker} Correcting . Correcting . We 'll {disfmarker} we 'll expect that they 'll have to move some time bins and do some corrections . And I {disfmarker} you know , I 've also d uh , discovered {disfmarker} So with the new transcriber I 'm {disfmarker} um {disfmarker} So {disfmarker} Uh , lemme say that my , uh {disfmarker} So , um {disfmarker} At present , um , the people have been doing these transcriptions a channel at a time . And , that sort of , um , {vocalsound} is useful , and t you know , and then once in a while they 'll have to refer to the other channels to clear something up . OK . Well , {vocalsound} I realize that , um , w i we we 're using the pre - segmented version , and , um , the pre - segmented version is extremely useful , and wouldn't it be , useful also to have the visual representation of those segments ? And so I 've {disfmarker} {pause} uh , {pause} I , uh , uh , I 've {comment} trained the new one {disfmarker} uh , the new the newest one , {vocalsound} to , um , {vocalsound} use the visual from the channel that is gonna be transcribed at any given time . And that 's just amazingly helpful . Because what happens then , is you scan across the signal and once in a while you 'll find a blip that didn't show up in the pre - segmentation . Oh , right . And that 'll be something like {disfmarker} {vocalsound} I it 's ver {disfmarker} it 's interesting . I see what you mean . A backchannel , or {disfmarker} Once in a while it 's a backchannel . Yep . Sometimes it seems to be , um , similar to the ones that are being picked up . Mm - hmm . And they 're rare events , but you can really go through a meeting very quickly . You just {disfmarker} you just , you know , yo you s you scroll from screen to screen , looking for blips . And , I think that we 're gonna end up with , uh {pause} better coverage of the backchannels , Yeah . but at the same time we 're benefitting tremendously from the pre - segmentation because {vocalsound} there are huge places where there is just absolutely no activity at all . And , uh , the audio quality is so good {disfmarker} Mm - hmm . So they can {disfmarker} they can , um , scroll through that pretty quick ? Yeah . Mm - hmm . That 's great . Yeah . So I think that that 's gonna , also {pause} eh , {comment} you know , speed the efficiency of this part of the process . Hmm . OK . Uh , yeah . So , uh {disfmarker} Yeah . So let 's talk about the digits , since they 're not here yet . Uh , so , we have a whole bunch of digits that we 've read and we have the forms and so on , um , but only a small number of that ha well , not a small number {disfmarker} only a subset of that has been transcribed . And so we need to decide what we wanna do . And , uh , Liz and Andreas {disfmarker} actually they 're not here , but , they did say at one point that they thought they could do a pretty good job of just doing a forced alignment . And , again , I don't think we 'll be able to do with that alone , because , um , sometimes people correct themselves and things like that . But {disfmarker} so , I was just wondering what people thought about how automated can we make the process of finding where the people read the digits , doing a forced alignment , and doing the timing . Well , forced alignment would be one thing . What about just actually doing recognition ? Well , we {disfmarker} we know what they read , because we have the forms . No , they make mistakes . Right . But , the point is that we wanna get a set of clean digits . You 're talking about as a pre - processing step . Right . Right , Morgan ? Um {disfmarker} Is that what you 're {disfmarker} ? Yeah , I 'm {disfmarker} I 'm not quite sure what I 'm talking about . I mean {disfmarker} I {disfmarker} I mean , uh , we 're talking about digits now . And {disfmarker} and so , um , there 's a bunch of stuff that hasn't been marked yet . Uh . And , um , {vocalsound} there 's the issue that {disfmarker} that they {disfmarker} we know what {disfmarker} what was said , but do we ? I mean , so one option i Because people make mistakes and stuff . I was just asking , just out of curiosity , if {disfmarker} if with , uh {disfmarker} uh , the SRI recognizer getting one percent word error , uh , would we {disfmarker} would we do {pause} better {disfmarker} ? So , if you do a forced alignment but the force but the {disfmarker} but the transcription you have is wrong because they actually made mistakes , uh , or {vocalsound} false starts , it 's {disfmarker} it 's much less c {vocalsound} it 's {pause} much less common than one percent ? But that 's pretty uncommon . Um , if we could really get one percent on {disfmarker} We should be able to . Well , I guess {disfmarker} yeah , I guess if we segmented it , we could get one percent on digits . Right ? Yeah . Yeah . So that 's just my question . I 'm not saying it should be one way or the other , but it 's {disfmarker} If {disfmarker} But , Well , there {disfmarker} there 're a couple different of doing it . We could use the tools I 've already developed and transcribe it . Hire some people , or use the transcribers to do it . We could let IBM transcribe it . You know , they 're doing it anyway , and unless we tell them different , they 're gonna transcribe it . Um , or we could try some automated methods . Well {disfmarker} And my {disfmarker} my tendency right now is , well , if IBM comes back with this meeting and the transcript is good , just let them do it . Yeah , it 's {disfmarker} Y you raised a point , kind of , uh , euphemistically {disfmarker} but , I mean , m maybe it is a serious problem . Ho - what will they do when they go {disfmarker} hear \" beep {pause} seven {pause} beep {pause} seven three five two \" {disfmarker} I mean , {vocalsound} you think they 'll {disfmarker} we 'll get {disfmarker} ? It 's pretty distinct . Yeah ? The beeps are {pause} pre - recorded . It 'll {comment} only be a problem for m for mine . Yeah . Well it {disfmarker} it {disfmarker} well , it 'd be preceded by \" I 'm reading transcript so - and - so \" ? Yeah . Yes . So , I think if they 're processing it at {disfmarker} I mean , it 'll be {disfmarker} it will be in the midst of a digit string . Yeah . So {disfmarker} I mean it {disfmarker} sure , there {disfmarker} there might be a place where it 's \" beep seven {pause} beep eight {pause} beep {pause} eight {pause} beep \" . But , you know , they {disfmarker} they 're {disfmarker} they 're gonna macros for inserting the beep marks . And so , I {disfmarker} I don't think it 'll be a problem . We 'll have to see , but I don't think it 's gonna be a problem . OK . Well , I {disfmarker} I {disfmarker} I dunno , I {disfmarker} I think that that 's {disfmarker} if they are in fact going to transcribe these things , uh , certainly any process that we 'd have to correct them , or whatever is {disfmarker} needs to be much less elaborate for digits than for other stuff . Right . So , why not ? Sure . That was it ? That was it . Just , what do we do with digits ? OK . We have so many of them , {vocalsound} and it 'd be nice to {pause} actually do something with them . Well , we {disfmarker} we {disfmarker} we wanna have them . Yeah , I {disfmarker} You mean there 're more than ten ? Anything else ? Your mike is a little low there . I in Berkeley , yeah . So , {vocalsound} uh {pause} You {disfmarker} you have to go a little early , right ? At twenty {disfmarker} Well , I can stay till about , uh , three forty . Alright . So le let 's make sure we do the ones that {disfmarker} that , uh , saved you . Yeah . Mm - hmm . So there was some {disfmarker} Uh {pause} {vocalsound} In {disfmarker} in {disfmarker} Adam 's agenda list , he had something from you about segmentation this last recognition ? Well , yeah . So this is just partly to inform everybody , um , and {disfmarker} and of course to get , um , input . Oops . Um , so , {nonvocalsound} uh , we had a discussion {disfmarker} Don and Liz and I had discussion last week about how to proceed with , uh , you know , with Don 's work , Ch and {disfmarker} {vocalsound} and {disfmarker} and , uh , one of the obvious things that occur to us was that we 're {disfmarker} since we now have Thilo 's segmenter and it works , you know , amazingly well , {vocalsound} um , we should actually basically re - evaluate the recognition , um , results using {disfmarker} you know , without cheating on the segmentations . So {disfmarker} And , that should be fairly {disfmarker} And how do we find the transcripts for those so that {disfmarker} ? Yeah . The references for {disfmarker} for {pause} those segments ? Oh , OK . So , there 's actually {disfmarker} It 's not that {disfmarker} Why do you ask ? I could {disfmarker} No , actually , um , NIST has , um m a fairly sophisticated scoring program {vocalsound} that you can give a , um {disfmarker} {vocalsound} a time , Hand ones . Well {disfmarker} OK . uh {disfmarker} You know , you basically just give two {pause} time - marked sequences of words , and it computes the um {disfmarker} the , {comment} uh {disfmarker} {comment} you know , the {disfmarker} the {disfmarker} th It does all the work for you . it does all the work for you . Yeah . OK . So , it {disfmarker} we just {disfmarker} and we use that actually in Hub - five to do the scoring . Um . So what we 've been using so far was sort of a {pause} simplified version of the scoring . And we can {disfmarker} we can handle the {disfmarker} the {disfmarker} the type of problem we have here . So , basically you give some time constraints for {disfmarker} for the references and for {disfmarker} for the hypothesis , So , we ha Yeah . Right . and {disfmarker} Yeah , OK . Yeah . Right . Maybe the {pause} start of your speech and the end of it , So do OK . or stuff like that . Right . It does time - constrained word - alignment . OK . So . So that should be possible . I mean that shouldn't be a problem . Uh , so that was the one thing , and the other was that , um {disfmarker} What was the other problem ? Oh ! That Thilo wanted to use {pause} the recognizer alignments to train up his , um , speech detector . Yeah . Um , so that we could use , uh {disfmarker} you know there wouldn't be so much hand {vocalsound} labelling needed to , uh {disfmarker} to generate training data for {disfmarker} for the speech detector . Yeah . I 'm just in progress of {disfmarker} of doing that . So . And I think you 're in the process of doing that . Yeah . So , you can {disfmarker} {comment} you can {disfmarker} It 'll give you a lot more data , too . Won't it ? Yeah . So , it 's basically {disfmarker} s I think , eight meetings or something which {disfmarker} which I 'm using , and , {vocalsound} it 's {disfmarker} {vocalsound} before it was twenty minutes of one meeting . Mm - hmm . So {disfmarker} should {comment} be a little bit better . Right . Great . That won't be perfect {disfmarker} the alignments aren't perfect , Yeah . But {disfmarker} but , um , it 's probably still better to have all this extra data , than {disfmarker} Yeah . Yeah . Yep . Yeah . We 'll see that . Yeah . OK . Actually , I had a question about that . If you find that you can {vocalsound} lower the false alarms that you get where there 's no speech , that would be useful {pause} for us to know . So , um {disfmarker} There were the false alarms . Yeah . So , {vocalsound} r right now you get f fal you know , false {disfmarker} false , uh , speech regions when it 's just like , um , {vocalsound} breath or something like that , OK . Yeah . Yep . and I 'd be interested to know the {disfmarker} wha if you retrain um , Yeah . do those actually go down or not ? Because {pause} of {disfmarker} Yeah . I 'll {disfmarker} can make {disfmarker} an can , like , make a c comparison of {disfmarker} of the old system to the {disfmarker} to the new one , and {pause} then {disfmarker} Yeah , just to see if by doing nothing in the modeling of {disfmarker} just having that training data wh what happens . Yeah . Yeah . Yep . Um another one that we had on Adam 's agenda {pause} that definitely involved you was s something about SmartKom ? Right . So , Rob Porzel {disfmarker} eh , Porzel ? and the , uh {disfmarker} Porzel {disfmarker} and the , uh , SmartKom group are collecting some dialogues . Porzel . Porzel . Basically they have one person sitting in here , looking at a picture , and a wizard sitting in another room somewhere . And , uh , they 're doing a travel task . And , uh , it involves starting {disfmarker} I believe starting with a {disfmarker} It 's {disfmarker} it 's always the wizard , but it starts where the wizard is pretending to be a computer and it goes through a , uh , {vocalsound} speech generation system . Yeah . Actually , it 's changed to a synthesis for {disfmarker} for the first part now . Synthesis system . Yeah . Um , and then , it goes to a real wizard and they 're evaluating that . And they wanted to use this equipment , and so the w question came up , is {disfmarker} well , here 's some more data . Should this be part of the corpus or not ? And my attitude was yes , because there might be people who are using this corpus for {pause} acoustics , as opposed to just for language . Um , or also for dialogue of various sorts . Um , so it 's not a meeting . Right ? Because it 's two people and they 're not face to face . Wait a minute . So , I just wanted to understand it , cuz I {disfmarker} I 'm {disfmarker} uh , hadn't quite followed this process . Yeah . Um . So , it 's wizard in the sen usual sense that the person who is asking the questions doesn't know that it 's , uh , a machi not a machine ? Right . At the beginning . Actually {disfmarker} actually , w w the {disfmarker} the {disfmarker} We do this {disfmarker} I dunno who came up with it , but I think it 's a really clever idea . We simulate a computer breakdown halfway through the session , and so then after that , the person 's told that they 're now talking to a , uh {disfmarker} to a human . Yeah . It 's a human operator . Yeah . Yeah . But of course they don't know that it 's the same person both times . So , we {disfmarker} we collect {disfmarker} we collect both human - computer and human - human data , essentially , in the same session . You might wanna try collecting it the other way around sometime , saying that th the computer isn't up yet Hmm . and then {disfmarker} so then you can separate it out whether it 's the beginning or end kind of effects . That 's an idea . But , yeah . Yep . Yeah . That 's a good idea . \" I have to go now . You can talk to the computer . \" It 's a lot more believable , too , \" No ! \" if you tell them that they 're {disfmarker} the computer part is running on a Windows machine . And the whole breakdown thing kinda makes sense . O Just {disfmarker} just reboot it . Abort {disfmarker} abort , retry , fail ? So did they actually save the far - field {pause} data ? Yes . Well , this was {disfmarker} this was the question . Cuz at first they weren't {disfmarker} they weren't sa Yeah . So {disfmarker} so they were saying they were not going to , Yeah . OK . and I said , \" well that 's silly , if {disfmarker} if we 're gonna try to do it for a corpus , there might be people who are interested in acoustics . \" Yeah . Wow . No . Or {disfmarker} projector {comment} We were not saying we are not {pause} doing it . Yeah . S We wer we just wanted to do {disfmarker} No , the {disfmarker} the question is do we save one or two far - field channels or all of them ? Right . Yeah . Yeah . I {disfmarker} I see no reason not to do all of them . Um {disfmarker} That {disfmarker} that if we have someone who is doing acoustic studies , uh , it 's nice to have the same for every recording . Nnn . Yeah . Hmm . So , what is the purpose of this recording ? Mm - hmm . This is to get acoustic and language model training data for SmartKom. OK . It 's to be traini to b training data and development data for the SmartKom {pause} system . The English system ? Yeah . Yeah . Right . Right . Where does this {disfmarker} ?  Maybe we can have him vary the microphones , too , Well , B or they 're different s speakers . Right . So {disfmarker} so {disfmarker} so for their usage , they don't need anything . so why not {disfmarker} ? Yeah . Right ? But {disfmarker} but I 'm not sure about the legal aspect of {disfmarker} of that . Is {disfmarker} is there some contract with SmartKom or something about the data ? Yeah . What they {disfmarker} or , is {disfmarker} is that our data which we are collecting here , We 've never signed anything that said that we couldn't use anything that we did . or {disfmarker} ? OK . OK . We weren't supposed to collect any data . So . OK . Yeah . So . Yeah , th th that was the question . This was all {disfmarker} If {disfmarker} if {disfmarker} ? Yeah . Yeah . No that 's not a problem . Basically . I {disfmarker} L look , it seems to me that if we 're doing it anyway and we 're doing it for these {disfmarker} these purposes that we have , {vocalsound} and we have these distant mikes , we definitely should re should save it all as long as we 've got disk space , Mm - hmm . and disk is pretty cheap . OK . So should we save it ? And then {disfmarker} Now th Yeah . So we save it because it 's {disfmarker} it {disfmarker} it 's potentially useful . And now , what do we do with it is {disfmarker} is a s separate question . Right . I mean , anybody who 's training something up could {vocalsound} choose to put it {disfmarker} eh , to u include this or not . Right . I {disfmarker} I would not say it was part of the meetings corpus . It isn't . But it 's some other data we have , and if somebody doing experiment wants to train up including that then they can . Right ? Mm - hmm . So it 's {disfmarker} It {disfmarker} it {disfmarker} I guess it {disfmarker} the {disfmarker} begs the question of what is the meeting corpus . So if , at UW they start recording two - person hallway conversations is that part of the meeting corpus ? I think it 's {disfmarker} I {disfmarker} I think {disfmarker} I th think the idea of two or more people conversing with one another is key . Well , this has two or more people conversing with each other . Nnn , well Yeah . Well this {disfmarker} They 're just not face to face . What if we just give it a {disfmarker} a name like we give these meetings a name ? No , it doesn't . Right ? It has {disfmarker} I mean , that was my intention . And then later on some people will consider it a meeting and some people won't , Well this {disfmarker} Yeah . That was my intention . So {disfmarker} so {disfmarker} s {vocalsound} so part of the reason that I wanted to bring this up is , {vocalsound} do we wanna handle it as a special case or do we wanna fold it in , and {disfmarker} Just give it a {vocalsound} title . Oh . I think it is a s we give everyone who 's involved as their own user ID , give it session I Ds , {vocalsound} let all the tools that handle Meeting Recorder handle it , or do we wanna special case it ? And if we were gonna special case it , who 's gonna do that ? So . Well , it {disfmarker} it makes sense to handle it with the same infrastructure , since we don't want to duplicate things unnecessarily . It {disfmarker} it {disfmarker} it {disfmarker} I think {disfmarker} But as far as distributing it , we shouldn't label it as part of this meeting corpus . Yeah . We should let it be its own corp Well it 's {disfmarker} it {disfmarker} well , because {disfmarker} I don't see why not . It 's just a different topic . I ha I have an extra point , which is the naturalness issue . Because we have , like , meetings that have a reason . That 's one of the reasons that we were talking about this . And {disfmarker} and those {disfmarker} and this sounds like it 's more of an experimental setup . Yeah . It 's got a different purpose . It 's scenario - based , it 's {disfmarker} it 's human - computer interface {disfmarker} {vocalsound} it 's really pretty different . Yeah . But I I {disfmarker} I have no problem with somebody folding it in for some experiment they 're gonna do , but I don't think i it {disfmarker} it doesn't match anything that we 've described about meetings . Mm - hmm . Whereas everything that we talked about them doing at {disfmarker} at UW and so forth really does . They 're actually talking {disfmarker} OK . So w so what does that mean for how we are gonna organize things ? Hmm . Yeah . You can {disfmarker} you can {disfmarker} Again , as {disfmarker} as I think Andreas was saying , {vocalsound} if you wanna use the same tools and the same conventions , there 's no problem with that . It 's just that it 's , you know , different directory , it 's called something different , it 's {disfmarker} you know . It is different . You can't just fold it in as if it 's {disfmarker} I mean , digits are different , too . Right ? Yeah , but those are folded in , It might also be potentially confusing . and it 's just {disfmarker} you just mark the transcripts differently . So {disfmarker} so one option is you fold it in , Right . and just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction . Yeah , I th Well , I don I wouldn't call reading digits \" meetings \" . Right ? I mean , we {disfmarker} we {disfmarker} we were doing {disfmarker} Well , but {disfmarker} but , {vocalsound} I put it under the same directory tree . Well {disfmarker} You know , it 's in \" user doctor speech data MR \" . Can we just have a directory called , like , \" other stuff \" ? Other . And {disfmarker} Well {disfmarker} or , I dunno . I mean , I don't care what directory tree you have it under . And {disfmarker} {vocalsound} and just , um , store it there . Right ? I mean that 's just a {disfmarker} OK . My preference is to have a single procedure so that I don't have to think too much about things . Yes . I mean {disfmarker} Yeah . And , just have a marking . O - You {disfmarker} you can use whatever procedure you want that 's p convenient for you . If we do it any other way that means that we need a separate procedure , and someone has to do that . All I 'm saying is that there 's no way that we 're gonna tell people that reading digits is meetings . And similarly we 're not gonna tell them that someone talking to a computer to get travel information is meetings . Right . Those aren't meetings . But if it makes it easier for you to pu fold them in the same procedures and have them under the same directory tree , knock yourself out . There 's a couple other questions that I have too , You know ? and {disfmarker} and {pause} one of them is , what about , uh , consent issues ? And the other one is , what about transcription ? Are {disfmarker} ? Transcription is done in Munich . OK . So we don't have to worry about transcribing it ? Alright . Yeah . So , w we will hafta worry about format . That 's a {disfmarker} that 's another argument to keep it separate , because it 's gonna follow the SmartKom transcription conventions and not the ICSI meeting transcription conventions . Yeah . Oh , OK . Ah . Good point . OK . Well , I didn't realize that . That 's {disfmarker} that 's a {disfmarker} Good point . But I 'm sure no one would have a problem with our folding it in for some acoustic modeling or {disfmarker} or some things . Um . Do we h do we have , uh , um , American - born folk , uh , reading German {disfmarker} German , uh , pla uh , place names and so forth ? Is that {disfmarker} ? Yeah . Exactly . Yeah , great . Yeah . Yep . Yeah . They {disfmarker} they even have a reading list . I bet that sounds good , huh ? Yeah . It 's pretty funny . Yeah . You can do that if you want . OK . Yeah . I dunno if you want that . Right . Yeah . Hmm . Heidelberg So {disfmarker} Exactly Disk might eventually be an issue so we might {disfmarker} we {disfmarker} we might need to , uh , {vocalsound} get some more disk pretty soon . Do you wanna be a subject ? Yeah , I be pretty good . We {disfmarker} Yeah . We 're about {disfmarker} we 're about half {disfmarker} halfway through our disk right now . Yeah . That was one of our concerns . Are we only half ? I thought we were more than that . We 're probably a little more than that because we 're using up some space that we shouldn't be on . So , once everything gets converted over to the disks we 're supposed to be using we 'll be probably , uh , seventy - five percent . Well , when I was looking for space for Thilo , I found one disk that had , uh , I think it was nine gigs and another one had seventeen . Yep . And everything else was sorta committed . Uh {disfmarker} Were those backed - up or non - backed - up ? Those were non - backed - up . Non - back - up . Right . So that 's different . S oh , you 're talking about backed - up . I 'm much more concerned about the backed - up . The non - backed - up , I haven't looked to see how much of that we have . yeah , i is cheap . I mean , if we need to we can buy a disk , hang it off a s uh , workstation . If it 's not backed - up the sysadmins don't care too much . Yeah . So , I mean , pretty much anytime we need a disk , we can get it at the rate that we 're {disfmarker} You can {disfmarker} I shouldn't be saying this , but , you can just {disfmarker} you know , since the back - ups are every night , you can recycle the backed - up diskspace . Yeah . But that 's {disfmarker} that 's {disfmarker} {pause} that 's risky . Yeah . You really shouldn't be saying {disfmarker} Mmm . Mmm . I didn't say that . Yeah , that 's right . I didn't say that . Beep that out . Da - we had allowed Dave to listen to these {disfmarker} {vocalsound} these , {vocalsound} uh , recordings . Right . Um {disfmarker} {vocalsound} Yeah , I me and there 's been this conversation going on about getting another file server , and {disfmarker} and {vocalsound} we can do that . Mm - hmm . We 'll take the opportunity and get another big raft of {disfmarker} {vocalsound} of disk , I guess . Yeah . It 's really the back - up issue rather than the file server issue . Well , I think {disfmarker} {comment} I think there 's an argument for having {disfmarker} you know , you could use our old file server for {disfmarker} for disks that have data that {pause} is very rarely accessed , and then have a fast new file server for data that is , um , heavily accessed . Yeah . My understanding is , the issue isn't really the file server . Yeah . We could always put more disks on . Yeah . It 's the back it 's the back - up capaci It 's the back - up system . Yeah . So {disfmarker} which is near saturation , apparently . So . I think {disfmarker} I think the file server could become an issue as we get a whole bunch more new compute machines . Soon . And we 've got , you know , fifty machines trying to access data off of Abbott at once . Well , we 're alright for now because the network 's so slow . I mean , I think {disfmarker} I think we 've raised this before and someone said this is not a reliable way to do it , but the {disfmarker} What about putting the stuff on , like , C - CD - ROM or DVD or something ? Yeah . That was me . I was the one who said it was not reliable . The - they {disfmarker} they wear out . OK . Oh , OK . Yeah . The {disfmarker} the {disfmarker} th But they wear out just from sitting on the shelf ? Yep . Absolutely . Or from being {pause} read and read ? No . Read and write don't hurt them too much unless you scratch them . Oh , OK . But the r the write once , and the read - writes , don't last . So you don't wa you don't wanna put ir un reproduceable data {pause} on them . Uh - huh . Wear out after what amount of time ? Year or two . Would it be {disfmarker} ? Year or two ? Yep . Wow . Hmm . But if that {disfmarker} then you would think you 'd {pause} hear much more clamoring about data loss Yeah . and {disfmarker} I mean , yeah , all the L I {disfmarker} I don't know many people who do it on CD . I mean , they 're {disfmarker} the most {disfmarker} fo LDC - all the LDC distributions are on CD - ROM . Yeah . They 're on CD , but they 're not {disfmarker} tha that 's not the only source . Like {disfmarker} They have them on disk . And they burn new ones every once in a while . But if you go {disfmarker} {vocalsound} if you go k But , you know , we have {disfmarker} But we have like thirty {pause} you know , from {pause} ten years ago ? We have all sorts of CD - ROMs from a long time ago . No . Yeah . Yeah ! Well , th th OK . Ten years ago . Right . Ninety - one , and they 're still all fine . Yeah . Were they burned or were they pressed ? Uh , both . I 've burned them and they 're still OK . Yeah . The {disfmarker} the pressed ones last for I mean , usually they 're {disfmarker} well , not forever , they 've been finding even those degrade . Oh , I see . But , uh , the burned ones {disfmarker} I mean , when I say two or three years what I 'm saying is that I have had disks which are gone in a year . That 's what I {disfmarker} On the average , it 'll probably be three or four years . But , uh {disfmarker} I {disfmarker} I {disfmarker} you don't want to per p have your only copy on a media that fails . Mmm . And they do . Um , if you have them professionally pressed , y you know , they 're good for decades . So how about {disfmarker} ? So {disfmarker} so how about putting them on that plus , like on a {disfmarker} on {disfmarker} on DAT or some other medium that isn't risky ? I think th um , we can already put them on tape . And the tape is hi is very reliable . OK . Mm - hmm . So the {disfmarker} the only issue is then {pause} if we need access to them . So that 's fine f if we don't need access to them . Right . Well , if {disfmarker} if {disfmarker} if you {disfmarker} if they last {disfmarker} Say , they actually last , like , five years , huh , in {disfmarker} in the typical case , and {disfmarker} and occasionally you might need to recreate one , and then you get your tape out , but otherwise you don't . Can't you just {disfmarker} you just put them on {disfmarker} ? So you just archive it on the tape , and then put it on CD as well ? Yeah . Right . Oh . So you 're just saying put them on C Ds for normal access . Yeah . Right . What you {disfmarker} Yeah . I mean , you can do that but that 's pretty annoying , because the C Ds are so slow . See {disfmarker} Yeah . Yeah . Mmm . What 'd be nice is a system that re - burned the C Ds every {vocalsound} year . H everytime it was a \" gonna \" {disfmarker} \" gonna die \" . Well {disfmarker} Well , I mean , the C Ds are {disfmarker} are an op Yeah . It 's like {disfmarker} like dynamic ra DRAM . Just before . Yeah . Just before they be before it goes bad , it burns them in . The {disfmarker} the CD is an alternative to tape . Yeah . ICSI already has a perfectly good tape system and it 's more reliable . You know {disfmarker} I would think {disfmarker} So for archiving , we 'll just use tape . One {disfmarker} one thing I don't understand is , if you have the data {disfmarker} if {disfmarker} if you if the meeting data is put on disk exactly once , then it 's backed - up once and the back - up system should never have to bother with it , uh , more than once . Well , regardless {disfmarker} Well , first of all there was , um , a problem with the archive in that I was every once in a while doing a chmod on all the directories an or recursive chmod and chown , because {vocalsound} they weren't getting set correctly every once in a while , Mm - hmm . and I was just , {vocalsound} doing a minus R star , {vocalsound} not realizing that that caused {pause} it to be re - backed - up . Mm - hmm . Ah . But normally you 're correct . But even without that , the back - up system is becoming saturated . But {disfmarker} but this back - up system is smart enough to figure out that something hasn't changed and doesn't need to be {pause} backed - up again . The b I think th the {disfmarker} at least the once tha that you put it on , it would {disfmarker} {vocalsound} it would {comment} {vocalsound} kill that . Sure , but we still have enough changed that the nightly back - ups are starting to take too long . OK . So {disfmarker} so then , if {disfmarker} So {disfmarker} so then , let 's {disfmarker} So . It has nothing to do with the meeting . It 's just the general ICSI back - up system is becoming saturated . Right . OK . Right . So , what if we buy , uh {disfmarker} uh , what {disfmarker} what do they call these , um {pause} high density {disfmarker} ? Well , why don't you have this {disfmarker} have a {disfmarker} this conversation with Dave Johnson tha rather than with me ? No , no . Because this is {pause} maybe something that we can do without involving Dave , and {disfmarker} and , putting more burden on him . How about we buy , uh {disfmarker} uh {disfmarker} uh , one of these high density tape drives ? And we put the data actually on non - backed - up disks . And we do our own back - up once and for all {disfmarker} all , and then {disfmarker} and we don't have to bother this @ @ up ? Actually , you know , we could do that just with the tape {disfmarker} with the current tape . I dunno what the these tapes {disfmarker} uh , at some point these {disfmarker} I dunno . What kind of tape drive is it ? I dunno but it 's an automatic robot so it 's very convenient . Is it {disfmarker} is {disfmarker} ? Wh The o the one that we have ? You just run a program to restore them . Right . The {disfmarker} I mean {disfmarker} Yeah . But it might interfere with their back - up schedule , But {disfmarker} No , we have s we {disfmarker} Don't we have our own ? eh . Something wi th that doesn't {disfmarker} that isn't used by the back - up gang ? Don't we have something downstairs ? Well they {disfmarker} What kinda tape drive ? Just in {disfmarker} ? Yeah . Well {disfmarker} but {disfmarker} no , but Andreas 's point is a good one . And we don't have to do anything ourselves to do that . They 're already right now on tape . Right . Right . So your {disfmarker} your point is , and I think it 's a good one , that we could just get more disk and put it there . Mmm . On an XH {disfmarker} uh , X {disfmarker} X whatever partition . Yeah . That 's not a bad idea . Yeah . Yeah , that 's basically what I was gonna say , is that a disk is {disfmarker} is so cheap it 's es essentially , you know , close to free . And the only thing that costs is the back - up {pause} issue , {vocalsound} eh , to first order . So once it 's on tape {disfmarker} Right . Right . And we can take care of that by putting it on non - back {pause} up drives and just backing it up once onto this tape . Mm - hmm . I think that 's a good idea . Right . Oh . Yeah . OK . Good . It 's good . So , who 's gonna do these back - ups ? The people that collect it ? Uh Well , I 'll talk to Dave , and {disfmarker} and see what th how {disfmarker} {nonvocalsound} what the best way of doing that is . It 's probably gonna n There 's a little utility that will manually burn a tape for you , and that 's probably the right way to do it . Yeah , and we should probably make that part of the procedure for recording the meetings . Well , s Yep . Yeah . That 's what I 'm wondering , if {disfmarker} Well {pause} we 're g we 're gonna automate that . OK . My intention is to {pause} do a script that 'll do everything . I mean , you don't have to physically put a tape in the drive ? No . It 's all tape robot , Or s ? s ? {comment} Oh , OK . so you just sit down at your computer and you type a command . So it 's just {disfmarker} Oh , OK . Yeah , but then you 're effectively using the resources of the back - up system . Or is that a different tape robot ? Yeah . But not at the same time . But y but you would be anyway . No , no , no . Right ? He 's saying get a whole different drive . Because {disfmarker} No , no . See {disfmarker} But there 's no reason to do that . Yeah , just give a dedi It {disfmarker} we already have it there and it {disfmarker} it 's {disfmarker} Well , I 'm saying is @ @ i if you go to Dave , and {disfmarker} and {disfmarker} and ask him \" can I use your tape robot ? \" , he will say , \" well {pause} that 's gonna screw up our back - up operation . \" No , we won't . He 'll say \" if {disfmarker} if that means {pause} that it 's not gonna be backed - up standardly , great . \" He - I {disfmarker} Dave has {disfmarker} has promoted this in the past . So I don't think he 's actually against it . Yeah . It 's {disfmarker} it 's definitely no problem . Oh , OK . Alright . Yeah . Alright . OK . Good . What about if the times overlap with the normal back - up time ? Um , it 's {disfmarker} it 's just {disfmarker} it 's just a utility which queues up . It just queues it up and {disfmarker} and when it 's available , it will copy it . OK . Yeah . And then you can tell it to then remove it from the disk or you can , you know , do it a a few days later or whatever you wanna do , after you confirm that it 's really backed - up . OK . NW {disfmarker} ? You saying NW archive ? NW archive . Yep {comment} {vocalsound} And if you did that during the day it would never make it to the nightly back - ups . That 's what it is . OK . Right . And then there wouldn't be this extra load . Well , it {disfmarker} if he {disfmarker} you have to put the data on a {disfmarker} on a non - backed - up disk to begin with . Well , but you can have it NW archive to {disfmarker} you can have , {vocalsound} uh , a non - backed - up disk NW archived , Right . So that {disfmarker} so that {disfmarker} otherwise you don't {disfmarker} you {disfmarker} and it 'll never show up on the nightly back - ups . Right . And then it never {disfmarker} Right . Right . Right . Which I 'm sure would make ever the sysadmins very happy . Right . Yeah . So , I think that 's a good idea . OK . That 's what we should do . OK . So , that means we 'll probably wanna convert all {disfmarker} all those files {disfmarker} filesystems to non - backed - up media . That sounds good . Yeah . Yep . Um , another , thing on the agenda said SRI recognition experiments ? What 's that ? SRI recognition ? Oh . That wasn't me . Uh . Um . well , Who 's that ? we have lots of them . Uh , I dunno . Chuck , do you have any {disfmarker} any updates ? N I 'm successfully , uh , increasing the error rate . Uh {disfmarker} That 's good . Mmm . Oh . Lift the Herve approach . Yeah . So , I mean I 'm just playing with , um , the number of Gaussians that we use in the {disfmarker} the recognizer , and {disfmarker} Well , you have to sa you have to {pause} tell people that you 're {disfmarker} you 're doing {disfmarker} you 're trying the tandem features . Yes , I 'm using tandem features . Oh you are ? And {disfmarker} Cool . A and I 'm still tinkering with the PLP features .  Yeah , I got confused by the results . It sai because {disfmarker} uh , the {pause} meeting before , {vocalsound} you said \" OK , we got it down to where they 're {disfmarker} they 're within a tenth of a percent \" . That was on males . Right . That was {disfmarker} that was before I tried it on the females . Oh . See , women are nothi are , trouble . It 's the women are the problem . OK . Right ? As we all know . So . Well , let 's just say that men are simple . So {disfmarker} {comment} so , when {disfmarker} So I {disfmarker} I had {disfmarker} I ha That was a quick response . So , we had reached the point where {disfmarker} I 'm well rehearsed . Yeah . we had reached the point where , {comment} um , on the male portion of the {pause} development set , the , um {disfmarker} or one of the development sets , I should say {disfmarker} {vocalsound} the , um {disfmarker} the male error rate with , uh , ICSI PLP features was pretty much identical with , uh , SRI features . which are {pause} MFCC . So , um , then I thought , \" Oh , great . I 'll j I 'll {disfmarker} just let 's make sure everything works on the females . \" And the error rate {disfmarker} you know , there was a three percent difference . Oh . Uh - huh . So , Is there less training data ? uh {disfmarker} I mean , we don No , actually there 's more training data . This is on just digits ? No . No , no . No . Hub - five . It 's , uh , Swi Oh , sorry . OK . This is on {disfmarker} This is Hub - five . Oh , OK . Hub - five . Yeah . Yeah . Um , and the test data is CallHome and Switchboard . So , uh {disfmarker} so then {pause} um {disfmarker} Oh , and plus the {disfmarker} the vocal tract {pause} length normalization didn't {disfmarker} actually made things worse . So something 's really seriously wrong . So {disfmarker} Um {disfmarker} Aha ! OK . So {disfmarker} So {disfmarker} So {disfmarker} but you see , now , between {disfmarker} between the males and the females , there 's certainly a much bigger difference in the scaling range , than there is , say , just within the males . And what you were using before was scaling factors that were just from the {disfmarker} the m the {pause} SRI front - end . And that worked {disfmarker} that worked fine . That 's true . Yeah . Uh , but now you 're looking over a larger range and it may not be so fine . Well , um {disfmarker} So {disfmarker} I just {disfmarker} d so the one thing that I then tried was to put in the low - pass filter , which we have in the {disfmarker} So , most {disfmarker} most Hub - five systems actually band - limit the {disfmarker} uh , at about , uh , thirty - seven hundred , um , hertz . Uh - huh . Although , you know , normally , I mean , the channel goes to four {disfmarker} four thousand . Right ? So , um {disfmarker} And that actually helped , uh {disfmarker} uh , a little bit . Uh - huh . Um {pause} and it didn't hurt on the males either . So , um {disfmarker} And I 'm now , uh , trying the {disfmarker} Oh , and suddenly , also the v the vocal tract length normalization only in the test se on the test data . So , you can do vocal tract length normalization on the test data only or on both the training and the test . Yeah . And you expect it to help a little bit if you do it only on the test , and s more if you do it on both training and test . Yeah . And so the {disfmarker} It now helps , if you do it only on the test , and I 'm currently retraining another set of models where it 's both in the training and the test , and then we 'll {disfmarker} we 'll have , hopefully , even better results . So {disfmarker} But there 's {disfmarker} It looks like there will still be some difference , maybe between one and two percent , um , for the females . Huh . And so , um , you know , I 'm open to suggestions . Mm - hmm . And it is true that the , uh {disfmarker} that the {disfmarker} {vocalsound} you know , we are using the {disfmarker} But {disfmarker} it can't be just the VTL , Uh - huh . because if you don't do VTL in both systems , uh , you know , the {disfmarker} the females are considerably worse in the {disfmarker} with the PLP features . No {disfmarker} no . I {disfmarker} I remember that . It 's much worse . Yeah . So there must be some {disfmarker} something else going on . Well , what 's the standard {disfmarker} ? Yeah , so I thought the performance was actually a little better on females than males . That 's what I thought , too . Um , {pause} that {pause} ye {comment} overall , yes , but on this particular development test set , they 're actually a little worse . But that 's beside the point . We 're looking at the discrepancy between the SRI system and the SRI system when trained with ICSI features . Right . I 'm just wondering if that {disfmarker} if {disfmarker} if you have any indication of your standard features , What 's {disfmarker} Are the freq ? you know , if that 's also different {pause} or in the same direction or not . You 're {disfmarker} This is {disfmarker} lemme ask a q more basic que Cuz {disfmarker} I mean , is this , uh {disfmarker} uh , iterative , Baum - Welch training ? Mm - hmm . Or is it Viterbi training ? Or {disfmarker} ? It 's Baum - Welch training . Baum - Welch training . And how do you determine when to {disfmarker} to stop iterating ? Um {disfmarker} Well , actually , we {disfmarker} we just basically do a s a fixed number of iterations . Hmm . Uh , in this case four . Um , which {disfmarker} Eh , we used to do only three , and then we found out we can squeeze {disfmarker} And it was basically , we 're s we 're keeping it on the safe side . But you 're d Right . It might be that one more iteration {vocalsound} would {disfmarker} would help , but it 's sort of Or maybe {disfmarker} or maybe you 're doing one too many . you know . I mean it 's {disfmarker} it 's {disfmarker} No , but with Baum - Welch , there shouldn't be an over - fitting issue , really . Uh . {comment} Well , there can be . Sure . Well , you can try each one on a cross - validation set , Um . It d if you {disfmarker} if you remember some years ago Bill Byrne did a thing where he was {disfmarker} he was looking at that , can't you ? and he showed that you could get it . Yeah . So . But {disfmarker} {comment} but {disfmarker} {vocalsound} but , um {disfmarker} Well , yeah . We can {disfmarker} Well , that 's {disfmarker} that 's the easy one to check , Yeah . because we save all the intermediate models Do you {disfmarker} ? and we can {disfmarker} And in each case , ho What {disfmarker} ? um , I 'm sorry {disfmarker} in each case how do you determine , you know , the {disfmarker} the usual {pause} fudge factors ? The , uh {disfmarker} {vocalsound} the , uh , language , uh , scaling , acoustic scaling , uh , uh {disfmarker} Um {pause} I uh {disfmarker} {comment} I 'm actually re - optimizing them . Although that hasn't shown to make {pause} a big difference . OK . And the pru the question he was asking at one point about pruning , uh {disfmarker} Remember that one ? Pruning {disfmarker} ? Well , he was {disfmarker} he 's {disfmarker} it looked like the probabil at one point he was looking at the probabilities he was getting out {disfmarker} at the likelihoods he was getting out of PLP versus mel cepstrum , and they looked pretty different , Pruning in the {disfmarker} ? Yeah , the likelihoods were {pause} lower for the PLP . as I recall . Oh . And so , uh , there 's the question {disfmarker} I you mean {disfmarker} did you see this in the SRI system ? Mm - hmm . Was just looking through the log files , Um . Well , the likelihoods are {disfmarker} and {disfmarker} You can't directly compare them , because , for every set of models you compute a new normalization . And so these log probabilities , they aren't directly comparable Oh . because you have a different normalization constants for each model you train . Hmm . But , still it 's a question {disfmarker} So {disfmarker} if you have some threshold somewhere in terms of beam search or something , Well , yeah . That 's what I was wondering . or {disfmarker} ? W yeah . I mean {disfmarker} Uh {disfmarker} I mean , if you have one threshold that works well because the range of your likelihoods is in this area {disfmarker} We prune very conservatively . I mean , as we saw with the meeting data , um {pause} we could probably tighten the pruning without really {disfmarker} So we we basically we have a very open beam . But , you 're only talking about a percent or two . Yeah . Right ? Here we 're - we 're saying that we there {disfmarker} gee , there 's this b eh , there 's this difference here . And {pause} it {disfmarker} See cuz , i i {comment} there could be lots of things . Right ? But {disfmarker} but {disfmarker} but {disfmarker} but , um , let 's suppose just for a second that , uh , we 've sort of taken out a lot of the {disfmarker} the major differences , uh , between the two . Right . Course . Mm - hmm . Right . I mean , we 're already sort of using the mel scale and we 're using the same style filter integration , and {vocalsound} and , well , we 're making sure that low and high {disfmarker} Actually , there is {disfmarker} the difference in that . So , for the PLP features we use the triangular filter shapes . And for the {disfmarker} in the SRI front - end we use the trapezoidal one . And what 's the top frequency of each ? Well , now it 's the same . It 's thirty {disfmarker} thirty to seven hundred and sixty hertz . Yeah . Exp - one 's triangular , one 's trapezoidal . So {disfmarker} No , no . But {disfmarker} Before we {disfmarker} i i th with straight PLP , it 's trapezoidal also . Well {disfmarker} But {disfmarker} But then we had a slight difference in the {disfmarker} in the scale . Uh , so . Since currently the Feacalc program doesn't allow me to change {pause} the filter shape independently of the scale . Uh - huh . And , I did the experiment on the SRI front - end where I tried the {disfmarker} y where the standard used to be to use trapezoidal filters . You can actually continuously vary it between the two . And so I wen I swi I tried the trap eh , triangular ones . And it did slightly worse , but it 's really a small difference . Hmm . Coup - Couple tenths of a percent or something . So {disfmarker} OK . Right . So it 's not just losing some {vocalsound} frequency range . Yeah , exactly . So , it 's not {disfmarker} I don't think the filter shape by itself will make a huge {comment} difference . Yeah . Right . So the oth {vocalsound} the other thing that {disfmarker} Yeah . So , f i We 've always viewed it , anyway , as the major difference between the two , is actually in the smoothing , that the {disfmarker} that the , um , {vocalsound} PLP , and {disfmarker} and the reason PLP has been advantageous in , uh , slightly noisy situations is because , {vocalsound} PLP does the smoothing at the end by an auto - regressive model , Mm - hmm . Mm - hmm . and mel cepstrum does it by just computing the lower cepstral coefficients . Mm - hmm . Um . So , um {disfmarker} Mm - hmm . OK . So {pause} one thing I haven't done yet is to actually do all of this with a much larger {disfmarker} with our full training set . So right now , we 're using a {disfmarker} I don't know , forty ? I i it 's {disfmarker} it 's {disfmarker} eh {comment} it 's a f training set that 's about , um , you know , by a factor of four smaller than what we use when we train the full system . So , some of these smoothing issues are over - fitting for that matter . Mm - hmm . And the Baum - Welch should be much less of a factor , if you go full {disfmarker} whole hog . Could be . Yeah . And so , w so , just um {disfmarker} so the strategy is to first sort of treat things {pause} with fast turn - around on a smaller training set and then , {vocalsound} when you 've sort of , narrowed it down , you try it on a larger training set . Yeah . And so , we haven't done that yet . Now the other que related question , though , is {disfmarker} is , {vocalsound} uh , what 's the boot models for these things ? Th - th the boot models are trained from scratch . So we compute , um {disfmarker} So , we start with a , um , alil alignment that we computed with the b sort of the best system we have . And {disfmarker} and then we train from scratch . So we com we do a , you know , w um {disfmarker} {vocalsound} We collect the {disfmarker} uh , the observations from those alignments under each of the feature sets that {disfmarker} that we {pause} train . And then , from there we do , um {disfmarker} There 's a lot of , actually {disfmarker} {vocalsound} The way it works , you first train a phonetically - tied mixture model . Um . You do a total of {disfmarker} First you do a context - independent PTM model . Then you switch to a context {disfmarker} You do two iterations of that . Then you do two iterations of {disfmarker} of {disfmarker} of context - dependent phonetically - tied mixtures . And then from that you {disfmarker} you do the {disfmarker} you {disfmarker} you go to a state - clustered model , Yeah . and you do four iterations of that . So there 's a lot of iterations overall between your original boot models and the final models . I don't think that {disfmarker} Hmm . We have never seen big differences . Once I thought \" oh , I can {disfmarker} Now I have these much better models . I 'll re - generate my initial alignments . Then I 'll get much better models at the end . \" Made no difference whatsoever . It 's {disfmarker} I think it 's {disfmarker} eh , i Right . Well , mis for making things better . the boot models are recur Yeah . But , this for making things worse . This it migh Th - the thought is {disfmarker} is {disfmarker} is possible {disfmarker} another possible {pause} partial cause is if the boot models {vocalsound} used a comple used a different feature set , that {disfmarker} Mm - hmm . Mm - hmm . But there are no boot models , in fact . You {disfmarker} you 're not booting from initial models . You 're booting from initial alignments . Which you got from a different feature set . That 's correct . So , those features look at the data differently , actually . Yeah , but {disfmarker} I mean , you know , they {disfmarker} they will find boundaries a little differently , though {disfmarker} You know , all th all that sort of thing is actually slightly different . I 'd expect it to be a minor effect , But {disfmarker} but {disfmarker} but , what I 'm {disfmarker} what I 'm saying is {disfmarker} but {disfmarker} So , we e w f w For a long time we had used boot alignments that had been trained with a {disfmarker} {vocalsound} with the same front - end but with acoustic models that were , like , fifteen percent worse than what we use now . Mm - hmm . And with a dict different dictionary {disfmarker} with a considerably different dictionary , which was much less detailed and much less well - suited . Mm - hmm . Yeah . And so , {vocalsound} then we switched to new boot alignments , which {disfmarker} which now had the benefit of all these improvements that we 've made over two years in the system . Right . And , the result in the end was no different . Right . So , what I 'm saying is , the exact nature of these boot alignments is probably not {pause} a big factor in the quality of the final models . Yeah , maybe not . But {pause} it {disfmarker} it {disfmarker} I st still see it as {disfmarker} I mean , {vocalsound} there 's {disfmarker} there 's a history to this , too , Yeah . but I {disfmarker} uh , I don't wanna go into , Mm - hmm . but {disfmarker} but I {disfmarker} I {disfmarker} I th I think it could be the things {pause} that it {disfmarker} the data is being viewed in a certain way , uh , that a beginning is here rather than there and so forth , Yeah . Right . because the actual signal - processing you 're doing is slightly different . Right . But , {vocalsound} it 's {disfmarker} it 's {disfmarker} that 's probably not it . Yeah . Anyway , I {disfmarker} I {disfmarker} I should really reserve , uh , any conclusions until we 've done it on the large training set , um , and until we 've seen the results with the {disfmarker} with the VTL in training . Yeah . At some point you also might wanna take the same thing and try it on , uh , some Broadcast News data or something else that actually has {disfmarker} has some noisy {disfmarker} {vocalsound} noisy components , so we can see if any conclusions we come to holds {vocalsound} across {pause} different data . So . Yeah . Right . Uh {disfmarker} And , uh , with this , I have to leave . OK . Hmm ! So , is there something quick about Absinthe {pause} that you {disfmarker} ? With this said . Uh . Just what we were talking about before , which is that I ported a Blass library to Absinthe , and then got {disfmarker} got it working with fast - forward , and got {vocalsound} {vocalsound} a speedup roughly proportional to the number of processors times the clock cycle . Oh . So , that 's pretty good . Oh ! Cool . Um , I 'm in the process of doing it for Quicknet , but there 's something going wrong and it 's about half the speed that I was estimating it should be , and I 'm not sure why . Mm - hmm . But I 'll keep working on it . But the {disfmarker} what it means is that it 's likely that for net training and forward passes , we 'll {disfmarker} Absinthe will be a good machine . Especially if we get a few more processors and upgrade the processors . A few more processors ? How many are you shooting for ? There 're five now . It can hold eight . Oh , OK . Yeah , we 'll just go buy them , I guess . And it 's also five - fifty megahertz and you can get a gigahertz . Yeah . So . Can you mix {pause} t uh , processors of different speed ? I don't think so . I think we 'd have to do all {disfmarker} OK . Probably just throw away the old ones , and {disfmarker} Yep . Thank you {pause} for the box , Oh , OK . and {disfmarker} {vocalsound} I 'll just go buy their process . Hmm ! Maybe we can stick them in another system . I dunno . We 'd have to get a {disfmarker} almost certainly have to get a , uh , Netfinity server . I see . They 're pretty {disfmarker} pretty specialized . Yeah . OK . OK . Is {disfmarker} is Liz coming back , do you know , or {disfmarker} ? I dunno . Yeah . Oh , you don't . OK . Alright . Alright . See you . Um . Alright . So {disfmarker} Uh , they 're having tea out there . So I guess the other thing that we were gonna talk about is {disfmarker} is , uh , demo . And , um , so , these are the demos for the {pause} uh , July , uh , meeting {pause} and , um {disfmarker} DARPA mee July what ? Early July ? Late July ? Oh , I think it 's July fifteenth . Sixteen to eighteen , I think . Is that it ? Roughly . Yeah , sixteenth , eighteenth . Yeah . So , we talked about getting something together for that , but maybe , uh {disfmarker} maybe we 'll just put that off for now , given that {disfmarker} But I think maybe we should have a {disfmarker} a sub - meeting , I think , uh , probably , uh , Adam and {disfmarker} and , uh , Chuck and me should talk about {disfmarker} should get together and talk about that sometime soon . Over a cappuccino tomorrow ? Yeah {comment} something like that . Um , uh , you know , maybe {disfmarker} maybe we 'll involve Dan Ellis at some {disfmarker} some level as well . Mm - hmm . Um . OK . The {disfmarker} the tea is {disfmarker} is going , so , uh , I suggest we do , uh {disfmarker} uh , a unison . A unison digits ? OK . Yeah . Gets our {disfmarker} Which is gonna be a little hard for a couple people because we have different digits forms . Oops . We have a {disfmarker} I found a couple of old ones . Oh . Hmm . Well , that 'll be interesting . So , uh {disfmarker} Have you done digits before ? No . I haven't done it . OK . So , uh , the idea is just to read each line {pause} with a short pause between lines , Alright . not between {disfmarker} And , uh , since we 're in a hurry , we were just gonna read everyone all at once . So , if you sorta plug your ears and read {disfmarker} OK . So first read the transcript number , and then start reading the {pause} digits . Sure . OK ? One , two , three . OK we 're done . And {disfmarker}",
        "summarize": "The participants discussed how meetings would be transcribed, what kind of information to include in their corpus as well as how to structure it, issues with storing data, and their model. They were particularly concerned with how IBM could assist with transcribing meetings and how they would manage large amounts of data if they include more information in their corpus, given that they were running low on storage. They decided that they could store the data on tapes for backup, and that they would wait and see how IBM transcribes their meetings. As for the modeling, PhD I reported several results and a few members of the team decided to further discuss progress in a smaller meeting later on."
    }
]