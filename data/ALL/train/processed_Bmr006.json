[
    {
        "transcript": "OK , That 's looks strange . now we 're on and it seems to be working . Oh there we go . One two three four five six That is weird . This looks good . It 's like when it 's been sitting for a long time or something . So , I mean {disfmarker} I don't know what it is . But all {disfmarker} all I know is that it seems like every time I am up here after a meeting , and I start it , it works fine . And if I 'm up here and I start it and we 're all sitting here waiting to have a meeting , it gives me that error message and I have not yet sat down with {disfmarker} been able to get that error message in a point where I can sit down and find out where it 's occurring in the code . Next time you get it maybe we should write it down . Yep , we will . One of these days . Yeah . Was it a pause , or {disfmarker} ? OK . Was it on \" pause \" or something ? No . OK . Don't know . So uh {disfmarker} so the uh , the new procedural change that just got suggested , which I think is a good idea is that um , we do the digit recordings at the end . And that way , if we 're recording somebody else 's uh meeting , and a number of the participants have to run off to some other meeting and don't have the time , uh , then they can run off . It 'll mean we 'll get somewhat fewer uh , sets of digits , but um , I think that way we 'll cut into people 's time , um , if someone 's on strict time uh , less . So , I th I think {disfmarker} I think we should start doing that . Um , so , uh , let 's see , we were having a discussion the other day , maybe we should bring that up , about uh , the nature of the data that we are collecting . uh @ @ that uh , we should have a fair amount of data that is um , collected for the same meeting , so that we can , uh {disfmarker} I don't know . Wh - what {disfmarker} what were some of the points again about that ? Is it {disfmarker} Uh , well , OK , I 'll back up . Yeah . Um , at the previous {disfmarker} at last week 's meeting , this meeting I was griping {vocalsound} about wanting to get more data and I {disfmarker} I talked about this with Jane and Adam , um , and was thinking of this mostly just so that we could do research on this data um , since we 'll have a new {disfmarker} this new student di does wanna work with us , Well , great . th the guy that was at the last meeting . Great . And he 's already funded part - time , so we 'll only be paying him for sort of for half of the normal part - time , What a deal . uh {disfmarker} Yeah . And what 's he interested in , specifically ? So he 's {disfmarker} comes from a signal - processing background , but I liked him a lot cuz he 's very interested in higher level things , like language , and disfluencies and all kinds of eb maybe prosody , Mm - hmm . Great . so he 's just getting his feet wet in that . Anyway , I thought OK , maybe we should have enough data so that if he starts {disfmarker} he 'd be starting in January , next semester that we 'd have , you know , enough data to work with . Right . But , um , Jane and Adam brought up a lot of good points that just posting a note to Berkeley people to have them come down here has some problems in that you m you need to make sure that the speakers are who you want and that the meeting type is what you want , and so forth . So , I thought about that and I think it 's still possible , um , but I 'd rather try to get more regular meetings of types that we know about , and hear , then sort of a mish - mosh of a bunch of one {disfmarker} one - time {disfmarker} One offs ? Yeah , just because it would be very hard to process the data in all senses , both to get the , um {disfmarker} to figure out what type of meeting it is and to do any kind of higher level work on it , like well , I was talking to Morgan about things like summarization , or what 's this meeting about . I mean it 's very different if you have a group that 's just giving a report on what they did that week , versus coming to a decision and so forth . So . Then I was um , talking to Morgan about some {pause} new proposed work in this area , sort of a separate issue from what the student would be working on where I was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , sort of raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to sort of hot spots in the meeting , or things where stuff is going on that might be important for someone who didn't attend to {pause} listen to . And in that uh , regard , I thought we definitely w will need {disfmarker} it 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . So this {disfmarker} this meeting is one of them , although I 'm not sure I can participate if I {disfmarker} You know , I would feel very strange being part of a meeting that you were then analysing later for things like summarization . Mm - hmm . Um , and then there are some others that menti that Morgan mentioned , like the front - end meeting {pause} and maybe a networking {pause} group meeting . Right . Yep . Yeah , we 're {disfmarker} we 're hoping that they 'll let us start recording regularly . So {disfmarker} So if that were the case then I think we 'd have enough . So . Mm - hmm . But basically , for anything where you 're trying to get a summarization of some kind of meeting {disfmarker} {comment} {pause} meaning out of the meeting , um , it would be too hard to have fifty different kinds of meetings where we didn't really have a good grasp on what does it mean to summarize , Yeah . but {disfmarker} rather we should have different meetings by the same group but hopefully that have different summaries . And then we need a couple that {disfmarker} of {disfmarker} {pause} We don't wanna just have one group because that might be specific to that particular group , but @ @ three or four different kinds . Yeah , we have a lot of overlap between this meeting and the morning meeting . S So {disfmarker} Yeah . See , I 've never listened to the data for the front - end {pause} meeting . Yeah , we {disfmarker} we 've only had three . Yeah . So . OK . But maybe that 's enough . So , in general , I was thinking more data but also data where we hold some parameters constant or fairly similar , Mm - hmm . like a meeting about of people doing a certain kind of work where at least half the participants each time are the same . Um {disfmarker} Now , let {disfmarker} l l let me just give you the other side to that cuz I ca because I {disfmarker} I don't disagree with that , but I think there is a complimentary piece to it too . Uh , for other kinds of research , particularly the acoustic oriented research , I actually feel the opposite need . I 'd like to have lots of different people . Right . Right . As many people here a a and talking about the kind of thing that you were just talking about it would have uh too few people from my point of view . I 'd like to have many different speakers . So , um I think I would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , and {disfmarker} and uh , Mm - hmm . I mean , sure , if we can get more from them , fine , Mm - hmm . Right . but if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people . Yeah , I definitely agree with that . Yeah . Mm - hmm . Definitely . Yeah . Can I {disfmarker} can I say about that {disfmarker} that the {disfmarker} the issues that I think Adam and I raised were more a matter of advertising so that you get more native speakers . Because I think if you just say {disfmarker} an And in particular , my suggestion was to advertise to linguistics grad students because there you 'd have so people who 'd have proficiency enough in English that {disfmarker} that uh , it would be useful for {disfmarker} for purposes {disfmarker} You know . Mm - hmm . But you know , I think I 've been {disfmarker} I 've I {disfmarker} I 've gathered data from undergrads at {disfmarker} on campus and if you just post randomly to undergrads I think you 'd get such a mixed bag that it would be hard to know how much conversation you 'd have at all . And {disfmarker} and the English you 'd have {disfmarker} The language models would be really hard to build Well , you want to i because it would not really be {disfmarker} it would be an interlanguage rather than {pause} than a {disfmarker} Well , OK , uh , first place , I {disfmarker} I {disfmarker} I don't think we 'd just want to have random people come down and talk to one another , I think there should be a meeting that has some goal and point cuz I {disfmarker} I think that 's what we 're investigating , OK . It has to be a {disfmarker} a pre - existing meeting , {pause} like a meeting that would otherwise happen anyway . so Right . Yeah , yeah . OK . Yep . So I was {disfmarker} I was thinking more in terms of talking to professors uh , and {disfmarker} and {disfmarker} and uh , senior uh , uh , d and uh , doctoral students who are leading projects and offering to them that they have their {disfmarker} hold their meeting down here . That 's I think what we {disfmarker} and I agree with . Oh , interesting ! Yeah . Oh , I see . Oh , interesting ! Uh , that 's the first point . The second point is um I think that for some time now , going back through BeRP I think that we have had speakers that we 've worked with who had non - native accents and I th I think that {disfmarker} Oh , oh . I 'm not saying accents . u The accent 's not the problem . Oh , OK . No , it 's more a matter of uh , proficiency , e e just simply fluency . Yeah . I mean , I deal with people on {disfmarker} on campus who {disfmarker} I think sometimes people , undergraduates um in computer science uh , have language skills that make , you know {disfmarker} that their {disfmarker} their fluency and writing skills are not so strong . Oh ! You 're not talking about foreign language at all . Yeah . Yeah , just talking about . You 're just talking about {disfmarker} Well , e I just think , We all had the same thought . but you know , it 's like when you get into the graduate level , uh , no problem . I mean , I 'm not saying accents . Uh - huh . Yeah , then we 're completely gone . I 'm say I 'm saying fluency . Mm - hmm . It 's {disfmarker} {vocalsound} The {disfmarker} the habits are already burnt in . Well , yeah . I 'm just saying fluency . But {disfmarker} Well , I think that , um {disfmarker} I think that the only thing we should say in the advertisement is that the meeting should be held in English . And {disfmarker} and I think if it 's a pre - existing meeting and it 's held in English , {comment} I {disfmarker} I think it 's probably OK if a few of the people don't have uh , g particularly good English skills . Yeah . OK , now can I {disfmarker} can I say the other aspect of this from my perspective which is that um , there 's {disfmarker} there 's this {disfmarker} this issue , you have a corpus out there , it should be used for {disfmarker} for multiple things cuz it 's so expensive to put together . Right . Right . And if people want to approach {disfmarker} Um , i so I know {pause} e e {pause} You know this {disfmarker} The idea of computational linguistics and probabilistic grammars and all may not be the focus of this group , Uh - huh . but the idea of language models , which are fund you know generally speaking uh , you know , t t terms of like the amount of benefit per dollar spent or an hour invested in preparing the data , Mm - hmm . Mm - hmm . if you have a choice between people who are pr more proficient in {disfmarker} {nonvocalsound} um , i more fluent , more {disfmarker} more close to being academic English , then it would seem to me to be a good thing . I guess {disfmarker} I maybe {disfmarker} Hmm . I Because otherwise y you don't have the ability to have {disfmarker} Uh , so if {disfmarker} if you have a bunch of idiolects that 's the worst possible case . If you have people who are using English as a {disfmarker} as an interlanguage because they {disfmarker} they don't {disfmarker} uh , they can't speak in their native languages and {disfmarker} but their interlanguage isn't really a match to any existing , uh , language model , Uh - huh . this is the worst case scenario . Yeah . Yeah . Well , that 's pretty much what you 're going to have in the networking group . And {disfmarker} Right . because {disfmarker} because they {disfmarker} most {disfmarker} the network group is almost entirely Germans and Spaniards . Well Oh . But the thing is , I think that these people are of high enough level in their {disfmarker} in their language proficiency that {disfmarker} I see . And I 'm not objecting to accents . OK . I {disfmarker} I 'm {disfmarker} I 'm just thinking that we have to think at a {disfmarker} at a higher level view , could we have a language model , a {disfmarker} a grammar {disfmarker} a grammar , basically , that um , wo would be a {disfmarker} a possibility . Uh - huh . So y so if you wanted to bring in a model like Dan Jurafsky 's model , an and do some top - down stuff , it {disfmarker} to help th the bottom - up and merge the things or whatever , uh , it seems like um , I don't see that there 's an argument {disfmarker} Mm - hmm . I 'm {disfmarker} I {disfmarker} what I think is that why not have the corpus , since it 's so expensive to put together , uh , useful for the widest range of {disfmarker} of central corp things that people generally use corpora for and which are , you know , used in computational linguistics . Mm - hmm . That 's {disfmarker} that 's my point . Which {disfmarker} which includes both top - down and bottom - up . It 's difficult . OK . Yeah . OK , well , i i let 's {disfmarker} let 's see what we can get . I mean , it {disfmarker} it {disfmarker} I think that if we 're aiming at {disfmarker} at uh , groups of graduate students and professors and so forth who are talking about things together , and it 's from the Berkeley campus , probably most of it will be OK , Yes , that 's fine . That 's fine . Exactly . And my point in m in my note to Liz was I think that undergrads are an iff iffy population . but {disfmarker} OK . OK . I definitely agree with that , I mean , for this purpose . OK . Well , not to mention the fact that I would be hesitant certainly to take anyone under eighteen , probably even an anyone under twenty - one . Yeah . Grads and professors , fine . Yeah . So . Oh , you age - ist ! What 's that ? Well , age - ist . {comment} The \" eighteen \" is because of the consent form . Age - ist . Yeah . Right , Yeah . We 'd hafta get {disfmarker} find their parent to sign for them . \" Age - ist \" . Yeah . Yeah . Yes . Yeah , that 's true . So . I have a {disfmarker} uh , um , question . Well , Morgan , you were mentioning that Mari may not use the k equipment from IBM if they found something else , cuz there 's a {disfmarker} They 're {disfmarker} they 're {disfmarker} yeah , they 're d they 're uh {disfmarker} assessing whether they should do that or y do something else , hopefully over the next few weeks . Cuz I mean , one remote possibility is that if we st if we inherited that equipment , if she weren't using it , could we set up a room in the linguistics department ? And {disfmarker} and I mean , there {disfmarker} there may be a lot more {disfmarker} or {disfmarker} or in psych , or in comp wherever , in another building where we could um , record people there . I think we 'd have a better chance I think we 'd need a real motivated partner to do that . We 'd need to find someone on campus who was interested in this . Right , but {disfmarker} Right . But if there were such a {disfmarker} I mean it 's a remote possibility , then um , you know , one of us could you know , go up there and record the meeting or something rather than bring all of them down here . Yep . So it 's just a just a thought if they end up not using the {disfmarker} the hardware . Well , the other thing {disfmarker} Yeah , I mean the other thing that I was hoping to do in the first place was to turn it into some kind of portable thing so you could wheel it around . Right . Uh . But . Um , and {disfmarker} Well , I know that space is really scarce on {disfmarker} at least in CS . You know , to {disfmarker} to actually find a room that we could use regularly might actually be very difficult . Uh {disfmarker} Yeah . But you may not need a separate room , you know , That 's true . Yeah . the idea is , if they have a meeting room and they can guarantee that the equipment will be safe and so forth , and if one of us is up there once a week to record the meeting or something {disfmarker} True . Mm - hmm . Yep . Well , maybe John would let us put it into the phonology lab or something . Huh . Yep . You know . I {disfmarker} I think it 's not out of the question . Yeah , I think it would be interesting because then we could regularly get another meeting . Yeah . Um . So . another type of meeting . Yeah . Right . But I {disfmarker} I {disfmarker} I think you need , uh , another portable thing a another portable equipment to {disfmarker} to do , eh , more e easier the recording process , eh , out from ICSI . Right . Hmm . Yeah . Right . Eh and probably . I don't know . Yeah . Eh , if you {disfmarker} you want to {disfmarker} to record , eh , a seminar or a class , eh , in the university , you {disfmarker} you need {disfmarker} {vocalsound} It - it would be eh eh very difficult to {disfmarker} to put , {vocalsound} eh , a lot of , eh , head phones eh in different people when you have to {disfmarker} to record only with , eh , this kind of , eh , d device . Yeah . Yeah , but {disfmarker} I think if we {disfmarker} if we wanna just record with the tabletop microphones , that 's easy . Oh - yeah . Right ? That 's very easy , Ye - Yeah , yeah . but that 's not the corpus that we 're collecting . Yeah . Actually , that 's a int that raises an interesting point that came up in our discussion that 's maybe worth repeating . We realized that , um , when we were talking about this that , OK , there 's these different things that we want to do with it . So , um , it 's true that we wanna be selective in some ways , uh , the way that you were speaking about with , uh , not having an interlingua and uh , these other issues . But on the other hand , it 's not necessarily true that we need all of the corpus to satisfy all of it . So , a a as per the example that we wanna have a fair amount that 's done with a small n recorded with a small , uh , typ number of types of meetings But we can also have another part that 's , uh , just one or two meetings of each of a {disfmarker} of a range of them and that 's OK too . Uh , i We realized in discussion that the other thing is , what about this business of distant and close microphones ? I mean , we really wanna have a substantial amount recorded this way , that 's why we did it . But {pause} what about {disfmarker} For th for these issues of summarization , a lot of these higher level things you don't really need the distant microphone . Right , I mean , I c I think there 's {disfmarker} And you don't really need the close microphone , you mean . You actually don't . Yeah . Yea - yeah yeah , you actually don't really even need any fancy microphone . Which one did you mean ? You d You don't ne it doesn't {disfmarker} you just need some microphone , somewhere . Ye - Yeah . Yep . You can use found data . Tape recorder . Yeah . Yeah . Oh . Yeah . You {disfmarker} you can . You need some microphone , You can Mm - hmm . but I mean {disfmarker} use {disfmarker} Um , but I think that any {pause} data that we spend a lot of effort {nonvocalsound} to collect , Yeah . you know , each person who 's interested in {disfmarker} I mean , we have a cou we have a bunch of different , um , slants and perspectives on what it 's useful for , um , they need to be taking charge of making sure they 're getting enough of the kind of data that they want . Right . And {disfmarker} So in my case , um , I think there w there is enough data for some kinds of projects and not enough for others . Not enough for others , right . And so {nonvocalsound} I 'm looking and thinking , \" Well I 'd be glad to walk over and record people and so {nonvocalsound} forth if it 's {disfmarker} to help th in my interest . \" Mm - hmm . And other people need to do that for themselves , uh , h or at least discuss it so that we can find some optimal {disfmarker} Right . So that {disfmarker} Yeah . But I think that {disfmarker} I 'm raising that cuz I think it 's relevant exactly for this idea up there that if you think about , \" Well , gee , we have this really complicated setup to do , \" well maybe you don't . Yeah . For some of it . Maybe if {disfmarker} if {disfmarker} If really all you want is to have a {disfmarker} a {disfmarker} a recording that 's good enough to get a {disfmarker} {vocalsound} uh , a transcription from later , you just need to grab a tape recorder and go up and make a recording . Right . Yep . I mean , we {disfmarker} we could have a fairly {disfmarker} We could just get a DAT machine and {disfmarker} Well , I agree with {nonvocalsound} Jane , though , on the other hand that {disfmarker} Yeah . So that might be true , you may say for instance , summarization , or something that sounds very language oriented . You may say well , \" Oh yeah , you just do that from transcripts of a radio show . \" I mean , you don't even need the speech signal . Right . But what you {disfmarker} what I was thinking is long term what would be neat is to be able to pick up on um {disfmarker} Suppose you just had a distant microphone there and you really wanted to be able to determine this . There 's lots of cues you 're not gonna have . Right . Yeah . So I {pause} do think that long term you should always try to satisfy the greatest number of {disfmarker} of interests and have this parallel information , which is really what makes this corpus powerful . Yeah . Special ? Yep . I {disfmarker} I {disfmarker} I {disfmarker} I {disfmarker} I agree . Otherwise , you know , lots of other sites can propose {disfmarker} individual studies , so {disfmarker} Uh but I {disfmarker} I think that the uh {vocalsound} i We can't really underestimate the difficulty {disfmarker} shouldn't really u underestimate the difficulty of getting a setup like this up . Yep . And so , {disfmarker} uh it took quite a while to get that together and to say , \" Oh , we 'll just do it up there , \" {disfmarker} OK . If you 're talking about something simple , where you throw away a lot of these dimensions , then you can do that right away . Talking about something that has all of these different facets that we have here , it won't happen quickly , it won't be easy , and there 's all sorts of issues about th you know {vocalsound} keeping the equipment safe , or else hauling it around , and all sorts of o So then maybe we should {nonvocalsound} {pause} try to bring people here . Here . I think the first priority should be to pry {comment} to get {disfmarker} try to get people to come here . I mean , that 's that 's {disfmarker} OK , so We 're set up for it . Mm - hmm . The room is {disfmarker} is really , uh , underused . OK . Uh {disfmarker} Right . I thought the free lunch idea was a great idea . Yeah , I thought so too . Yeah . Free lunch is good . Yeah , I {disfmarker} And I think we can get people to come here , that {disfmarker} But the issue is you definitely wanna make sure that the kind of group you 're getting is the right group so that you don't waste a lot of your time {nonvocalsound} and the overhead in bringing people down . Mm - hmm . No crunchy food . Yeah . So {disfmarker} {comment} Well , it would be {pause} lunch afterwards . Well , I was thinking , lunch after . Yeah . Right . And they 'd have to do their digits or they don't get dessert . Yep . Yeah , they have to do their digits or they don't {comment} get {disfmarker} they don't {comment} get their food . Yeah . Um , I had a {disfmarker} I spoke with some people up at Haas Business School who volunteered . Yeah Should I pursue that ? Oh , definitely , yeah . Yeah . So . They {disfmarker} they originally {disfmarker} They 've decided not to do {disfmarker} go into speech . Yeah . So I 'm not sure whether they 'll still be so willing to volunteer , but I 'll send an email and ask . Tell them about the free lunch . I 'll tell them about the free lunch . Yeah . And they 'll say there 's no such thing . Yeah . So . I 'd love to get people that are not linguists or engineers , cuz these are both weird {disfmarker} Right . Yeah . Yeah . The {disfmarker} the {disfmarker} {vocalsound} The oth the other h well , I know , I shouldn't say that . That 's alright . No , the they {disfmarker} they 're very weird . We need a wider sampling . \" Beep . \" Yeah . Uh , \" beep \" The problem with engineers is \" beep . \" Uh , the {disfmarker} the {disfmarker} They make funny sounds . The o the o the other {disfmarker} The other thing is , uh , that we {disfmarker} we talked about is give to them {disfmarker} uh , burn an extra CD - ROM . Yep . Let them have their meeting . and give them {disfmarker} So if they want a {disfmarker} {nonvocalsound} basically and audio record of their {disfmarker} Well , I thought that was {disfmarker} I thought he meant , \" Give them a music CD , \" like they g {vocalsound} Then he said a CD of the {disfmarker} of their speech Oh . and I guess it depends of what kind of audience you 're talking to , but {disfmarker} {vocalsound} You know , I personally {nonvocalsound} would not want a {nonvocalsound} CD {comment} of my meeting , Mmm . Of the meeting ? but {vocalsound} maybe {disfmarker} yeah , {pause} maybe you 're If you 're having some planning meeting of some sort and uh you 'd like {disfmarker} right . {comment} Right . Right . Oh , that 's a good idea . It 'd be fun . I think it would just be fun , you know , if nothing else , you know . Yeah . Yeah . Right . It 's a novelty item . But it als It {disfmarker} it {disfmarker} it also I think builds up towards the goal . Right . We 're saying , \" Look , you know , you 're gonna get this . Is - is isn't that neat . Then you 're gonna go home with it . It 's actually p It 's probably gonna be pretty useless to you , Yep . but you 'll ge appreciate , you know , where it 's useful and where it 's useless , Right . and then , we 're gonna move this technology , so it 'll become useful . \" Yeah . So . No , I think that 's a great idea , actually . What if you could tell them that you 'll give them the {disfmarker} the transcripts when they come back ? Alth But we might need a little more to incentivize them , {comment} that 's all . Oh , yeah . I mean , anyone can have the transcripts . So . I thought we could point that out . Oh yeah . Yeah . Well , that 's interesting . I hav I have to uh raise a little eensy - weensy concern about doing th giving them the CD immediately , because of these issues of , you know , this kind of stuff , {comment} where maybe {disfmarker} {vocalsound} You know ? Good point . That 's a very good point . So . So we can {disfmarker} so we can {disfmarker} We could burn it after it 's been cleared with the transcript stage . r Right . And then they {disfmarker} they get a CD , but just not the same day . Oh , right . Yeah , that 's right . If {disfmarker} It should be the same CD - ROM that we distribute publically , That 's a good point . Right , it can't be the internal one . right ? Although it 's {disfmarker} Otherwise they 're not allowed to play it for anyone . There we go . That 's right . Oh , I like that . Well put . Well put . So , after the transcript screening phase . Yeah , that 's true . Things have been weeded out . Otherwise we 'd need two lawyer stages . Yeah , that 's right , say {comment} \" Yeah , well , I got this CD , and , Your Honor , I {disfmarker} \" Yeah . That 's a good point . Yeah so that 's {disfmarker} so let 's start with Haas , and Yeah . Sorry to have to {disfmarker} {nonvocalsound} Sorry I have to {pause} leave . Oh , that 's fine . I will be here full - time next week . OK , see you . OK . No . Bye . That 's alright . See you . OK . See you . So , uh {disfmarker} Let 's see . So that was that topic , and {vocalsound} then um , I guess another topic would be {vocalsound} where are we in the whole disk resources {pause} question for {disfmarker} We are slowly slowly getting to the point where we have uh enough sp room to record meetings . So I uh did a bunch of archiving , and still doing a bunch of archiving , I {disfmarker} I 'm in the midst of doing the P - files from uh , {vocalsound} Broadcast News . and it took eleven hours {comment} {vocalsound} to do {disfmarker} to uh copy it . Eleven ? And it 'll take another eleven to do the clone . Where did you copy it to ? Well , it 's Abbott . It 's Abbott , so it just {disfmarker} But it 's {disfmarker} it 's a lot of data . Sk - It 's copying from one place on Abbott to another place on Abbott ? Tape . Tape ? Oh , on the tape . Oh ! I did an archive . I 'm sorry . Ah ! So I 'm archiving it , and then I 'm gonna delete the files . Oh . So that will give us ten gigabytes of free space . Eleven hours ? Wow ! Oh . Yeah , the archiving m {pause} program does take a long time . And {disfmarker} and {disfmarker} Yeah . Yep . And so one That {disfmarker} that will be done , like , in about two hours . And so uh , {vocalsound} at that point we 'll be able to record five more meetings . So . Yeah . One thing {disfmarker} The good news about that {disfmarker} that is that once {disfmarker} once it 's archived , it 's pretty quick to get back . Yeah . Is it ? I mean , it {disfmarker} it {disfmarker} it {disfmarker} The other direction is fast , but this direction is really slow . Right . Hmm . Well , especially because I 'm generating a clone , also . Yeah . So . And that takes a while . Yeah . Yeah , OK . Generating a clone ? Yeah , that 's a good point . Two copies . Yeah . Oh ! One offsite , one onsite . Oh ! Hunh ! S Now , what will uh {disfmarker} Is the plan to g {pause} to {disfmarker} So {pause} stuff will be saved , it 's just that you 're relocating it ? I mean , so we 're gonna get more disk space ? Or did I {disfmarker} ? No , the {disfmarker} the {disfmarker} these are the P - files from Broadcast News , which are regeneratable {disfmarker} regeneratable OK . Oh , good . I see . um , if we really need to , but we had a lot of them . And {disfmarker} for the full , uh , hundred forty hour sets . OK . And so they {disfmarker} they were two gigabytes per file and we had six of them or something . Yeah . Wow . Wow . W w we are getting more space . We are getting , uh , another disk rack and {disfmarker} and four thirty - six gigabyte disks . Uh {pause} so {pause} uh {pause} but that 's not gonna happen instantaneously . Wonderful . Or maybe six . Or maybe six ? The SUN , ha uh , takes more disks than the Andatico one did . The SUN rack takes {disfmarker} {comment} Th - One took four and one took six , or maybe it was eight and twelve . Whatever it was , it was , {pause} you know , fifty percent more . How many {disfmarker} How much {disfmarker} Is there a difference in price or something ? Well , what happened is that we {disfmarker} we bought all our racks and disks from Andatico for years , according to Dave , and Andatico got bought by another company and doubled their prices . Oh ! Oh . And so , uh , we 're looking into other vendors . \" We \" {disfmarker} By \" we \" of course I mean Dave . Wow . Mm - hmm . So . Hmm . I 've been looking at the , uh , Aurora data and , um , first {disfmarker} first look at it , there were basically three directories on there that could be moved . One was called Aurora , one was Spanish , which was Carmen 's Spanish stuff , and the other one was , um , SPINE . SPINE . And so , um , I wrote to Dan and he was very concerned that the SPINE stuff was moving to a non - backed - up disk . So , um , I realized that well , probably not all of that should be moved , just {pause} the {pause} CD - ROM type data , the {disfmarker} {pause} the static data . So I moved that , and then um , I asked him to check out and see if it was OK . before I actually deleted the old stuff , um , but I haven't heard back yet . I told him he could delete it if he wanted to , I haven't checked {pause} today to see if he 's deleted it or not . And then Carmen 's stuff , I realized that when I had copied all of her stuff to XA , I had copied stuff there that was dynamic data . And so , I had to redo that one and just copy over the static data . And so I need to get with her now and delete the old stuff off the disk . And then I lo haven't done any of the Aurora stuff . I have to meet with , uh , Stephane to do that . So . So , but , uh y you 're figuring you can record another five meetings or something with the space that you 're clearing up from the Broadcast News , but , we have some other disks , some of which you 're using for Aurora , but are we g do we have some other {disfmarker} other space now ? Yep . So , so , uh , we have space on the current disk right now , where Meeting Recorder is , and that 's probably enough for about four meetings . Yeah . Is that the one that has {disfmarker} is that DC ? Yeah . So . Yep . No , no , well , it 's wherever the Meeting Recorder currently is . I think it 's DI . OK , I {disfmarker} but the stuff I 'm moving from Aurora is on the DC disk that we {disfmarker} I don't remember . Th - I think it 's DC - It 's whatever that one is . OK , DC . I just don't remember , it might be DC . Yeah . And that has enough for about four more meetings right now . Yeah , I mean we were at a hundred percent and then we dropped down to eighty - six for reasons I don't understand . Mm - hmm . Um , someone deleted something somewhere . And so we have some room again . And then with Broadcast News , that 's five or six more meetings , so , you know , we have a couple weeks . Uh , so , yeah , I think {disfmarker} I think we 're OK , until we get the new disk . OK . So should , um {disfmarker} One question I had for you was , um , we need {disfmarker} {pause} we sh probably should move the Aurora an and all that other stuff off of the Meeting Recorder disk . Is there another backed - up {pause} disk that you know of that would {disfmarker} ? We should put it onto the Broadcast News one . That 's probably the best thing to do . And that way we consolidate Meeting Recorder onto one disk {pause} rather than spreading them out . OK . Right . Right . Do you know what {disfmarker} happen to know what disk that is off {disfmarker} ? OK . No . I mean , I can tell you , I just don't know off the top of my head . Yeah . OK . Alright , I 'll find out from you . But , so we could ' jus just do that at the end of today , once the archive is complete , and I 've verified it . OK . Cuz that 'll give us plenty of disk . Uh , OK , @ @ {comment} So , uh , then I guess th the last thing I 'd had on my {disfmarker} my agenda was just to hear {disfmarker} hear an update on {vocalsound} what {disfmarker} what Jose has been doing , Uh - huh . OK . so I have , eh , {vocalsound} The result of my work during the last days . OK . Thank you for your information because I {disfmarker} I read . Eh , and the {disfmarker} the last , eh , days , eh , I work , eh , in my house , eh , in a lot of ways and thinking , reading eh , different things about the {disfmarker} the Meeting Recording project . Yeah . Uh - huh . And I have , eh , some ideas . Eh , this information is very {disfmarker} very useful . Because {vocalsound} you have the {disfmarker} the {disfmarker} the distribution , now . I 'm glad to hear it . Glad to hear it . But for me , eh is interesting because , eh , eh , here 's i is the demonstration of the overlap , eh , {pause} problem . I 've seen it already . It 's a real problem , {comment} a frequently problem {comment} uh , because you have overlapping zones eh , eh , eh , all the time . Yeah . Yeah . Yep . Yeah . Throughout the meeting . Eh , by a moment I have , eh , nnn , the , eh , {pause} n I {disfmarker} I did a mark of all the overlapped zones in the meeting recording , with eh , a exact {pause} mark . Mm - hmm . Oh , you did that by hand ? Heh ? That 's eh , yet b b Yeah , by {disfmarker} b b by hand {disfmarker} by hand because , eh , {vocalsound} eh {disfmarker} \" Why . \" Can I see that ? Can I get a copy ? Oh . My {disfmarker} my idea is to work {disfmarker} Wow ! I {disfmarker} I {disfmarker} I do I don I don't @ @ {disfmarker} I don't know , eh , if , eh , it will be possible because I {disfmarker} I {disfmarker} I haven't a lot {disfmarker} eh , enough time to {disfmarker} to {disfmarker} to work . uh , only just eh , six months , as you know , but , eh , my idea is , eh , is very interesting to {disfmarker} to work {pause} in {disfmarker} in the line of , eh , automatic segmenter . Mm - hmm . Eh but eh , eh , in my opinion , {pause} we need eh , eh , a reference {pause} eh session to {disfmarker} t to {disfmarker} to evaluate the {disfmarker} the {disfmarker} the tool . Yes , absolutely . And so are you planning to do that or have you done that already ? And {disfmarker} No , no , with i Have you done that or are you planning to do that ? Sorry ? No , I {disfmarker} I {disfmarker} plan to do that . OK . Darn ! I plan {disfmarker} I plan , but eh , eh , the idea {vocalsound} is the {disfmarker} is the following . Now , {vocalsound} eh , I need ehm , {vocalsound} to detect eh all the overlapping zones exactly . I {disfmarker} I will {disfmarker} I will eh , talk about eh , {pause} in the {disfmarker} in the blackboard about the {disfmarker} my ideas . Yeah . Mm - hmm . Duration . Eh , um , {vocalsound} {vocalsound} eh {disfmarker} This information eh , with eh , exactly time marks eh , for the overlapping zones {vocalsound} eh {disfmarker} overlapping zone , and eh , a speaker {disfmarker} a {disfmarker} a pure speech eh , eh , speaker zone . I mean , eh zones eh of eh speech of eh , one speaker without any {disfmarker} any eh , noise eh , any {disfmarker} any acoustic event eh that eh , eh , w eh , is not eh , speech , real speech . And , I need t true eh , silence for that , because my {disfmarker} my idea is to {disfmarker} to study the nnn {disfmarker} the {disfmarker} {vocalsound} the set of parameters eh , what , eh , are more m more discriminant to eh , classify . Right . the overlapping zones in cooperation with the speech {pause} eh zones . The idea is {pause} to eh {disfmarker} to use {disfmarker} eh , I 'm not sure to {disfmarker} eh yet , but eh my idea is to use a {disfmarker} a cluster {pause} {vocalsound} eh algorithm or , nnn , a person strong in neural net algorithm to eh {disfmarker} to eh study what is the , eh , the property of the different feat eh feature , eh , to classify eh speech and overlapping eh speech . Mmm . And my idea is eh , it would be interesting to {disfmarker} to have eh , {vocalsound} a control set . And my control set eh , will be the eh , silence , silence without eh , any {disfmarker} any noise . Mm - hmm . Which means that we 'd still {disfmarker} You 'd hear the {disfmarker} Yeah , fans . Yeah , acoustic with this . {comment} With {disfmarker} with , yeah , the background . Yeah . {comment} That 's interesting . This is like a ground level , with {disfmarker} It 's not it 's not total silence . Eh , I {disfmarker} I mean eh , noise eh , eh claps eh , tape clips , eh , the difference eh , Mm - hmm . eh , eh , event eh , which , eh , eh , has , eh eh , a hard effect of distorti spectral distortion in the {disfmarker} in the eh {pause} speech . So {disfmarker} so you intend to hand - mark those and exclude them ? Mm - hmm . Mm - hmm . Yeah , I have mark in {disfmarker} in {disfmarker} in {disfmarker} in that {disfmarker} Not in all {disfmarker} in all the {disfmarker} the file , Mm - hmm . only eh , eh , nnn , {pause} mmm , I have eh , ehm {pause} I don't remind {comment} what is the {disfmarker} the {disfmarker} the {disfmarker} the quantity , but eh , I {disfmarker} I have marked enough speech on over and all the overlapping zones . I have , eh , {pause} two hundred and thirty , more or less , overlapping zones , and is similar to {disfmarker} to this information , Whew ! Mm - hmm . Great . Great . because with the program , I cross {pause} the information of uh , of Jane {comment} with eh , my my segmentation by hand . And {pause} is eh , mor more similar . Excellent . Glad to hear it . Good . But {disfmarker} Sorry , sorry . Go ahead . And the {disfmarker} the idea is , eh , {vocalsound} I {disfmarker} I will use , eh , {disfmarker} I want {disfmarker} {pause} My idea is , eh , {vocalsound} {vocalsound} to eh {disfmarker} {comment} {nonvocalsound} to classify . I should 've {pause} got the digital camera . Oh well . I {disfmarker} I need eh , the exact eh , mark of the different , eh , eh , zones because I {disfmarker} I want to put , eh , for eh , each frame a label {pause} indicating . It 's a sup supervised and , eh , hierarchical clustering process . I {disfmarker} I {disfmarker} I put , eh , eh , for each frame {nonvocalsound} a label indicating what is th the type , what is the class , eh , which it belong . Mm - hmm . Eh , I mean , the class you will {nonvocalsound} overlapping speech \" overlapping \" is a class , eh , \" speech \" {nonvocalsound} @ @ the class {pause} that 's Nonspeech . These will be assigned by hand ? a I {disfmarker} I {disfmarker} I ha I h I {disfmarker} I put the mark by hand , Based on the {disfmarker} Uh - huh . because , eh , {vocalsound} my idea is , eh , in {disfmarker} in the first session , I need , eh , {pause} I {disfmarker} I need , eh , to be sure that the information eh , that , eh , I {disfmarker} I will cluster , is {disfmarker} is right . Because , eh , eh , if not , eh , I will {disfmarker} I will , eh , return to the speech file to analyze eh , what is the problems , Well , training , and validation . Sure . Mm - hmm . eh . And {vocalsound} I {disfmarker} I 'd prefer {disfmarker} I would prefer , the to {disfmarker} to have , eh , this labeled automatically , but , eh , eh , fro th I need truth . You need truth . Hmm . Yeah , but this is what you 're starting with . Yeah . Yeah . Yeah . Yeah . I 've gotta ask you . So , uh , the difference between the top two , i So {disfmarker} so {disfmarker} I start at the bottom , so \" silence \" is clear . By \" speech \" do you mean speech by one sp by one person only ? Speech {disfmarker} Yeah . So this is un OK , and then and then the top includes people speaking at the same time , or {disfmarker} or a speaker and a breath overlapping , someone else 's breath , or {disfmarker} or clicking , overlapping with speech {disfmarker} So , that {disfmarker} that 's all those possibilities in the top one . Yeah . Yeah . Is {disfmarker} One or two or more . One , two , three . but No , by th by the moment n Yeah . Yeah . Yeah . Yeah . Yeah . OK . Eh , in the first moment , because , eh , eh , I {disfmarker} I have information , eh , of the overlapping zones , eh , information about if the , eh , overlapping zone is , eh , from a speech , clear speech , from a one to a two eh speaker , {pause} or three speaker , or is {disfmarker} is the zone where the breath of a speaker eh , overlaps eh , onto eh , a speech , another , especially speech . So it 's basi it 's basically speech wi som with {disfmarker} with something overlapping , which could be speech but doesn't need to be . No , no , es especially {pause} eh , overlapping speech {pause} from , eh , different eh , eh , speaker . Eh {disfmarker} No , but there 's {disfmarker} but , I think she 's saying \" Where do you {disfmarker} In these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? \" Ah ! Which category do you put that in ? Yeah , that 's right . That 's my question . Yeah . Yeah , he here I {disfmarker} I put eh speech from eh , from , eh , one speaker {pause} without , eh , eh , any {disfmarker} any {disfmarker} any events more . Oh ! Right , so where do you put speech from one speaker that does have a nonspeech event at the same time ? Where ? Where {disfmarker} What is the class ? Which catege which category ? Like a c No . By the moment , no . Yeah , yeah , that 's what he was saying before . For {disfmarker} for the {disfmarker} by the @ @ no , @ @ because I {disfmarker} I {disfmarker} I {disfmarker} I want to limit the {disfmarker} the {disfmarker} nnn , {vocalsound} the {disfmarker} the study . Oh , so you {disfmarker} not {disfmarker} not marked . Oh . So you don't {disfmarker} i i it 's not in that {disfmarker} OK . Got it . Fine . So {disfmarker} so {disfmarker} So you 're not using all of the data . Yeah , so that 's what he was saying before , is that he excluded those . The {disfmarker} All {disfmarker} I {disfmarker} Exactly . Yeah . Yeah , you mean {disfmarker} Yeah . So you 're ignoring overlapping events unless they 're speech with speech . Yeah , be Yeah . Yeah , that 's fine . OK . \" Why ? Why ? What 's the reason ? \" because {pause} i it 's the first study . the first Oh , no {disfmarker} no , it 's a perfectly sensible way to go . We just wondered {disfmarker} trying to understand what {disfmarker} what you were doing . We 're just Yeah . Yeah . OK . Yeah cuz you 've talked about other overlapping events in the past . Yeah . So , this is {disfmarker} this is {disfmarker} a subset . Yeah . In the {disfmarker} in the future , the {disfmarker} the idea is to {disfmarker} to extend {pause} the class , Is {disfmarker} is {disfmarker} to consider all the {disfmarker} all the information , you {disfmarker} you mentioned before Yeah . Yeah , I {disfmarker} I don't think we were asking for that . OK . but eh , the {disfmarker} the first idea {disfmarker} Because eh , I don't know {pause} what hap what will happen {comment} with the study . We were jus just trying to understand {disfmarker} Yeah . Yeah , we just wanted to know what the category was here . Right . Yeah . Sure . Is your silence category pure silence , or {disfmarker} ? Yeah . i it 's pure {disfmarker} What if there was a door - slam or something ? No , no , it 's pure silence . Pure silence . It 's the control set . OK . OK ? It 's the control set . It 's pure si pure silence {comment} with the {disfmarker} with the machine on the {disfmarker} on the roof . What you {disfmarker} Well {disfmarker} w {vocalsound} I {disfmarker} I think what you m I think what you mean {vocalsound} is that it 's nonspeech segments that don't have impulsive noises . With the fan . Yeah . Right ? Cuz you 're calling {disfmarker} what you 're calling \" event \" is somebody coughing {vocalsound} or clicking , or rustling paper , or hitting something , which are impulsive noises . Yeah . But steady - state noises are part of the background . Yeah . Which , are being , included in that . Right ? h here yet , yet I {disfmarker} I {disfmarker} I {disfmarker} I {disfmarker} I think {disfmarker} I {disfmarker} I think , eh , there are {disfmarker} that {disfmarker} some kind of noises that , eh , don't {disfmarker} don't wanted to {disfmarker} to be in that , eh , in that control set . Yeah . So it 's like a signal - noise situation . Yeah . Well {disfmarker} Yeah . But I prefer , I prefer at {disfmarker} at the first , eh , the {disfmarker} the silence with eh , this eh this kind of the {disfmarker} of eh {disfmarker} of noise . Well , steady state . Right , it 's {disfmarker} I mean , it 's {disfmarker} \" Background \" might be {disfmarker} might be a better word than \" silence \" . Yeah . It 's just sort of that {disfmarker} the {disfmarker} the background acoustic {disfmarker} Yeah . Right . So {disfmarker} Fine . Go on . Yeah . Yeah . Is {disfmarker} is {disfmarker} is only {disfmarker} OK . Yeah . And , um , with this information {vocalsound} The idea is eh , eh , nnn , I have a label for {disfmarker} for each , eh , frame and , eh with a cluster eh {disfmarker} algorithm I {disfmarker} and {disfmarker} Well , we needed to get the categories , yeah . Sorry . And eh I am going {pause} to prepare a test bed , eh , well , eh , a {disfmarker} a set of {pause} feature structure eh , eh , models . Right . And {pause} my idea is \" Tone \" , whatever . so {disfmarker} so {disfmarker} on {disfmarker} because I have a pitch extractor yet . Right . Mm - hmm . I have to {disfmarker} to test , but eh I {disfmarker} You have your own ? Yeah , yeah , yeah . Oh ! I ha I have prepare . Is a modified version of {disfmarker} of {disfmarker} of a pitch tracker , eh , from , eh , Standar - eh Stanford University {disfmarker} in Stanford ? No . From , eh , em , {vocalsound} Cambridge {pause} University . Oh ! What 's it written in ? Eh , em , I {disfmarker} I {disfmarker} I don't remember what is the {disfmarker} the name of the {disfmarker} of the author , because I {disfmarker} I have several {disfmarker} I have eh , eh , em , eh , library tools , from eh , Festival and {disfmarker} of {disfmarker} from Edinburgh eh , from Cambridge , eh , and from our department . Ah . Mm - hmm . Mm - hmm . And {disfmarker} And I have to {disfmarker} because , {vocalsound} in general the pitch tracker , doesn't work {comment} {vocalsound} very well and {disfmarker} Bad . Right . But , you know , as a feature , it might be OK . So , we don't know . Yeah . Yeah . This {disfmarker} this is {disfmarker} And {pause} th the idea is to {disfmarker} to , eh , to obtain , eh , {pause} for example , eh , {pause} {vocalsound} eh diff eh , eh , different {disfmarker} well , no , a great number of eh FEC for example , eh , {pause} eh , twenty - five , eh , thirty {disfmarker} thirty parameters , eh , for {disfmarker} for each one . And in a first eh , nnn , step in the investi in the research in eh , my idea is try to , eh , to prove , what is the performance of the difference parameter , eh {pause} to classify {pause} the different , eh , what is the {disfmarker} the {disfmarker} the {disfmarker} the front - end approach to classify eh , the different , eh , frames of each class {pause} eh and what is the {disfmarker} the , nnn , nnn , nnn , eh , what is the , the error {pause} eh , of the data Supervised clustering . Mm - hmm . This is the {disfmarker} the eh , first idea Mm - hmm . and the second {pause} is try to {disfmarker} eh , to use {pause} some ideas eh , similar to the linear discriminant analysis . Mm - hmm . Eh ? Eh , similar , because the the idea is to {disfmarker} to study {pause} what is the contribution of eh , each parameter to the process of classify correctly the different {disfmarker} the different parameters . Mm - hmm . What sort of classifier ar ? Eh , the {disfmarker} the {disfmarker} the classifier is {disfmarker} nnn by the moment is eh {disfmarker} is eh , similar , nnn , that the classifier used eh , in a quantifier {disfmarker} vectorial quantifier is eh , used to {disfmarker} to eh , some distance {pause} to {disfmarker} to put eh , a vector eh , in {disfmarker} in a class different . Unimodal ? Is {disfmarker} Yeah ? W with a model , is {disfmarker} is only to cluster using a eh , @ @ or a similarity . Mm - hmm . So is it just one cluster per {disfmarker} A another possibility it to use eh a netw netw a neural network . Right . But eh what 's the p {vocalsound} What is my idea ? What 's the problem I {disfmarker} I {disfmarker} I {disfmarker} I see in {disfmarker} in {disfmarker} in {disfmarker} {vocalsound} if you {disfmarker} you use the {disfmarker} the neural network ? If {disfmarker} w when {pause} this kind of eh , mmm , cluster , clustering algorithm to can test , to can eh observe what happened you {disfmarker} you can't {disfmarker} you can't eh , eh put up with your hand {comment} in the different parameter , Right , you can't analyse it . but eh {disfmarker} If you use a neural net is {disfmarker} is a good idea , but eh you don't know what happened in the interior of the neural net . Well , actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are . Yeah . It 's hard to {disfmarker} w w what you {disfmarker} It 's hard to tell on a neural net is what 's going on internally . Yeah . But it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized . Yeah . Yeah . Um , but {disfmarker} Well , using something simpler first I think is probably fine . Well , this isn't tru if {disfmarker} if {disfmarker} if you really wonder what different if {disfmarker} if {disfmarker} Yeah . Decision tree . But {disfmarker} Yeah , then a decision tree is really good , but the thing is here he 's {disfmarker} he 's not {disfmarker} he 's not like he has one you know , a bunch of very distinct variables , like pitch and this {disfmarker} he 's talking about , like , a all these cepstral coefficients , and so forth , Right . Yeah . Yeah . Right . Yeah . in which case a a any reasonable classifier is gonna be a mess , and it 's gonna be hard to figure out what {disfmarker} what uh {disfmarker} And {disfmarker} Right . I {disfmarker} I {disfmarker} I will include too the {disfmarker} the {disfmarker} the differential de derivates too . Deltas , Yeah . yeah . So . I {disfmarker} I mean , I think the other thing that one {disfmarker} I mean , this is , I think a good thing to do , to sort of look at these things at least {disfmarker} See what I 'd {disfmarker} I 'd {disfmarker} Let me tell you what I would do . I would take just a few features . Instead of taking all the MFCC 's , or all the PLP 's or whatever , I would just take a couple . Yeah . OK ? Like {disfmarker} like C - one , C - two , something like that , so that you can visualize it . Yeah . and look at these different examples and look at scatter plots . Yeah . OK , so before you do {disfmarker} build up any kind of fancy classifiers , just take a look in two dimensions , at how these things are split apart . Yeah . That I think will give you a lot of insight of what is likely to be a useful feature when you put it into a more complicated classifier . Yeah . And the second thing is , once you actually get to the point of building these classifiers , {vocalsound} @ @ what this lacks so far is the temporal properties . So if you 're just looking at a frame and a time , you don't know anything about , you know , the structure of it over time , and so you may wanna build @ @ {disfmarker} build a Markov model of some sort uh , or {disfmarker} or else have features that really are based on um on {disfmarker} on some bigger chunk of time . Yeah . Context window ? Yeah . Yeah . But I think this is a good place to start . But don't uh anyway , this is my suggestion , is don't just , you know , throw in twenty features at it , the deltas , and the delta del and all that into some classifier , even {disfmarker} even if it 's K - nearest - neighbors , you still won't know Yeah . Yeah , yeah . what it 's doing , even {disfmarker} You know it 's Uh , I think to know what it 's {disfmarker} to have a better feeling for what it 's Yep . look at {disfmarker} at som some picture that shows you , \" Here 's {disfmarker} These things uh , uh are {disfmarker} offer some separation . \" {vocalsound} And , uh , in LPC , uh , the thing to particularly look at is , I think {disfmarker} is something {vocalsound} like , uh , the residual {disfmarker} Yeah . Um So . Yeah . S Can I ask ? It strikes me that there 's another piece of information um , that might be useful and that 's simply the transition . So , w if you go from a transition of silence to overlap versus a transition from silence to speech , there 's gonna be a b a big informative area there , it seems to me . Yeah , because {disfmarker} Yeah yeah . Yeah . Yeah . I {disfmarker} Yeah . But eh I {disfmarker} I {disfmarker} Is my my {disfmarker} my own vision , {vocalsound} of the {disfmarker} of the project . So , some sort of {disfmarker} That 's {disfmarker} Mm - hmm . I {disfmarker} eh the {disfmarker} the Meeting Recorder project , for me , has eh , two {vocalsound} eh , w has eh several parts , several p {vocalsound} objective Mm - hmm . eh , because it 's a {disfmarker} a great project . But eh , at the first , in the acoustic , eh , eh , parts of the project , eh I think {pause} you eh {disfmarker} we have eh {vocalsound} {pause} two main eh objective . One {disfmarker} one of these is to {disfmarker} eh to detect the change , the acoustic change . And {vocalsound} for that , if you don't use , eh , {vocalsound} eh , a speech recognizer , eh broad class , or not broad class to {disfmarker} to try to {disfmarker} to {pause} {pause} {vocalsound} to label the different frames , I think {pause} the Ike criterion {pause} or BIC criterion eh will be enough to detect the change . OK . And {disfmarker} Probably . {comment} I {disfmarker} I {disfmarker} I {disfmarker} I would like to {disfmarker} to t prove . Uh , probably . When you you have , eh , eh s eh the transition of speech or {disfmarker} or silence eh to overlap zone , this criterion is enough with {disfmarker} {pause} probably with , eh , this kind of , eh , eh the {disfmarker} the {disfmarker} the more eh use eh {disfmarker} use eh {disfmarker} used eh em {pause} normal , regular eh parameter MF - MFCC . you {disfmarker} you have to {disfmarker} to {disfmarker} to find {disfmarker} you can find the {disfmarker} the mark . You can find the {disfmarker} nnn , the {disfmarker} the acoustic change . But eh eh I {disfmarker} I understand that you {disfmarker} your objective is {pause} to eh classify , to know that eh that zone {pause} not is only {comment} a new zone in the {disfmarker} in the file , that eh you have eh , but you have to {disfmarker} to {disfmarker} to know that this is overlap zone . because in the future you will eh try to {disfmarker} to process that zone with a non - regular eh eh speech recognizer model , I suppose . Mm - hmm . you {disfmarker} you will pretend {comment} to {disfmarker} to {disfmarker} to process the overlapping z eh zone with another kind of algorithm Mm - hmm . because it 's very difficult to {disfmarker} to {disfmarker} to obtain the transcription {pause} from eh using eh eh a regular , normal speech recognizer . That , you know , {pause} I {disfmarker} I {disfmarker} I think is the idea . And so {vocalsound} eh the , nnn {disfmarker} the {disfmarker} {nonvocalsound} the system {pause} eh will have two models . Clustering . A model to detect more acc the mor most accurately possible that is p uh , will be possible the , eh {disfmarker} the mark , the change and another {disfmarker} another model will @ @ {pause} or several models , to try s but {disfmarker} eh several model eh robust models , sample models to try to classify the difference class . OK . I 'm {disfmarker} I 'm {disfmarker} I 'm sorry , I didn't understand you {disfmarker} what you said . What {disfmarker} what model ?  Eh , the {disfmarker} the classifiers of the of the n to detect the different class to the different zones before try to {disfmarker} to recognize , eh with eh {disfmarker} to transcribe , with eh a speech recognizer . Mm - hmm . And my idea is to use eh , for example , a neural net So p with {pause} the {pause} information we obtain from this eh {disfmarker} this eh study of the parameter with the {pause} selected {pause} parameter to try to eh {disfmarker} to put the class of each frame . Eh {pause} for {pause} the difference {pause} zone Features . Yeah . you {disfmarker} you eh , eh {pause} have obtained in the first eh , step {pause} with the {pause} for example , BIC eh , eh {pause} criterion compare model Mm - hmm . And {disfmarker} {vocalsound} You I don't - u OK , but , I {disfmarker} I think {disfmarker} in any event we 're agreed that the first step is {disfmarker} i Yeah . Because what we had before for {disfmarker} for uh , speaker change detection did not include these overlaps . Yeah . So the first thing is for you to {disfmarker} to build up something that will detect the overlaps . Yeah . Right ? So again , I think the first thing to do to detect the overlaps is to look at these uh , in {disfmarker} in {disfmarker} in {disfmarker} in {disfmarker} Features ? Yeah . Well , I {disfmarker} again , the things you 've written up there I think are way too {disfmarker} way too big . Yeah . OK ? If you 're talking about , say , twelfth {disfmarker} twelfth - order uh MFCC 's or something like that it 's just way too much . Yeah . You won't be able to look at it . All you 'll be able to do is put it into a classifier and see how well it does . Yeah . Whereas I think if you have things {disfmarker} if you pick one or two dimensional things , or three of you have some very fancy display , uh , and look at how the {disfmarker} the different classes separate themselves out , you 'll have much more insight about what 's going on . It will be enough . Well , you 'll {disfmarker} you 'll get a feeling for what 's happening , you know , Yeah . so if you look at {disfmarker} {vocalsound} Suppose you look at first and second - order cepstral coefficients for some one of these kinds of things and you find that the first - order is much more effective than the second , {vocalsound} and then you look at the third and there 's not {disfmarker} and not too much there , {vocalsound} you may just take first and second - order cepstral coefficients , Yeah . Yeah . right ? And with LPC , I think LPC per se isn't gonna tell you much more than {disfmarker} than {disfmarker} than the other , maybe . Uh , and uh on the other hand , the LPC residual , the energy in the LPC residual , {vocalsound} will say how well , uh {vocalsound} the low - order LPC {vocalsound} model 's fitting it , which should be {vocalsound} pretty poorly for two two or more {vocalsound} people speaking at the same time , and it should be pretty well , for w for {disfmarker} for one . Yeah . Yeah . Yeah . And so {vocalsound} I {disfmarker} i again , if you take a few of these things that are {disfmarker} are {vocalsound} prob um {comment} {pause} promising features and look at them in pairs , {vocalsound} uh , I think you 'll have much more of a sense of \" OK , I now have {disfmarker} {vocalsound} uh , doing a bunch of these analyses , I now have ten likely candidates . \" And then you can do decision trees or whatever to see how they combine . Yeah . Yeah . I 've got a question . Yeah . This Interesting . Sorry . Hmm . but eh , eh {vocalsound} eh eh eh I don't know it is the first eh way to {disfmarker} to {disfmarker} do that and I would eh like to {disfmarker} to know what eh , your opinion . Eh {vocalsound} all this study in the f in the first moment , I {disfmarker} I w I {disfmarker} I will pretend to do {comment} with eh eh equalizes speech . The {disfmarker} the equalizes speech , the speech eh , the mixes of speech . With {disfmarker} With what ? With what ? Right . Mixed . the {disfmarker} the mix , mixed speech . \" Mixed \" . Thank you . Eh , why ? Because eh the spectral distortion is {disfmarker} {comment} {pause} more eh {disfmarker} a lot eh clearer , very much clearer if we compare with the PDA . Right . PDA speech file is eh {disfmarker} it will be eh difficult . I {disfmarker} So it 's messier . Yeah , The {disfmarker} the PDA is messier . fff ! {comment} Because the n the noise eh to sp the signal - to - noise relation is eh {disfmarker} is {disfmarker} is low . OK . Yeah , I think that that 's a good way to start . And , {vocalsound} I don't know {disfmarker} But . I don't know eh uh i i that eh the {disfmarker} {vocalsound} the result of the {disfmarker} of the study eh with eh {disfmarker} with eh this eh {disfmarker} this speech , the mix speech eh {pause} will work {pause} exactly {pause} with the {pause} eh PDA files . It would be interesting in itself to see . Well , I think that would be an interesting result . eh What , I {disfmarker} I mean , what what is the effect of the low ' signal to {disfmarker} to {disfmarker} to noise relation , you know , eh with {disfmarker} N u We Well , I think {disfmarker} I think {disfmarker} I think it 's not a {disfmarker} it 's not at all unreasonable . It makes sense to start with the simpler signal because if you have features which don't {disfmarker} aren't even helpful in the high signal - to - noise ratio , then there 's no point in putting them into the low signal ratio , one would think , anyway . Yeah . And so , if you can get {disfmarker} @ @ {comment} Uh again , my prescription would be that you would , with a mixed signal , you would take a collection of possible uh , features {vocalsound} look at them , look at how these different classes that you 've marked , separate themselves , {comment} {vocalsound} and then collect , uh in pairs , {vocalsound} and then collect ten of them or something , and then proceed {vocalsound} with a bigger classifier . Yeah . Yeah . And then if you can get that to work well , then you go to the other signal . And then , and you and you know , they won't work as well , but how m you know , how much {disfmarker} Right . Yeah . Yeah . Yeah . And then you can re - optimize , and so on . Yeah . But it I think it would be interesting to try a couple with both . Because it {disfmarker} I think it would be interesting to see if some features work well with close mixed , and {disfmarker} And don't {disfmarker} Hmm . Ah , yeah , yeah yeah yeah . That 's {disfmarker} well , the {disfmarker} It {disfmarker} it 's {disfmarker} it 's true that it also , it could be {vocalsound} useful to do this exploratory analysis where you 're looking at scatter plots and so on in both cases . Sure . But {disfmarker} Mm - hmm . I {disfmarker} I {disfmarker} I {disfmarker} I think that the {disfmarker} the eh parameter we found , eh , eh {vocalsound} worked with both eh , speech file , That 's good . but eh what is the {disfmarker} the {disfmarker} the relation of eh {disfmarker} of the {vocalsound} performance when eh you use eh the , eh eh speech file the PDA speech files . Hmm . Yeah , I don't know . Right . But it {disfmarker} I {disfmarker} I {disfmarker} I {disfmarker} I think it will be important . Because eh people eh eh , different groups eh has eh experience with this eh kind of problem . Is {disfmarker} eh is not easy eh to {disfmarker} to solve , because if you {disfmarker} I {disfmarker} I {disfmarker} {vocalsound} I have seen the {disfmarker} the {disfmarker} the speech file from eh PDA , and s some parts is {comment} very difficult because you {disfmarker} you don't see the spectrum {disfmarker} the spectrogram . Right . Yeah , they 're totally hidden . Is very difficult to apply eh , eh a parameter to detect change when you don't see . Yeah . Yeah . Well , that {disfmarker} that {disfmarker} that 's another reason why very simple features , things like energy , and things {disfmarker} things like harmonicity , and {vocalsound} residual energy are uh , yeah are {disfmarker} are better to use than very complex ones because they 'll be more reliable . But I suppose {disfmarker} Are probably better , yep . Yeah , yeah yeah , I {disfmarker} I {disfmarker} I will put eh the energy here . Yeah . Yeah . Yeah . Ch - Chuck was gonna ask something I guess . You have a question . Yeah , I {pause} maybe this is a dumb question , but w I thought it would be {disfmarker} {vocalsound} I thought it would be easier if you used a PDA Nah . because can't you , couldn't you like use beam - forming or something to detect speaker overlaps ? I mean {disfmarker} Well , if you used the array , rather than the signal from just one . Uh - huh . Yeah , no , you you 're {disfmarker} you 're right But that 's {disfmarker} that {disfmarker} In fact , if we made use of the fact that there are two microphones , you do have some location information . which we don't have with the one and {disfmarker} and so that 's {disfmarker} Is that not allowed with this project ? Uh , well , no , I mean , we we don't have any rules , r really . But I didn't mean {disfmarker} I w {pause} Given {disfmarker} given the goal . I think {disfmarker} {vocalsound} I {disfmarker} I think {disfmarker} I think it 's {disfmarker} it 's {disfmarker} it 's a {disfmarker} it 's an additional interesting question . I mean , is {disfmarker} is that violation of the {disfmarker} Oh . No . Yeah . I mean , I think you wanna know whether you can do it with one , because you know it 's not necessarily true that every device that you 're trying to do this with will have two . Mm - hmm Yeah . Uh , if , on the other hand , we show that there 's a huge advantage with two , well then that could be a real point . Yeah . But , we don't n even know yet what the effect of detecting {disfmarker} having the ability to detect overlaps is . You know , maybe it doesn't matter too much . Right . Right . OK . Yeah . Yeah . So , this is all pretty early stages . I see . Yeah . Yeah , yeah , yeah . But no , you 're absolutely right . That 's {pause} a good thing to consider . OK . There {disfmarker} there is a complication though , and that is if a person turns their back to the {disfmarker} to the PDA , then some of the positional information goes away ? Yeah . Well , it {disfmarker} it {disfmarker} it does , i it d it does , but the {disfmarker} the {disfmarker} the issue is that {disfmarker} that {disfmarker} No , it 's not {disfmarker} it 's not that so much as {disfmarker} And then , And if they 're on the access {disfmarker} {comment} on the axis of it , that was the other thing I was thinking . Mm - hmm . He {disfmarker} You mentioned this last time , that {disfmarker} that if {disfmarker} if you 're straight down the midline , then {disfmarker} then {disfmarker} the r the left - right 's gonna be different , Yeah , we hav need to put it on a little turntable , I {disfmarker} I {disfmarker} {vocalsound} I {disfmarker} I {disfmarker} I th and {disfmarker} Well , it 's Yeah . and {disfmarker} and {disfmarker} and in his case , I mean , he 's closer to it anyway . Yeah . Yeah . It seems to me that {disfmarker} that it 's not {disfmarker} a p uh , you know , it 's {disfmarker} this {disfmarker} the topograph the topology of it is {disfmarker} is a little bit complicated . But it 's another source of information . I {disfmarker} I {disfmarker} Yeah . I don't {disfmarker} I don't know ho I {disfmarker} I {disfmarker} I think {disfmarker} Sorry . I {disfmarker} I {disfmarker} I think because the the the distance between the two microph eh , microphone , eh , in the PDA is very near . But it 's uh {disfmarker} from my opinion , it 's an interesting idea to {disfmarker} to try to study the binaural eh problem eh , with information , because I {disfmarker} I found difference between the {disfmarker} the speech from {disfmarker} from each micro eh , in the PDA . I would guess {disfmarker} Yep . Yeah , it 's timing difference . It - it 's not amplitude , Oh yeah ! Oh I agree ! And we use it ourselves . right ? S Right . I mean , I know {disfmarker} I n I know that 's a very important cue . Yep . Yeah . But I 'm just {disfmarker} I 'm just saying that the way we 're seated around a table , is not the same with respect to each {disfmarker} to each person with respect to the PDA , No . No . No , no , no . so we 're gonna have a lot of differences with ref respect to the speaker . That 's {disfmarker} That 's fine . But th I don't think that matters , though . But {disfmarker} That 's {disfmarker} So {disfmarker} so i @ @ {comment} I think the issue is , \" Is there a clean signal coming from only one direction ? \" Right . If it 's not coming from just one direction , if it {disfmarker} if th if there 's a broader pattern , it means that it 's more likely there 's multiple people speaking , Yeah . wherever they are . So it 's sort of like how {disfmarker} how confused is it about where the beam is . Is it a {disfmarker} is it {disfmarker} Yeah . Yeah , is there a narrow {disfmarker} Is there a narrow beam pattern or is it a {disfmarker} a distributed beam pattern ? So if there 's a distributed beam pattern , then it looks more like it 's {disfmarker} it 's uh , multiple people . Yeah . Wherever you are , even if he moves around . OK . Yeah . OK , it just {disfmarker} it just seemed to me that {disfmarker} uh , that this isn't the ideal type of separation . I mean , I {disfmarker} I think it 's {disfmarker} I can see the value o Oh , ideal would be to have the wall filled with them , but I mean {disfmarker} {vocalsound} But the thing is just having two mikes {disfmarker} If you looked at that thing on {disfmarker} on Dan 's page , it was {disfmarker} When {disfmarker} when there were two people speaking , and it looked really really different . Yeah . Yeah , OK . Yeah . Yeah . Yep . Oh yeah yeah . OK . What looked different ? Yeah . Yeah . Uh , well , basic he was looking at correlation . Cross - co cross - correlation . Correlation , yeah . Just cross - correlation between two sides . Did - Sorry , b uh I 'm not sure what Dan 's page is that you mean . He was looking at the two {disfmarker} So cross - correlation is pretty sensitive . Uh , his a web page . You take the signal from the two microphones and you cros and you cross - correlate them with different lags . Subtract them . OK . Mm - hmm . Uh - huh . Yeah . And you find {disfmarker} They get peaks . OK . So when one person is speaking , then wherever they happen to be at the point when they 're speaking , {vocalsound} then there 's a pretty big maximum right around that point in the l in {disfmarker} in the lag . OK . OK . So if {disfmarker} at whatever angle you are , {vocalsound} at some lag corresponding to the time difference between the two there , you get this boost in the {disfmarker} in {disfmarker} in the cross - correlation value {disfmarker} function . So {disfmarker} so if there 's two {disfmarker} And if there are multiple people talking , you 'll see two peaks . It 's spread out . Yeah . Well , let me ask you , if {disfmarker} if both people were over there , it would be less effective than if one was there and one was across , catty - corner ? Yeah . Yeah . The - the {disfmarker} Oh , I 'm sorry , No ? if they 're right next to one another ? If I was {disfmarker} if I was here and Morgan was there and we were both talking , it wouldn't work . i i Next {disfmarker} next one over n over {comment} on this side of the P {disfmarker} PDA . Right . Yeah . There we go . Good example , the same one I 'm asking . Yeah . Yeah , e I see . Yes . Yeah . Versus you {disfmarker} versus {disfmarker} you know , and we 're catty - corner across the table , and I 'm farther away from this one and you 're farther away from that one . Or {disfmarker} or even if , like , if people were sitting right across from each other , you couldn't tell the difference either . Yeah . Yeah . Yeah . Yeah . Oh , yeah . It seems like that would be pretty strong . Yeah . Across {disfmarker} the same axis , you don't have as much to differentiate . Yeah . Well , we d yeah , we don't have a third dimension there . Yeah , so it 's {disfmarker} And so my point was just that it 's {disfmarker} it 's gonna be differentially {disfmarker} differentially varia valuable . Right . I mean , it 's not to say {disfmarker} I mean , I certainly think it 's extremely val {comment} And we {disfmarker} we humans {pause} n n depend on {pause} you know , these {disfmarker} these binaural cues . Yeah , yeah . But it 's almost {disfmarker} but it 's almost a {disfmarker} {vocalsound} I think what you 're talking about i there 's two things . But . Must do . {comment} Yeah . There 's a sensitivity issue , and then there 's a pathological error uh issue . So th the one where someone is just right directly in line is sort of a pathological error . Yes . Yeah . Yeah . If someone just happens to be sitting right there then we won't get good information from it . OK . and i and if there {disfmarker} So it {disfmarker} And if it 's the two of you guys on the same side {disfmarker} Uh , if they 're {disfmarker} if they 're close , it 's just a question of the sensitivity . Yep . So if the sensitivity is good enough {disfmarker} and we just {disfmarker} we just don't have enough , uh , experience with it to know how {disfmarker} Yeah . OK . Yeah yeah , OK . Yeah . But {disfmarker} Yeah . Oh I 'm not {disfmarker} I 'm not trying to argue against using it , by any means . I just wanted to point out that {disfmarker} that weakness , that it 's topo topologically impossible to get it perfect for everybody . Yeah . Mm - hmm . And I think Dan is still working on it . So . He actually {disfmarker} he wrote me about it a little bit , so . Great . No , I don't mean to discourage that at all . I mean , the other thing you can do {disfmarker} uh , if {disfmarker} I mean , i We 're assuming that it would be a big deal just to get somebody {disfmarker} convince somebody to put two microphones in the PDA . But if you h put a third in , {vocalsound} you could put in the other axis . And then you know {disfmarker} then you 're sort of {disfmarker} Yeah , then {disfmarker} then you pretty much could cover {disfmarker} Once you got two {disfmarker} Interesting . Yeah . Well what about just doing it from these mikes ? Interesting . You know ? Yeah . Yep . It will be more interesting to study the PZM because the {disfmarker} the {disfmarker} the separation {disfmarker} I {disfmarker} I think {disfmarker} Uh @ @ {comment} {vocalsound} But - but that 's {disfmarker} I mean , we can we 'll be {disfmarker} all of this is there for us to study . Then they 're much broader . Yeah , we can do whatever we want . Yeah . But {disfmarker} {vocalsound} but {disfmarker} but the thing is , uh , one of the {disfmarker} at least one of the things I was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has a PDA . Whatever you 're interested in . Yeah . That 's what I was asking about , what are the constraints ? Yeah . Yeah . Yeah . Right . Yeah . Yeah . Well , that 's {disfmarker} that 's the constraint of one question that I think both Adam and I were {disfmarker} were {disfmarker} were interested in . Well {disfmarker} Mm - hmm . Yep . Mm - hmm . Yeah . Uh , but {disfmarker} you know if you can instrument a room , this is really minor league compared with what some people are doing , right ? Some people at {disfmarker} at {disfmarker} uh , yeah , at Brown and {disfmarker} and {disfmarker} and {disfmarker} and {disfmarker} at uh {pause} um and at Cape , Big micro @ @ arrays . Yeah . Didn't they have something at Cape ? they both have these , you know , big arrays on the wall . And you know , if you could do that , you 've got microphones all over the place Very finely . uh , you know p tens of microphones , and {disfmarker} and uh {disfmarker} Oh ! I saw a demo . Oh , right , oh , yeah . And if you do that then you can really get very nice uh kind of selectivity {disfmarker} Yeah . Oh , I saw one that was like a hundred microphones , a ten by ten array . Yeah . Yeah . And you could {disfmarker} In a noisy room , they could have all kinds of noises and you can zoom right in on somebody . Hundred . And they had very precision . Yeah . Yeah . Right . Very complex , uh {disfmarker} Yeah . Ye - Pretty much . Yeah . It was all in software and they {disfmarker} and you could pick out an individual beam and listen to it . That is cool . Yeah . It was {disfmarker} yeah , it was interesting . Yeah . But , the reason why I haven't focused on that as the fir my first concern is because um , I 'm interested in what happens for people , random people out in some random place where they 're p having an impromptu discussion . And you can't just always go , \" well , let 's go to this heavily instrumented room that we spent tens of thousands of dollars to se to set up \" . Yeah . No , what you need to do is you 'd have a little fabric thing that you unroll and hang on a wall . Yeah . It has all these mikes and it has a plug - in jack to the PDA . Interesting . But I think {disfmarker} The other thing actually , that gets at this a little bit of something else I 'd like to do , is what happens if you have two P D Yep . Yeah . and they communicate with each other ? And then {disfmarker} You know , they 're in random positions , the likelihood that {disfmarker} I mean , basically there wouldn't be any {disfmarker} l likely to be any kind of nulls , if you even had two . If you had three or four it 's {disfmarker} Yeah . Ooo ! That 's on my web pages . Network ! Yeah . Interesting . Though {disfmarker} All sorts of interesting things you can do with that , Interesting . I mean , not only can you do microphone arrays , but you can do all sorts of um multi - band as well . Hmm . Yeah . Yeah . So it 's {disfmarker} it would be neat . Ah ! I still like my rug on the wall idea , so if anybody patents that , then {disfmarker} But {disfmarker} I think {disfmarker} Well , you could have strips that you stick to your clothing . in terms of {disfmarker} Yeah ! Yeah . Hats ? In terms of the research {pause} th research , it 's really {disfmarker} it 's whatever the person who is doing the research wants to do . Shirts . So if {disfmarker} if Jose is interested in that , that 's great . But if {disfmarker} if he 's not , that 's great too . Yeah . Yeah , yeah . Yeah . Um , I {disfmarker} i I {disfmarker} i I would actually kind of like us to wind it down , see if we can still get to the end of the , uh , birthdays thing there . Catch some tea ? Um . So Well , I had a couple things that I did wanna bring out . OK . One is , do we need to sign new {disfmarker} these again ? Well , it 's slightly different . So I {disfmarker} I would say it would be a good idea . Are they new ? Cuz {disfmarker} it {disfmarker} it 's slightly different . Yep . Oh . Oh , this morning we didn't sign anything cuz we said that if anybody had signed it already , we didn't have to . Yeah , I {disfmarker} I should 've checked with Jane first , but the ch the form has changed . It 's slightly different . So we may wanna have everyone sign the new form . Ah - oh . OK . Um , I had some things I wanted to talk about with the thresholding stuff I 'm doing . I had to make one {disfmarker} But , if we 're in a hurry , we can put that off . Um and then also anonymity , how we want to anonymize the data . Uh . Well , should I {disfmarker} I mean I have some results to present , but I mean I guess we won't have time to do that this time . But it seems like um the anonymization is uh , is also something that we might wanna discuss in greater length . Um . I mean , wha what {disfmarker} If {disfmarker} if we 're about to wind down , I think {disfmarker} what I would prefer is that we uh , delay the anonymization thing till next week , and I would like to present the results that I have on the overlaps . We still have to do this , too , right ? Right . Digits ? Right . No - well , we don't have to do digits . Well , why don't we {disfmarker} Uh , so @ @ OK . @ @ {comment} It sounds like u uh , there were {disfmarker} there were a couple technical things people would like to talk about . Why don't we just take a couple minutes to {disfmarker} to briefly {comment} do them , and then {disfmarker} and then {disfmarker} and then {disfmarker} and then {disfmarker} and then we {disfmarker} OK , go ahead , Jane . I 'd {disfmarker} Oh , I 'd prefer to have more time for my results . e Could I do that next week maybe ? OK . Oh , yeah . Sure . OK , that 's what I 'm asking . Oh yeah , yeah . And I think the anonymization , if y if you want to proceed with that now , I just think that that 's {disfmarker} that 's a discussion which also n really deserves a lo a {disfmarker} you know , more that just a minute . We could s Mm - hmm . I really do think that , because you raised a couple of possibilities yourself , you and I have discussed it previously , and there are different ways that people approach it , e and I think we should {disfmarker} Alright . We 're {disfmarker} we 're just {disfmarker} We 're getting enough data now that I 'd sort of like to do it now , before I get overwhelmed with {disfmarker} once we decide how to do it Well , OK . going and dealing with it . It 's just {disfmarker} Yeah . OK . I {disfmarker} I 'll give you the short version , but I do think it 's an issue that we can't resolve in five minutes . Mm - hmm . OK , so {disfmarker} the {disfmarker} the short thing is um , we have uh , tape recording uh , uh , sorry , digitized recor recordings . Those we won't be able to change . If someone says \" Hey , Roger so - and - so \" . Right . So that 's gonna stay that person 's name . Yep . Now , in terms of like the transcript , the question becomes what symbol are you gonna put in there for everybody 's name , and whether you 're gonna put it in the text where he says \" Hey Roger \" or are we gonna put that person 's anonymized name in instead ? No , because then that would give you a mapping , and you don't wanna have a mapping . OK , so first decision is , we 're gonna anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned . I don't {disfmarker} No . Because that would give you a mapping between the speaker 's real name and the tag we 're using , and we don't want {disfmarker} I {disfmarker} I don't think you understood what I {disfmarker} what I said . OK . So {disfmarker} uh , so in {disfmarker} within the context of an utterance , someone says \" So , Roger , what do you think ? \" OK . Then , uh , it seems to me that {disfmarker} Well , maybe I {disfmarker} uh it seems to me that if you change the name , the transcript 's gonna disagree with the audio , and you won't be able to use that . Right , you don't wanna do that . We don't {disfmarker} we wanna {disfmarker} we ha we want the transcript to be \" Roger \" . Yeah . Because if we made the {disfmarker} the transcript be the tag that we 're using for Roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wanna avoid that . OK , well , but then there 's this issue of if we 're gonna use this for a discourse type of thing , then {disfmarker} and , you know , Liz was mentioning stuff in a previous meeting about gaze direction and who 's {disfmarker} who 's the addressee and all , then to have \" Roger \" be the thing in the utterance and then actually have the speaker identifier who was \" Roger \" be \" Frank \" , that 's going to be really confusing and make it pretty much useless for discourse analysis . Oh . Ugh ! That 's a good point . Now , if you want to , you know , I mean , in some cases , I {disfmarker} I {disfmarker} I know that Susan Ervin - Tripp in some of hers , uh , actually did do uh , um , a filter of the s signal where the person 's name was mentioned , except Yeah Yeah , once you get to the publication you can certainly do that . And {disfmarker} and I {disfmarker} cer and I {disfmarker} So , I mean , the question then becomes one level back . Um , how important is it for a person to be identified by first name versus full name ? Well , on the one hand , uh , it 's not a full identity , we 're taking all these precautions , um and they 'll be taking precautions , which are probably even the more important ones , to {disfmarker} they 'll be reviewing the transcripts , to see if there 's something they don't like {disfmarker} {comment} OK . So , maybe , uh , maybe that 's enough protection . On the other hand , this is a small {disfmarker} this is a small pool , and people who say things about topic X e who are researchers and well - known in the field , they 'll be identifiable and simply from the {disfmarker} from the first name . However , taking one step further back , they 'd be identifiable anyway , even if we changed all the names . Right . Mmm . So , is it really , um {disfmarker} {comment} You know ? Ugh ! Now , in terms of like {disfmarker} so I {disfmarker} I did some results , which I 'll report on n next time , which do mention individual speakers by name . Mm - hmm . Now , there , the Human Subjects Committee is very precise . You don't wanna mention subjects by name in published reports . Now , it would be very possible for me to take those data put them in a {disfmarker} in a study , and just change everybody 's name for the purpose of the publication . And someone who looked {disfmarker} You can go , you know , uh , \" Z \" {vocalsound} uh , for instance . Yeah , exactly . Doesn't matter if {disfmarker} Uh . Um , yeah , I mean , t it doesn't {disfmarker} I mean , I 'm not knowledgeable about this , but it certainly doesn't bother me to have someone 's first name in {disfmarker} in the {disfmarker} in the transcript . That 's the same thing you saw . OK .  Uh , I think {disfmarker} you don't wanna have their full name to be uh , listed . Yeah , and {disfmarker} and in the form that they sign , it does say \" your first name may arise in the course of the meetings \" . Yeah . And so {disfmarker} Well {disfmarker} Yeah . So again , th the issue is if you 're tracking discourse things , you know , if someone says , uh , uh , \" Frank said this \" and then you wanna connect it to something later , you 've gotta have this part where that 's \" Frank colon \" . Or \" your name \" . Yeah , shoot ! Right ? Yeah , and {disfmarker} and {disfmarker} you know , even more i i uh , immediate than that just being able to , uh {disfmarker} Well , it just seems like to track {disfmarker} track from one utterance to the next utterance who 's speaking and who 's speaking to whom , cuz that can be important . Mm - hmm . S i You know , \" You raised the point , So - and - so \" , it 's be kind of nice to be able to know who \" you \" was . Shoot ! Yeah . I {disfmarker} I 'm thinking too much . And ac {comment} and actually you remember {disfmarker} furthermore , you remember last time we had this discussion of how you know , I was sort of avoiding mentioning people 's names , Yeah , I was too . Yeah . and {disfmarker} and it was {disfmarker} and we made the decision that was kind of artificial . Well , I mean , if we 're going to step in after the fact and change people 's names in the transcript , we 've basically done something one step worse . Yep . Well , I would sug I {disfmarker} I {disfmarker} don't wanna change the names in the transcript , Yeah . Yeah . but that 's because I 'm focused so much on the acoustics instead of on the discourse , and so I think that 's a really good point . Misleading . Yeah . You 're right , this is going to require more thought . Yeah . L let me just back up this to make a {disfmarker} a brief comment about the , uh , what we 're covering in the meeting . Uh I realize when you 're doing this that uh {disfmarker} I mean , I didn't realize that you had a bunch of things that you wanted to talk about . Uh , and so , uh {disfmarker} and so I was proceeding some somewhat at random , frankly . So I think what would be helpful would be uh , i and I 'll {disfmarker} I 'll mention this to {disfmarker} to Liz and Andreas too , that um , before the meeting if anybody could send me , any {disfmarker} any , uh , uh , agenda items that they were interested in and I 'll {disfmarker} I 'll take the role of organizing them uh , into {disfmarker} into the agenda , OK . Sure . but I 'd be very pleased to have everyone else {vocalsound} completely make up the agenda . I 've no desire to {disfmarker} {vocalsound} to make it up , but if {disfmarker} if no one 's told me things , then I 'm just proceeding from my {disfmarker} my guesses , and {disfmarker} and uh , and i ye yeah , I {disfmarker} I 'm sorry it ended up with your out your time to {disfmarker} I mean , I 'm just always asking Jose what he 's doing , you know , and {disfmarker} {vocalsound} and so it 's {disfmarker} {pause} There 's uh , there 's obviously other things going on . Mm - hmm . Oh , it 's not a problem . Not a problem . Yeah . I just {disfmarker} I just couldn't do it in two minutes . How will we {disfmarker} how would the person who 's doing the transcript even know who they 're talking about ? Do you know what I 'm saying ? \" The person who 's doing the transcript {disfmarker} \" {comment} The IBM people ? Yeah . I mean , so so {disfmarker} how is that information gonna get labeled anyway ? How do you mean , who {disfmarker} what they 're {disfmarker} who they 're talking about ? I mean , so if I 'm saying in a meeting , \" oh and Bob , by the way , wanted {disfmarker} wanted to do so - and - so \" , How do you mean ? They 're just gonna write \" Bob \" on it or do @ @ {disfmarker} if you 're doing {disfmarker} Yeah , @ @ they 're just gonna write \" Bob \" . And so . If you 're {disfmarker} if you 're doing discourse analysis , They won't be able to change it themselves . What ar how are they gonna do any of this ? Yeah , really . Well , I {disfmarker} I 'm betting we 're gonna have huge chunks that are just totally un untranscribable by them . I mean , they 're gonna say speaker - one , or speaker - two or speaker I mean I {disfmarker} I {disfmarker} They can't do that . Yeah , I think {disfmarker} Well , the current one they don't do speaker identity .  because in NaturallySpeaking , or , excuse me , in ViaVoice , it 's only one person . and so in their current conventions there are no multiple speaker conventions . So it may just be one long transcript of a bunch of words . Yep . Oh . {vocalsound} I think that {disfmarker} My understanding from Yen Is it Yen - Ching ? Is that how you pronounce her name ? Uh {pause} Yu - Ching , Yu - Ching . Yeah . Oh , uh Yu - Ching ? Yu - Ching ? y Yu - Ching . was that um , they will {disfmarker} that they will adopt the {disfmarker} part of the conventions that {disfmarker} that we discussed , where they put speaker identifier down . But , you know , h they won't know these people , so I think it 's {disfmarker} Well , they 'll {disfmarker} they 'll adopt some convention but we haven't specified to them {disfmarker} So they 'll do something like speaker - one , speaker - two , is what I bet , but I 'm betting there 'll be huge variations in the accuracy of {disfmarker} of their labeling the speakers . We 'll have to review the transcripts in any case . And it {disfmarker} and it may very well be {disfmarker} I mean , since they 're not going to sit there and {disfmarker} and {disfmarker} and worry ab about , uh , it being the same speaker , they may very well go the {disfmarker} eh the {disfmarker} the first se the first time it changes to another speaker , that 'll be speaker - two . Yeah . And the next time it 'll be speaker - three even if it 's actually speaker - one . You know {disfmarker} Uh - huh . You know , that would be a very practical solution on their part . Yeah . It 's a good idea . Yeah . And {disfmarker} and {disfmarker} but then we would need to label it . Yeah we {disfmarker} we can probably regenerate it pretty easily from the close - talking mikes . Yeah . Yeah , I think {disfmarker} And that 's OK .  Yes , I was thinking , the temp the time values of when it changes . Yeah . Yeah . So . But I mean that doesn't {disfmarker} This doesn't answer the {disfmarker} the question . Yeah . But that {disfmarker} That 'd be very efficient . The p It 's a good point , \" which {disfmarker} what do you do for discourse tracking ? \" Because y y you don't know to know , eh {disfmarker} you don't need to know what i what is the iden identification of the {disfmarker} of the speakers . You only eh want to know {disfmarker} Hmm . For {disfmarker} for acoustics you don't but for discourse you do . Well , you do . Ah , for discourse , yeah . Yeah . Yeah . Yeah . If {disfmarker} if {disfmarker} if {disfmarker} if someone says , uh , \" what {disfmarker} what is Jose doing ? \" and then Jose says something , you need to know that that was Jose responding . Yeah , yeah . Yeah . Yeah . Yeah , yeah , yeah . Yeah . Yeah , Ugh , {comment} that 's a problem . Uh , so . Mm - hmm . Yeah . Unless we adopt a different set of norms which is to not id to make a point of not identifying people by name , which then leads you to be more contextually ex explicit . That would be hard . Well , people are very flexible . You know ? I mean , so when we did this las last week , I felt that you know , now , Andreas may , uh , @ @ {comment} uh , he {disfmarker} he {disfmarker} i sometimes people think of something else at the same time and they miss a sentence or something , and {disfmarker} and because he missed something , then he missed the r the initial introduction of who we were talking about , and was {disfmarker} was unable to do the tracking . Mm - hmm . But I felt like most of us were doing the tracking and knew who we were talking about and we just weren't mentioning the name . So , people are really flexible . Yeah . But , you know , like , at the beginning of this meeting {disfmarker} Or , you I think said , {pause} you know , or s Liz , said something about um , uh , \" is Mari gonna use the equipment ? \" I mean , how would you say that ? Yeah ? I mean , you have to really think , you know , about what you 're saying bef if you wanted to anonymize . Yeah . {vocalsound} Yeah , is {disfmarker} \" Is you know who up in you know where ? \" Yeah . Yeah . Mm - hmm . Right ? Use the {disfmarker} I think it would be really hard if we made a policy where we didn't say names , plus we 'd have to tell everybody else . Yeah , darn ! I mean , what I was gonna say is that the other option is that we could bleep out the names . Well , it Yeah . but then , again that kills your discourse analysis . Right . Uh - huh . Yeah . Ugh ! Yeah . Yeah . Yeah . I {disfmarker} I think the {disfmarker} I think {disfmarker} I don't know , my own two cents worth is that you don't do anything about what 's in the recordings , you only anonymize to the extent you can , the speakers have signed the forms and all . That 's {disfmarker} that 's the issue . Well , but that but that {disfmarker} as I said , that {disfmarker} that {disfmarker} that works great for the acoustics , but it {disfmarker} it hurts you a lot for trying to do discourse . Well . Why ? Mm - hmm . Because you don't have a map of who 's talking versus {pause} their {pause} name that they 're being referred to . Yeah . Yeah . Th - Bec Yeah . I thought we were gonna get it labelled speaker - one , speaker - two {disfmarker} Sure but , h then you have to know that Jose is speaker - one and {disfmarker} Why do you have to know his name ? OK , so suppose someone says , \" well I don't know if I really heard what {disfmarker} uh , what Jose said . \" Yeah . Yeah . And then , Jose responds . Yeah . And part of your learning about the dialogue is Jose responding to it . But it doesn't say \" Jose \" , it says \" speaker - five \" . OK . Yeah . Yeah . So {pause} uh {pause} u Oh , I see , you wanna associated the word \" Jose \" in the dialogue with the fact that then he responded . Right . Someone who 's doing discourse would wanna do that . And so , if we pass out the data to someone else , and it says \" speaker - five \" there , we also have to pass them this little guide that says that speaker - five is Jose , And that violates our privacy . and if were gonna do that we might as well {comment} give them \" Jose \" {disfmarker} say it was \" Jose \" . Yeah . Yeah . And that violates our privacy issue . Yeah . Mm - hmm . Yeah . Yeah . Now , I {disfmarker} I think that we have these two phases in the {disfmarker} in the data , which is the one which is o our use , University of Washington 's use , IBM , SRI . Yeah . And within that , it may be that it 's sufficient to not uh change the {disfmarker} to not incorporate anonymization yet , but always , always in the publications we have to . Mm - hmm . And I think also , when we take it that next step and distribute it to the world , we have to . But I {disfmarker} but I don that 's {disfmarker} that 's a long way from now and {disfmarker} and it 's a matter of {disfmarker} between now and then of d of deciding how {disfmarker} Making some decisions ? i i it {disfmarker} You know , it may be s that we we 'll need to do something like actually X out that part of the um {disfmarker} the audio , and just put in brackets \" speaker - one \" . Yeah . For the public one . the ? ? You know , what we could do also is have more than one version of release . Yeah . You know . One that 's public and one {disfmarker} one that requires licensing . And so the licensed one would {disfmarker} w we could {disfmarker} it would be a sticky limitation . Uh - huh . You know , like {disfmarker} Well , we can talk about that later . I think that 's risky . I think that the public should be the same . I think that when we do that world release , it should be the same . I {disfmarker} I agree . I {disfmarker} I agree with Jane . For a bunch of reasons , legal . I {disfmarker} I think that we {disfmarker} we have a {disfmarker} need to have a consistent licensing policy of some sort , and {disfmarker} But I also think a consistent licensing policy is important . Well , one thing to to take into consideration is w are there any um {disfmarker} For example , the people who are funding this work , they want this work to get out and be useful for discourse . Yeah . If we all of a sudden do this and then release it to the public and it 's not longer useful for discourse , you know {disfmarker} Well , depending on how much editing we do , you might be able to {pause} still have it useful . because for discourse you don't need the audio . Right ? So you could bleep out the names in the audio . Mm - hmm . and use the anonymized one through the transcript . But if you release both {disfmarker} Uh . Excuse me . We {disfmarker} we do need audio for discourse . But , n excuse me , but you could bleep out just the names . She {disfmarker} No , but she 's saying , from the argument before , she wants to be able to say if someone said \" Jose \" in their {disfmarker} in their thing , and then connect to so to what he said later , then you need it . Right . But in the transcript , you could say , everywhere they said \" Jose \" that you could replace it with \" speaker - seven \" . Oh I see . I see . Yeah . But I {disfmarker} {pause} I also wanna say that people {disfmarker} And then it wouldn't meet {disfmarker} match the audio anymore . But it would be still useful for the {disfmarker} Uh - huh . But if both of those are publically available {disfmarker} Yeah . That 's good . But they {disfmarker} Right . And th and the other thing is if {disfmarker} if {disfmarker} if Liz were here , {vocalsound} what she might say is that she wants to look if things that cut across between the audio and the dialogue , Well , you see ? So , it 's complicated . and so , {vocalsound} uh , Mm - hmm . Yeah . yeah . Sorry . I think we have to think about w @ @ {comment} how . I think that this can't be decided today . Yeah , OK , good point . But it 's g but I think it was good to introduce the thing and we can do it next time . Yeah . I didn't think {disfmarker} when I wrote you that email I wasn't thinking it was a big can of worms , but I guess it is . OK . OK . Yeah , a lot of these things are . Discourse . Well it {disfmarker} Discourse , you know {disfmarker} Also I wanted to make the point that {disfmarker} that discourse is gonna be more than just looking at a transcript . Yeah , ab absolutely . Oh , yeah , sure . It 's gonna be looking at a t You know , and prosod prosodic stuff is involved , and that means you 're going to be listening to the audio , and then you come directly into this {disfmarker} confronting this problem . Maybe we should just not allow anybody to do research on discourse , So . and then , we wouldn't have to worry about it . OK . Yeah , we should just market it to non - English speaking countries . OK . Uh , maybe we should only have meetings between people who don't know one another and who are also amnesiacs who don't know their own name . Did you read the paper on Eurospeech ? We could have little labels . I {disfmarker} I {disfmarker} I wanna introduce my Reservoir Dogs solution again , which is everyone has like \" Mister White \" , \" Mister Pink \" , {vocalsound} \" Mister Blue \" . Mister White . Yeah . Did you read the paper a few years ago where they were reversing the syllables ? They were di they they had the utterances . and they would extract out the syllables and they would play them backwards . But {disfmarker} so , the syllables were in the same order , with respect to each other , but the acous Everything was in the same order , but they were {disfmarker} the individual syll {comment} syllables were played backwards . And you could listen to it , {pause} and it would sound the same . What did it sound like ? People had no difficulty in interpreting it . So what we need is something that 's the reverse , that a speech recognizer works exactly the same on it but people can't understand it . Oh , well that 's {disfmarker} there 's an easy way to do that . Jus - jus just play it all backwards . Oh right . The speech recognizer 's totally symmetric , isn't it . What , what does the speech recognizer care ? Ah , anyway . Um , Oh , do we do digits ? Or {disfmarker} ? What do we do ? Uh {disfmarker} OK , we 'll quickly do digits . Let 's do digits . Yeah , we {disfmarker} we {disfmarker} we already missed the party . Or do we just quit ? OK . So . Yeah . OK , go off here . I think it would be fun sometime to read them with different intonations . like as if you were talking like , \" nine eight six eight seven ? \" Well , you know , in the {disfmarker} in the one I transcribed , I did find a couple instances {disfmarker} {pause} I found one instance of contrastive stress , where it was like the string had a {disfmarker} li So it was like \" nine eight two four , nine nine two four \" . Oh , really . So they were like looking ahead , And {disfmarker} huh ? Well , they differed . I mean , at that {disfmarker} that session I did feel like they did it more as sentences . But , um , sometimes people do it as phone numbers . {comment} I mean , I 've {disfmarker} I {pause} am sort of interested in {disfmarker} in {disfmarker} And sometimes , you know , I s And I {disfmarker} I never know . When I do it , I {disfmarker} I ask myself what I 'm doing each time . Yeah , yeah . Yep . Well , I was thinking that it must get kind of boring for the people who are gonna have to transcribe this and I {disfmarker} They may as well throw in some interesting intonations . Well , except , I like your question intonation . yeah . That 's very funny . I haven't heard that one . We have the transcript . We have the actual numbers they 're reading , so we 're not necessarily depending on that . OK , I 'm gonna go off .",
        "summarize": "In this meeting, the speakers addressed issues that related to their meeting annotation progress. They talked about the types and variability of the future meetings. This led to them speaking about how to use their recording equipment if they got groups outside of their own departments to record meetings. Additionally, they discussed how to handle the storage of meetings on disk. They eventually address how to handle speech overlap and speaker anonymity, which were two crucial issues."
    }
]