[
    {
        "transcript": "Let 's see . Test ? Test ? Yeah . OK . Hello ? Channel one . Hello ? Test . I was saying Hynek 'll be here next week , uh , Wednesday through Friday {disfmarker} uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh , {vocalsound} as far as I know , so {disfmarker} There we go . OK . Um . So other than reading digits , what 's our agenda ? I don't really have , uh , anything new . Been working on {pause} Meeting Recorder stuff . So . OK . Um . Do you think that would be the case for next week also ? Or is {disfmarker} is , uh {disfmarker} ? What 's your projection on {disfmarker} ? Um . Cuz the one thing {disfmarker} the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me {disfmarker} it was sort of an obvious thing {disfmarker} is , um , adjusting the , uh , sca the scaling and , uh , insertion penalty sorta stuff . I did play with that , actually , a little bit . Um . What happens is , uh , {vocalsound} when you get to the noisy stuff , you start getting lots of insertions . Right . And , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that . Yeah . Um . I mean , it {disfmarker} it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um . {vocalsound} I could do more playing with that , though . And , uh {disfmarker} But you were looking at mel cepstrum . and see . Yes . Right . Oh , you 're talking about for th {vocalsound} for our features . Right . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the {disfmarker} uh , what 's the best you can do with {disfmarker} with mel cepstrum . But , they raised a very valid point , Mmm . which , I guess {disfmarker} So , to first order {disfmarker} I mean , you have other things you were gonna do , but to first order , I would say that the conclusion is that if you , um , do , uh , some monkeying around with , uh , the exact HTK training and @ @ {comment} with , uh , you know , how many states and so forth , that it {disfmarker} it doesn't particularly improve the performance . In other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians , Right . but , um , let 's just {disfmarker} If we had to {disfmarker} if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ? Mm - hmm . Uh , so the next question to ask , which is I think the one that {disfmarker} that {disfmarker} that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would . Yeah . So , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum . Mm - hmm . But , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with {disfmarker} with LDA and KLT and neural nets and {vocalsound} all these things . In the fa past we 've always found that we had to increase the insertion penalty to {disfmarker} to correspond to such things . So , I think that 's , uh , @ @ {comment} that 's kind of a first - order thing that {disfmarker} that we should try . So for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes So by \" our front - end \" I mean take , you know , the Aurora - two s take some version that Stephane has that is , you know , our current best version of something . if we were {disfmarker} Mm - hmm . Um . I mean , y don't wanna do this over a hundred different things that they 've tried but , you know , for some version that you say is a good one . You know ? Um . How {disfmarker} how much , uh , does it improve if you actually adjust that ? OK . But it is interesting . You say you {disfmarker} you have for the noisy {disfmarker} How about for the {disfmarker} for the mismatched or {disfmarker} or {disfmarker} or {disfmarker} or the {disfmarker} or the medium mismatched conditions ? Have you {disfmarker} ? When you adjusted those numbers for mel cepstrum , did it {disfmarker} ? Uh , I {disfmarker} I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I {disfmarker} I {disfmarker} I don't remember . I would need to {disfmarker} Well , I did write down , um {disfmarker} So , when I was doing {disfmarker} I just wrote down some numbers for the well - matched case . Yeah . Um . Looking at the {disfmarker} I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone . Yeah . Um , but , uh , that {disfmarker} that 's all I wrote down . OK . So . I {disfmarker} I would {disfmarker} Yeah . I would need to do that . OK . So {disfmarker} I can do that for next week . Yeah . And , um {disfmarker} Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But {disfmarker} but I think it would be {disfmarker} it 'd be good to know that . OK . I just need to get , um , {vocalsound} front - end , uh , stuff from you Hmm . or you point me to some files {pause} that you 've already calculated . Yeah . Alright . OK . Uh . I probably will have time to do that and time to play a little bit with the silence model . Mm - hmm . So maybe I can have that for next week when Hynek 's here . Yeah . Mm - hmm . Yeah . Cuz , I mean , the {disfmarker} the other {disfmarker} That , in fact , might have been part of what , uh , the difference was {disfmarker} at least part of it that {disfmarker} that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system . Hmm . Part of it might just be that the SRI system , they {disfmarker} they {disfmarker} they always adjust these things to be sort of optimized , Is there {disfmarker} ? and {disfmarker} I wonder if there 's anything that we could do {vocalsound} to the front - end that would affect the insertion {disfmarker} Yes . I think you can . What could you do ? Well , um {disfmarker} uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root . Oh . Mm - hmm . You know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven . Mm - hmm . But {disfmarker} but , um , that has a similar effect because it changes the scale of the numbers {disfmarker} of the differences between different candidates from the acoustic model Oh , right . as opposed to what 's coming from the language model . So that w Right . So , in effect , that 's changing the value of your insertion penalty . Yeah . I mean , it 's more directly like the {disfmarker} the language scaling or the , uh {disfmarker} the model scaling or acoustic scaling , That 's interesting . but you know that those things have kind of a similar effect to the insertion penalty Mm - hmm . anyway . They 're a slightly different way of {disfmarker} of handling it . Right . So , um {disfmarker} So if we know what the insertion penalty is , then we can get an idea about what range our number should be in , I think so . so that they {pause} match with that . Yeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing {disfmarker} ? Y y Mm - hmm . I 'm sure you 've already looked at this bu in these noisy cases , are {disfmarker} ? We are seeing lots of insertions . Right ? The insertion number is quite high ? Yeah . I know the VAD takes pre care of part of that , Yeah . Yeah . but {disfmarker} I 've seen that with the mel cepstrum . I don't {disfmarker} I don't know about {pause} the Aurora front - end , but {disfmarker} I think it 's much more balanced with , uh {disfmarker} when the front - end is more robust . Yeah . I could look at it {disfmarker} at this . Yeah . Mm - hmm . Yeah . Wha - what 's a typical number ? I don't {disfmarker} I don't know . Do we {disfmarker} ? Oh , you {disfmarker} oh , you don't know . I don't have this in {disfmarker} OK . I 'm sure it 's more balanced , Mm - hmm . but it {disfmarker} it {disfmarker} it wouldn't surprise me if there 's still {disfmarker} Mm - hmm . I mean , in {disfmarker} in the {disfmarker} the {disfmarker} the old systems we used to do , I {disfmarker} I {disfmarker} uh , I remember numbers kind of like insertions being half the number of deletions , as being {disfmarker} and both numbers being {disfmarker} tend to be on the small side comparing to {disfmarker} to , uh , substitutions . Mm - hmm . Well , this {disfmarker} the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down {pause} that one time and {disfmarker} and that was when people were saying , well we should have a , uh , uh , voice activity detector {disfmarker} Right . that , because all that stuff {comment} that we 're getting thr the silence that 's getting through is causing insertions . So . Mmm . Right . I 'll bet you there 's still a lot {vocalsound} of insertions . Mm - hmm . Yeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range . Mm - hmm . So , I mean , the insertions is {disfmarker} is a symptom . It 's a symptom that there 's something , uh , wrong with the range . Right . But there 's {disfmarker} uh , your {disfmarker} your {disfmarker} your substitutions tend to go up as well . So , uh , I {disfmarker} I {disfmarker} I think that , Mm - hmm . uh , the most obvious thing is just the insertions , @ @ . But {disfmarker} Uh {disfmarker} um . If you 're operating in the wrong range {disfmarker} I mean , that 's why just in general , if you {vocalsound} change what these {disfmarker} these penalties and scaling factors are , you reach some point that 's a {disfmarker} that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we {disfmarker} if we see {disfmarker} Um , I mean we ca it 's if we actually could pick a {disfmarker} a {disfmarker} a more stable value for the range of these features , it , um , uh , could {disfmarker} Uh {disfmarker} Even though it 's {disfmarker} it 's {disfmarker} it 's true that in a real situation you can in fact adjust the {disfmarker} these {disfmarker} these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range {disfmarker} Hmm . I remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a {disfmarker} Mm - hmm . for an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and {disfmarker} Uh , we might just not even be in the right operating range . So , would the {disfmarker} ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as {disfmarker} ? No . You don't wanna change it for different conditions . No . No . I {disfmarker} I {disfmarker} I {disfmarker} What {disfmarker} what I 'm saying {disfmarker} Oh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we {disfmarker} we wanna pick a range that we map our numbers into {disfmarker} Yeah . we should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to {disfmarker} to map everything into ? Well . It depends how much we wanna do gamesmanship and how much we wanna do {disfmarker} I mean , i if he it {disfmarker} to me , actually , even if you wanna be {disfmarker} play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the {disfmarker} set the scaling factors , uh , so that you got the best number for this point four five times the {disfmarker} {vocalsound} you know , and so on . Mm - hmm . But they might change that {disfmarker} those weightings . Yeah . Um . So {disfmarker} Uh {disfmarker} I just sorta think we need to explore the space . Just take a look at it a little bit . Mm - hmm . And we {disfmarker} we {disfmarker} we may just find that {disfmarker} that we 're way off . OK . Mm - hmm . Maybe we 're not . You know ? As for these other things , it may turn out that , uh , {vocalsound} it 's kind of reasonable . But then {disfmarker} I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future {disfmarker} of , you know , people {disfmarker} people within this tight - knit community who are doing this evaluation {vocalsound} are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say \" Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end , Yeah . when all you could do is just adjust this in the back - end with one s one knob . \" Mm - hmm . And so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with {disfmarker} with what we 're doing . And as you say {disfmarker} as you point out {disfmarker} finding ways to then compensate for that in the front - end {vocalsound} also then becomes a priority for this particular test , Right . and saying you don't have to do that . Mm - hmm . So . OK . So , uh {disfmarker} What 's new with you ? Uh . So there 's nothing {pause} new . Um . Uh , what 's old with you that 's developed ? I 'm sorry ? You {disfmarker} OK . What 's old with you that has developed over the last week or two ? Mmm . Well , so we 've been mainly working on the report and {disfmarker} and {disfmarker} Yeah . Mainly working on what ? On the report {pause} of the work that was already done . Oh . Um . Mm - hmm . That 's all . How about that {disfmarker} ? Any - anything new on the thing that , uh , you were working on with the , uh {disfmarker} ? I don't have results yet . No results ? Yeah . What was that ? The {disfmarker} the , uh , Voicing thing . voicing detector . I mean , what what 's {disfmarker} what 's going on now ? What are you {pause} doing ? Uh , to try to found , nnn , robust feature for detect between voice and unvoice . And we {disfmarker} w we try to use {vocalsound} the variance {vocalsound} of the es difference between the FFT spectrum and mel filter bank spectrum . Yeah . Uh , also the {disfmarker} another parameter is {disfmarker} relates with the auto - correlation function . Uh - huh . R - ze energy and the variance a also of the auto - correlation function . Uh - huh . So , that 's {disfmarker} Yeah . That 's what you were describing , I guess , a week or two ago . Yeah . But we don't have res we don't have result of the AURO for Aurora yet . So . We need to train the neural network Mm - hmm . and {disfmarker} So you 're training neural networks now ? No , not yet . So , what {disfmarker} wha {vocalsound} wh wha what what 's going on ? Well , we work in the report , too , because we have a lot of result , Uh - huh . they are very dispersed , and was necessary to {disfmarker} to look in all the directory to {disfmarker} to {disfmarker} to give some more structure . Yea So . B So {disfmarker} Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens . Hm - hmm . Uh , y yeah . Basically we we 've stopped , uh , experimenting , Yes ? I mean . We 're just writing some kind of technical report . And {disfmarker} Is this a report that 's for Aurora ? Or is it just like a tech report for ICSI , No . Yeah . For ICSI . or {disfmarker} ? Ah . I see . Yeah . Just summary of the experiment and the conclusion and something like that . Yeah . Mm - hmm . OK . So , my suggestion , though , is that you {disfmarker} you not necessarily finish that . But that you put it all together so that it 's {disfmarker} you 've got {disfmarker} you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up . Mm - hmm . So that , you know {disfmarker} so that such a thing can be written . And , um {disfmarker} When {disfmarker} when {disfmarker} when do you leave again ? Uh , in July . First of July . First of July ? OK . And that you figure on actually finishing it in {disfmarker} in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway . Mm - hmm . Mm - hmm . And right now it 's kind of important that we actually go forward with experiments . It 's not . So {disfmarker} so , I {disfmarker} I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and so that it can go into a report in June . But I think {vocalsound} to {disfmarker} to really work on {disfmarker} on fine - tuning the report n at this point is {disfmarker} is probably bad timing , I {disfmarker} I {pause} think . Mm - hmm . Yeah . Well , we didn't {disfmarker} we just planned to work on it one week on this report , not {disfmarker} no more , anyway . Um . But you ma you may really wanna add other things later anyway Yeah . Mm - hmm . because you {disfmarker} Mmm . There 's more to go ? Yeah . Well , so I don't know . There are small things that we started to {disfmarker} to do . But {disfmarker} Are you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this , Uh . or {disfmarker} ? Yeah . Yeah . And {disfmarker} Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything . Mmm . But anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from {pause} the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora {disfmarker} the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises {disfmarker} on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So {disfmarker} adding the noises from {disfmarker} from the SpeechDat - Car . Um . That 's {disfmarker} that 's , uh {disfmarker} that 's permitted ? Uh . Well , OGI does {disfmarker} did that . Um . At some point they did that for {disfmarker} for the voice activity detector . Uh , for a v VAD . Right ? Um . Could you say it again ? What {disfmarker} what exactly did they do ? They used some parts of the , um , Italian database to train the voice activity detector , I think . It {disfmarker} Yeah . I guess the thing is {disfmarker} Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English {disfmarker} no , Italian and the Finnish and the English ? {disfmarker} were development data Yeah . And Spanish , yeah . on which you could adjust things . And the {disfmarker} and the German and Danish were the evaluation data . Mm - hmm . And then when they finally actually evaluated things they used everything . Yeah . That 's right . Uh {disfmarker} So {disfmarker} Uh , and it is true that the performance , uh , on the German was {disfmarker} I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good . Mm - hmm . So {disfmarker} And , uh , it {disfmarker} it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that {disfmarker} that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh {disfmarker} I mean they were different drives . Different cars . Yeah . I mean , it was {disfmarker} it was actual different cars and so on . Yeah . So . Um , it 's somewhat tuned . It 's tuned more than , you know , a {disfmarker} a {disfmarker} a {disfmarker} a {disfmarker} Mm - hmm . You 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most . Mm - hmm . But that 's not really what this contest is . So . Um , I guess it 's OK . Mm - hmm . That 's something I 'd like to understand before we actually use something from it , I think it 's {disfmarker} because it would {disfmarker} it 's probably something that , mmm , the {disfmarker} you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just {pause} doing signal - processing . Yeah . Well , it 's true , So . except that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that . Yeah . That 's true . Um . And they didn't forbid us {disfmarker} right ? {disfmarker} to build models on the data ? No . But , I think {disfmarker} I think that it {disfmarker} it {disfmarker} it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that {disfmarker} that it would look bad . And I think someone would notice and would say \" Well , look . This is not generalizing . \" I would hope tha I would hope they would . Mm - hmm . Um . But , uh , it 's true . You know , maybe there 's parameters that other people have used {disfmarker} you know , th that they have tuned in some way for other things . So it 's {disfmarker} it 's , uh {disfmarker} We should {disfmarker} we should {disfmarker} Maybe {disfmarker} that 's maybe a topic {disfmarker} Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek Mm - hmm . to , you know , double check it 's OK . Do we know anything about {pause} the speakers for each of the , uh , training utterances ? What do you mean ? We {disfmarker} we {disfmarker} Do you have speaker information ? Social security number That would be good . Like , we have {pause} male , female , Hmm . Bank PIN . at least . Just male f female ? Mmm . What kind of information do you mean ? Well , I was thinking about things like , you know , gender , uh {disfmarker} you know , gender - specific nets and , uh , vocal tract length normalization . Mm - hmm . Things like that . I d I don't {disfmarker} I didn't know what information we have about the speakers that we could try to take advantage of . Mm - hmm . Hmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're {vocalsound} supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure {disfmarker} I mean , having the two nets {disfmarker} Suppose you detected that it was male , it was female {disfmarker} you come up with different {disfmarker} Well , you could put them both in as separate streams or something . Uh . Mm - hmm . Maybe . I don't know . I was just wondering if there was other information we could exploit . Mm - hmm . Hmm . Yeah , it 's an interesting thought . Maybe having something along the {disfmarker} I mean , you can't really do vocal tract normalization . But something that had some of that effect Yeah . being applied to the data in some way . Mm - hmm . Um . Do you have something simple in mind for {disfmarker} I mean , vocal tract length normalization ? Uh no . I hadn't {disfmarker} I hadn't thought {disfmarker} it was {disfmarker} thought too much about it , really . It just {disfmarker} something that popped into my head just now . And so I {disfmarker} I {disfmarker} I mean , you could maybe use the ideas {disfmarker} a similar {pause} idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance {disfmarker} like , the likelihood of each utterance . You divide the {disfmarker} the range of the likelihoods up into discrete bins and then each bin 's got some knob {disfmarker} uh , setting . Yeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that {disfmarker} and where you 're not adjusting the statistical engine at all . Yeah . Yeah . Mm - hmm . Yeah . That 's true . You know , that just {disfmarker} Right . Hmm . I mean {disfmarker} Yeah . Could be expensive . No . Well not just expensive . I {disfmarker} I {disfmarker} I don't see how you could possibly do it . You can't look at the whole utterance and do anything . You know , you can only {disfmarker} Right ? Oh , Each frame comes in and it 's gotta go out the other end . right . So , uh {disfmarker} Right . So whatever it was , it would have to be uh sort of on a per frame basis . Yeah . Mm - hmm . Yeah . I mean , you can do , um {disfmarker} Fairly quickly you can do male female {disfmarker} f male female stuff . Yeah . Yeah . But as far as , I mean {disfmarker} Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With {disfmarker} with , uh , uh , l trying to identify third formant {disfmarker} average third formant {disfmarker} {vocalsound} using that as an indicator of {disfmarker} I don't know . So . You know , third formant {disfmarker} I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion {disfmarker} Mm - hmm . So , if you had a first formant that was one hundred hertz before , if the fifty {disfmarker} if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at {disfmarker} So , although , you frequently get less distinct higher formants , it 's still {disfmarker} third formant 's kind of a reasonable compromise , and {disfmarker} Mm - hmm . So , I think , eh , if I recall correctly , they did something like that . And {disfmarker} and {disfmarker} Hmm . But {disfmarker} Um , that doesn't work for just having one frame or something . Yeah . Mm - hmm . You know ? That 's more like looking at third formant over {disfmarker} over a turn or something like that , Mm - hmm . and {disfmarker} Right . Um . So . But on the other hand , male female is a {disfmarker} is a {disfmarker} is a much simpler categorization than figuring out a {disfmarker} a factor to , uh , squish or expand the {disfmarker} the spectrum . Mm - hmm . So , um . Y you could imagine that {disfmarker} I mean , just like we 're saying voiced - unvoiced is good to know {disfmarker} uh , male female is good to know also . Um . Mm - hmm . But , you 'd have to figure out a way to {disfmarker} to {disfmarker} to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the {disfmarker} the male and female output vectors {disfmarker} you know , tr nets trained only on males and n trained only on females or {disfmarker} or , uh , you know . But {disfmarker} Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it {disfmarker} ? Is it balanced , um , in terms of gender {disfmarker} the data ? Mmm . Do you know ? Almost , yeah . Hmm . Mm - hmm . Hmm . OK . Y you 're {disfmarker} you were saying before {disfmarker} ? Uh . Yeah . So , this noise , um {disfmarker} Yeah . The MSG {disfmarker} Um . Mmm . There is something {disfmarker} perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on {disfmarker} let 's say , on TIMIT with MSG features , they {disfmarker} they look as good as networks trained on PLP . But , um , when they are used on {disfmarker} on the SpeechDat - Car data , it 's not the case {disfmarker} oh , well . The MSG features are much worse , and so maybe they 're , um , less {disfmarker} more sensitive to different recording conditions , or {disfmarker} Shou Shouldn't be . They should be less so . Yeah . But {disfmarker} R right ? Mmm . Wh - ? But let me ask you this . What {disfmarker} what 's the , um {disfmarker} ? Do you kno recall if the insertions were {disfmarker} were higher with MSG ? I don't know . I cannot tell . But {disfmarker} It 's {disfmarker} it {disfmarker} the {disfmarker} the error rate is higher . So , I don Yeah . But you should always look at insertions , deletions , and substitutions . Yeah . Mm - hmm . So {disfmarker} Mm - hmm . so , uh {disfmarker} MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them . Mm - hmm . So , if it 's very different , then this is the sort of thing {disfmarker} I mean I 'm really glad Andreas brought this point up . I {pause} sort of had forgotten to discuss it . Um . You always have to look at how this {disfmarker} uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features . Mm - hmm . So if it {disfmarker} if in fact , uh {disfmarker} The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum . Mm - hmm . Mm - hmm . And you might wanna change that . But {disfmarker} Yeah . But , it 's d it 's after {disfmarker} Well , it 's tandem features , so {disfmarker} Mmm . Yeah . Yeah . We {disfmarker} we have estimation of post posteriors with PLP and with MSG as input , Yeah . so I don Well . I don't know . That means they 're between zero and one . Mm - hmm . But i it {disfmarker} it {disfmarker} it {disfmarker} it doesn't necessarily {disfmarker} You know , they could be , um {disfmarker} Do - doesn't tell you what the variance of the things is . Mmm . Mm - hmm . Right ? Cuz if you 're taking the log of these things , it could be , uh {disfmarker} Knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are . Mm - hmm . Yeah . So . Yeah . So we should look at the likelihood , or {disfmarker} or what ? Or {disfmarker} well , at the log , perhaps , and {disfmarker} Yeah . Yeah . Mm - hmm . Or what {disfmarker} you know , what you 're uh {disfmarker} the thing you 're actually looking at . Mm - hmm . So your {disfmarker} your {disfmarker} the values that are {disfmarker} are actually being fed into HTK . Mm - hmm . But {disfmarker} What do they look like ? No And so th the , uh {disfmarker} for the tandem system , the values that come out of the net don't go through the sigmoid . Right ? They 're sort of the pre - nonlinearity values ? Yes . Right . So they 're {pause} kinda like log probabilities is what I was saying . And those {disfmarker} OK . And tho that 's what goes {pause} into {pause} HTK ? Uh , almost . But then you actually do a KLT on them . OK . Um . They aren't normalized after that , are they ? Mmm . No , they are not {disfmarker} no . No . OK . So , um . Right . So the question is {disfmarker} Yeah . Whatever they are at that point , um , are they something for which taking a square root or cube root or fourth root or something like that is {disfmarker} is gonna be a good or a bad thing ? So . Mm - hmm . Uh , and that 's something that nothing {disfmarker} nothing else after that is gonna {disfmarker} Uh , things are gonna scale it {disfmarker} Uh , you know , subtract things from it , scale it from it , but nothing will have that same effect . Um . So . Um . Anyway , eh {disfmarker} Yeah . Cuz if {disfmarker} if the log probs that are coming out of the MSG are really big , the standard {pause} insertion penalty is gonna have very little effect Well , the {disfmarker} Right . compared to , you know , a smaller set of log probs . Yeah . No . Again you don't really {pause} look at that . It 's something {disfmarker} that , and then it 's going through this transformation that 's probably pretty close to {disfmarker} It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a {disfmarker} a {disfmarker} a discrete cosine transformation is doing . Yeah . But still it 's {disfmarker} it 's not gonna probably radically change the scale of things . I would think . And , uh {disfmarker} Yeah . It may be entirely off and {disfmarker} and it may be {disfmarker} at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be {disfmarker} So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the {disfmarker} if the , uh {disfmarker} i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might {disfmarker} might be in that direction . Mm - hmm . Mm - hmm . Yeah . But , Anything else ? my {disfmarker} my point was more that it {disfmarker} it works sometimes and {disfmarker} but sometimes it doesn't work . Yeah . So . Well . And it works on TI - digits and on SpeechDat - Car it doesn't work , and {disfmarker} Yeah . Mm - hmm . Yeah . Well . But , you know , some problems are harder than others , Mm - hmm . Yeah . and {disfmarker} And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know , Mm - hmm . so it 's {disfmarker} But it {disfmarker} but , um , i it {disfmarker} it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ? Yeah . Yeah , sure . So . Uh . Hmm ? Yeah . Yeah . Well , there is also the spectral subtraction , which , um {disfmarker} I think maybe we should , uh , try to integrate it in {disfmarker} in our system . Yeah . Mmm . Mm - hmm . Right . But , O I think that would involve to {disfmarker} {vocalsound} to mmm {vocalsound} use a big {disfmarker} a {disfmarker} al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by , {vocalsound} um , other kind of processing that 's {disfmarker} are dependent on the {disfmarker} uh , if it 's speech or noi or silence . Mm - hmm . And there is this kind of spectral flattening after {disfmarker} if it 's silence , and {disfmarker} and s I {disfmarker} I think it 's important , um , {vocalsound} to reduce this musical noise and this {disfmarker} this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from {disfmarker} from the {disfmarker} this proposal and {disfmarker} and then just add some kind of on - line normalization in {disfmarker} in the neural network . Mmm . OK . Well , this 'll be , I think , something for discussion with Hynek next week . Yeah . Mm - hmm . Yeah . OK . Right . So . How are , uh , uh {disfmarker} how are things going with what you 're doing ? Oh . Well , um , I took a lot of time just getting my taxes out of the way {disfmarker} multi - national taxes . So , I 'm {disfmarker} I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here . Yeah . Do you know what his schedule will be like ? Uh , he 'll be around for three days . OK . So , y Uh , we 'll have a lot of time . OK . So , uh {disfmarker} Um . I 'll , uh {disfmarker} You know , he 's {disfmarker} he 'll {disfmarker} he 'll be talking with everybody in this room So . But you said you won't {disfmarker} you won't be here next Thursday ? Not Thursday and Friday . Yeah . Cuz I will be at faculty retreat . Hmm . So . I 'll try to {vocalsound} connect with him and people as {disfmarker} as I can on {disfmarker} on Wednesday . But {disfmarker} Um . Oh , how 'd taxes go ? Taxes go OK ? Mmm . Yeah . Yeah . Oh , good . Yeah . Yeah . That 's just {disfmarker} that 's {disfmarker} that 's one of the big advantages of not making much money is {vocalsound} the taxes are easier . Yeah . Unless you 're getting money in two countries . I think you are . Aren't you ? They both want their cut . Hmm . Hmm . Yeah . Right ? Yeah . Yeah . Huh . Canada w Canada wants a cut ? Mm - hmm . Have to do {disfmarker} So you {disfmarker} you have to do two returns ? Mmm . W uh , for two thousand I did . Yeah . Oh , oh . Yeah . For tw That 's right , ju But not for this next year ? Two thousand . Yeah . Probably not this next year , I guess . Ye Yeah . Um . Yeah . Uh , I 'll {disfmarker} I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a {disfmarker} considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return . OK . Alright . Uh . Barry , do you wanna {pause} say something about your stuff here ? Oh , um . Right . I {pause} just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um {disfmarker} Yeah . It 's {disfmarker} that 's pretty much it . Oh , well . No Um , why don't you say something about what it is ? Oh , you {disfmarker} oh , you want {disfmarker} you want details . Hmm . OK . Well , we 're all gathered here together . I thought we 'd , you know {disfmarker} I was hoping I could wave my hands . Um . So , um . So , once wa I {disfmarker} I was thinking getting {disfmarker} getting us a set of acoustic events to {disfmarker} um , to be able to distinguish between , uh , phones and words and stuff . And {vocalsound} um , once we {disfmarker} we would figure out a set of these events that can be , you know , um , hand - labeled or {disfmarker} or derived , uh , from h the hand - labeled phone targets . Um , we could take these events and , um , {vocalsound} do some cheating experiments , um , where we feed , um , these events into {pause} an SRI system , um , eh , and evaluate its performance on a Switchboard task . Uh , yeah . Hey , Barry ? Can you give an example of an event ? Yeah . Sure . Um , I {disfmarker} I can give you an example of {pause} twenty - odd events . Um {disfmarker} So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality . Whose paper is it ? Um , this is a paper by Hubener and Cardson {pause} Benson {disfmarker} Bernds - Berndsen . Yeah . Huh . From , uh , University of Hamburg and Bielefeld . Mm - hmm . OK . Um . Yeah . I think the {disfmarker} just to expand a little bit on the idea of acoustic event . Mm - hmm . There 's , um {disfmarker} in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um {disfmarker} So , stuff that 's not based on data . Stuff that 's not based on data , necessarily . Yeah . Oh , OK . Yeah . Yeah , OK . Right . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height , Yeah . its tenseness , laxness , things like that , Mm - hmm . which may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um {disfmarker} it 's a little different , in {disfmarker} at least in my mind . I mean , when we did the SPAM work {disfmarker} I mean , there we had {disfmarker} we had this notion of an , uh , auditory {disfmarker} @ @ {comment} auditory event . Good . That 's great . And , uh , um , called them \" avents \" , uh , uh , uh , with an A at the front . Mm - hmm . Uh . And the {disfmarker} the {disfmarker} the idea was something that occurred that is important to a bunch of neurons somewhere . So . Mm - hmm . Um . A sudden change or a relatively rapid change in some spectral characteristic will {disfmarker} will do sort of this . I mean , there 's certainly a bunch of {disfmarker} a bunch of places where you know that neurons are gonna fire because something novel has happened . That was {disfmarker} that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but {disfmarker} It 's kinda like the difference between top - down and bottom - up . Yeah . I think of the acoustic {disfmarker} you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be {disfmarker} you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event . Mm - hmm . What {disfmarker} ? And then that {disfmarker} you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that . Mm - hmm . And so it 's sort of a different way of looking . Mm - hmm . Yeah . So . Yeah . OK . Mm - hmm . Um {disfmarker} Using these {disfmarker} these events , um , you know , we can {disfmarker} we can perform these {disfmarker} these , uh , cheating experiments . See how {disfmarker} how {disfmarker} how good they are , um , in , um {disfmarker} in terms of phoneme recognition or word recognition . And , um {disfmarker} and then from that point on , I would , uh , s design robust event detectors , um , in a similar , um , wa spirit that Saul has done w uh , with his graphical models , and this {disfmarker} this probabilistic AND - OR model that he uses . Um , eh , try to extend it to , um {disfmarker} to account for other {disfmarker} other phenomena like , um , CMR co - modulation release . And , um {disfmarker} and maybe also investigate ways to {disfmarker} to modify the structure of these models , um , in a data - driven way , uh , similar to the way that , uh , Jeff {disfmarker} Jeff , uh , Bilmes did his work . Um , and while I 'm {disfmarker} I 'm doing these , um , event detectors , you know , I can ma mea measure my progress by comparing , um , the error rates in clean and noisy conditions to something like , uh , neural nets . Um , and {disfmarker} So {disfmarker} so , once we have these {disfmarker} these , uh , event detectors , um , we could put them together and {disfmarker} and feed the outputs of the event detectors into {disfmarker} into the SRI , um , HMM {disfmarker} HMM system , and , um {disfmarker} and test it on {disfmarker} on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the {disfmarker} the big picture of {disfmarker} of um , the plan . By the way , um , there 's , uh , a couple people who are gonna be here {disfmarker} I forget if I already told you this , but , a couple people who are gonna be here for six months . Mm - hmm . Uh {disfmarker} uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at {vocalsound} auditory properties inspired by various , uh , brain function things . Hmm . So , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are {disfmarker} are , uh , developing . Hmm . OK . So , he looks at interesting {disfmarker} interesting things in {disfmarker} in the {disfmarker} {vocalsound} different ways of looking at spectra in order to {disfmarker} to get various speech properties out . So . OK . OK . Well , short meeting , but that 's OK . And , uh , we might as well do our digits . And like I say , I {disfmarker} I encourage you to go ahead and meet , uh , next week with , uh , uh , Hynek . Alright , I 'll {disfmarker} I 'll start . It 's , uh , one thirty - five . seventeen OK",
        "summarize": null
    }
]