[
    {
        "transcript": "OK . We seem to be recording . Alright ! So , sorry about not {disfmarker} We 're not crashing . Number four . not pre - doing everything . The lunch went a little later than I was expecting , Chuck . Hmm ? OK . Chuck was telling too many jokes , or something ? Yep . Pretty much . Yeah . OK . {vocalsound} Does anybody have an agenda ? No . Well , I 'm {disfmarker} I sent a couple of items . They 're {disfmarker} they 're sort of practical . I thought {pause} somebody had . I don't know if you 're {disfmarker} Yeah , that 's right . if {disfmarker} if that 's too practical for what we 're {pause} focused on . I mean , we don't want anything too practical . Yeah , we only want th useless things . Yeah , that would be {disfmarker} Yeah . No , why don't we talk about practical things ? OK . Sure . Well , um , I can {pause} give you an update on the {pause} transcription effort . Great . Uh , maybe {nonvocalsound} raise the issue of microphone , uh , um procedures with reference to the {pause} cleanliness of the recordings . OK , transcription , uh , microphone issues {disfmarker} And then maybe {nonvocalsound} ask , th uh , these guys . The {disfmarker} we have great {disfmarker} great , uh , p steps forward in terms of the nonspeech - speech pre - segmenting of the signal . OK . Well , we have steps forward . Yeah . Well , it 's a {disfmarker} it 's a big improvement . I would prefer this . Yes . Yeah , well . OK . Uh {disfmarker} We talk about the {disfmarker} {vocalsound} the results of You have some {disfmarker} Yeah . I have a little bit of IRAM stuff OK . use {disfmarker} but {pause} I 'm not sure if that 's of general interest or not . Uh , bigram ? IRAM . IRAM . IRAM . IRAM , bigram , Well , m maybe . Bi - Bigram . you know . Yeah , let 's {disfmarker} let 's see where we are at three - thirty . Hmm . Um {disfmarker} Since , uh {disfmarker} since I have to leave as usual at three - thirty , can we do the interesting stuff first ? I beg your pardon ? Well {disfmarker} Which is {disfmarker} ? What 's the interesting stuff ? I beg your pardon ? Yeah . Yeah . Th - now you get to tell us what 's the interesting part . Please specify . But {disfmarker} Well , uh , I guess the work that 's been {pause} done on segmentation would be most {disfmarker} Yeah . I think that would be a good thing to start with . Yeah . OK . Um , and , um , {vocalsound} the other thing , uh , which I 'll just say very briefly that maybe relates to that a little bit , which is that , um , uh , one of the suggestions that came up in a brief meeting I had the other day when I was in Spain with , uh , Manolo Pardo and {vocalsound} Javier , uh , Ferreiros , who was {pause} here before , was , um , why not start with what they had before but add in the non - silence boundaries . So , in what Javier did before when they were doing , um {disfmarker} h he was looking for , uh , speaker change {pause} points . Mm - hmm . Um . As a simplification , he originally did this only using {pause} silence as , uh , a {pause} putative , uh , speaker change point . Yeah . And , uh , he did not , say , look at points where you were changing broad sp uh , phonetic class , for instance . And for Broadcast News , that was fine . Here obviously it 's not . Yeah . And , um , so one of the things that they were pushing in d in discussing with me is , um , w why are you spending so much time , uh , on the , uh , feature issue , uh , when perhaps if you sort of deal with what you were using before Uh - huh . and then just broadened it a bit , instead of just ta using silence as putative change point also {disfmarker} ? Nnn , yeah . So then you 've got {disfmarker} you already have the super - structure with Gaussians and H - you know , simple H M Ms and so forth . And you {disfmarker} you might {disfmarker} So there was a {disfmarker} there was a little bit of a {disfmarker} a {disfmarker} a {disfmarker} a difference of opinion because I {disfmarker} I thought that it was {disfmarker} it 's interesting to look at what features are useful . Yeah . But , uh , on the other hand I saw that the {disfmarker} they had a good point that , uh , if we had something that worked for many cases before , maybe starting from there a little bit {disfmarker} Because ultimately we 're gonna end up {vocalsound} with some s su kind of structure like that , Yeah . where you have some kind of simple HMM and you 're testing the hypothesis that , {vocalsound} uh , there is a change . Yeah . So {disfmarker} so anyway , I just {disfmarker} reporting that . OK . But , uh , uh {disfmarker} So . Yeah , why don't we do the speech - nonspeech discussion ? Yeah . Do {disfmarker} I {disfmarker} I hear {disfmarker} you {disfmarker} you didn't {disfmarker} Speech - nonspeech ? OK . Uh - huh . Yeah . Um , so , uh , what we basically did so far was using the mixed file to {disfmarker} to detect s speech or nonspeech {pause} portions in that . Mm - hmm . And what I did so far is I just used our old Munich system , which is an HMM - ba based system with Gaussian mixtures for s speech and nonspeech . And it was a system which used only one Gaussian for silence and one Gaussian for speech . And now I added , uh , multi - mixture possibility for {disfmarker} {vocalsound} for speech and nonspeech . Mm - hmm . Mm - hmm . And I did some training on {disfmarker} on one dialogue , which was transcribed by {disfmarker} Yeah . We {disfmarker} we did a nons s speech - nonspeech transcription . Jose . Adam , Dave , and I , we did , for that dialogue and I trained it on that . And I did some pre - segmentations for {disfmarker} for Jane . And I 'm not sure how good they are or what {disfmarker} what the transcribers say . They {disfmarker} they can use it or {disfmarker} ? Uh , they {disfmarker} they think it 's a terrific improvement . And , um , it real it just makes a {disfmarker} a world of difference . Hmm . And , um , y you also did some something in addition which was , um , for those in which there {nonvocalsound} was , uh , quiet speakers in the mix . Yeah . Uh , yeah . That {disfmarker} that was one {disfmarker} one {disfmarker} one thing , uh , why I added more mixtures for {disfmarker} for the speech . So I saw that there were loud {disfmarker} loudly speaking speakers and quietly speaking speakers . Mm - hmm . And so I did two mixtures , one for the loud speakers and one for the quiet speakers . And did you hand - label who was loud and who was quiet , or did you just {disfmarker} ? I did that for {disfmarker} for five minutes of one dialogue Right . and that was enough to {disfmarker} to train the system . W What {disfmarker} ? Yeah . And so it {disfmarker} it adapts , uh , on {disfmarker} while running . So . What kind of , uh , front - end processing did you do ? Hopefully . OK . It 's just our {disfmarker} our old Munich , uh , loudness - based spectrum on mel scale twenty {disfmarker} twenty critical bands and then loudness . Mm - hmm . And four additional features , which is energy , loudness , modified loudness , and zero crossing rate . So it 's twenty - four {disfmarker} twenty - four features . Mmm . Mm - hmm . And you also provided me with several different versions , Yeah . which I compared . Yeah . And so you change {nonvocalsound} parameters . What {disfmarker} do you wanna say something about the parameters {nonvocalsound} that you change ? Yeah . You can specify {vocalsound} the minimum length of speech or {disfmarker} and silence portions which you want . And so I did some {disfmarker} some modifications in those parameters , basically changing the minimum {disfmarker} minimum {pause} length for s for silence to have , er to have , um {disfmarker} yeah {disfmarker} to have more or less , uh , silence portions in inserted . So . Right . So this would work well for , uh , pauses and utterance boundaries and things like that . Yeah . Yeah . Yeah . But for overlap I imagine that doesn't work at all , Yeah . Yeah . that you 'll have plenty of s sections that are {disfmarker} Yeah . Yeah . That 's it . Yeah . Mm - hmm , mm - hmm . Yeah . But {disfmarker} That 's true . But {nonvocalsound} it {disfmarker} it saves so much time {disfmarker} the {disfmarker} the {nonvocalsound} transcribers Um {disfmarker} Yep . just enormous , enormous savings . Fantastic . That 's great . Um , just qu one quickly , uh , still on the features . So {vocalsound} you have these twenty - four features . Yeah . Uh , a lot of them are spectral features . Is there a {disfmarker} a transformation , uh , like principal components transformation or something ? No . Yeah . It was IS two . No . W w we {disfmarker} originally we did that Just {disfmarker} but we saw , uh , when we used it , uh , f for our close - talking microphone , which {disfmarker} yeah , for our {disfmarker} for our recognizer in Munich {disfmarker} we saw that w it 's {disfmarker} it 's not {disfmarker} it 's not so necessary . It {disfmarker} it works as well f with {disfmarker} with {disfmarker} without , uh , a LDA or something . OK . OK . No , I was j {pause} curious . Yeah . Mm - hmm . Yeah , I don't think it 's a big deal for this application , Yeah . Right . but {disfmarker} but {disfmarker} Yeah , it 's a {disfmarker} Mm - hmm . OK . But then there 's another thing that also Thilo 's involved with , which is , um {disfmarker} OK , and {disfmarker} and also Da - Dave Gelbart . So there 's this {disfmarker} this problem of {disfmarker} and w and {disfmarker} so we had this meeting . Th - the {nonvocalsound} {disfmarker} also Adam , before the {disfmarker} the {disfmarker} before you went away . Uh we , um {disfmarker} regarding the representation {nonvocalsound} of overlaps , because at present , {nonvocalsound} {vocalsound} um , because {nonvocalsound} of the limitations of {vocalsound} th the interface we 're using , overlaps are , uh , not being {nonvocalsound} encoded by {nonvocalsound} the transcribers in as complete {nonvocalsound} and , uh , detailed a way as it might be , and as might be desired {disfmarker} I think would be desired in the corpus ultimately . Mm - hmm . So we don't have start and end points {nonvocalsound} at each point where there 's an overlap . We just have the {disfmarker} the {nonvocalsound} overlaps {nonvocalsound} encoded in a simple bin . Well , OK . So {nonvocalsound} @ @ the limits of the {nonvocalsound} over of {disfmarker} of the interface are {vocalsound} such that we were {disfmarker} at this meeting we were entertaining how we might either expand {nonvocalsound} the {disfmarker} the {vocalsound} interface or find other tools which already {pause} do what would be useful . Because what would ultimately be , um , ideal in my {disfmarker} my view and I think {disfmarker} I mean , I had the sense that it was consensus , is that , um , a thorough - going musical score notation would be {nonvocalsound} the best way to go . Because {nonvocalsound} you can have multiple channels , there 's a single time - line , it 's very clear , flexible , and all those nice things . Mm - hmm . OK . So , um , um , I spoke {disfmarker} I had a meeting with Dave Gelbart on {disfmarker} on {disfmarker} and he had , uh , excellent ideas on how {pause} the interface could be {pause} modified to {disfmarker} to do this kind of representation . But , um , he {disfmarker} in the meantime you were checking into the existence of already , um , existing interfaces which might already have these properties . So , do you wanna say something about that ? Yes . Um , I {vocalsound} talked with , uh , Munich guys from {disfmarker} from Ludwi - Ludwig Maximilians University , who do a lot of transcribing and transliterations . Mm - hmm . And they basically said they have {disfmarker} they have , uh , a tool they developed {pause} themselves and they can't give away , uh , f it 's too error - prone , and had {disfmarker} it 's not supported , a a a and {disfmarker} Yeah . But , um , Susanne Bur - Burger , who is at se CMU , he wa who was formally at {disfmarker} in Munich and w and is now at {disfmarker} with CMU , she said she has something which she uses to do eight channels , uh , trans transliterations , eight channels simultaneously , Excuse me . but it 's running under Windows . Under Windows . So I 'm not sure if {disfmarker} if {disfmarker} if we can use it . Mm - hmm . She said she would give it to us . Mm - hmm . It wouldn't be a problem . And I 've got some {disfmarker} some kind of manual {pause} down in my office . Well , maybe we should get it and if it 's good enough we 'll arrange Windows machines to be available . Yeah . Mm - hmm . We could {disfmarker} uh , potentially {nonvocalsound} so . So . I also wanted to be sure {disfmarker} I mean , I 've {disfmarker} I 've seen the {disfmarker} this {disfmarker} this is called Praat , PRAAT , {nonvocalsound} which I guess means spee speech in Dutch or something . Yep . Yeah , but then I 'm not sure {pause} that 's the right thing for us . But {disfmarker} In terms {nonvocalsound} of it being {nonvocalsound} Windows {nonvocalsound} versus {disfmarker} Yeah . No , no . Praat isn't {disfmarker} Praat 's multi - platform . But I 'm just wondering , is {disfmarker} ? No . No , Praat {disfmarker} Yeah . Yeah . Oh ! I see . Yeah . Oh , I see . So Praat may not be {disfmarker} That 's not Praat . It 's called \" trans transedit \" {pause} I think . It 's a different one . The {disfmarker} the , uh {disfmarker} the tool from {disfmarker} from Susanne . I see . Oh , I see . OK . OK . Alright . The other thing , uh , to keep in mind , uh {disfmarker} I mean , we 've been very concerned to get all this rolling so that we would actually have data , Mmm , yeah . but , um , I think our outside sponsor is actually gonna kick in Mm - hmm . and ultimately that path will be smoothed out . So I don't know if we have a long - term need to do lots and lots of transcribing . I think we had a very quick need to get something out and we 'd like to be able to do some later because just it 's inter it 's interesting . But as far a you know , uh , with {disfmarker} with any luck we 'll be able to wind down the larger project . Oh . But you s What our decision was is that {pause} we 'll go ahead with what we have with a not very fine time scale on the overlaps . Yeah . Right . Yeah . And {disfmarker} and do what we can later {pause} to clean that up if we need to . Mm - hmm . Right . And {disfmarker} and I was just thinking that , um , {vocalsound} if it were possible to bring that in , like , {vocalsound} you know , this week , then {nonvocalsound} when they 're encoding the overlaps {nonvocalsound} it would be nice for them to be able to specify when {disfmarker} you know , the start points and end points of overlaps . Uh - huh . uh Th - they 're {nonvocalsound} making really quick progress . Yeah . That 's great . And , um , so my {disfmarker} my goal was {disfmarker} w m my charge was to get eleven hours by the end of the month . And it 'll be {disfmarker} I 'm {disfmarker} I 'm {disfmarker} I 'm clear that we 'll be able to do that . That 's great . And did you , uh , forward Morgan Brian 's {pause} thing ? Yeah . I sent {nonvocalsound} it to , um {disfmarker} who did I send that to ? I sent it to a list and I thought {nonvocalsound} I sent it to {nonvocalsound} the {nonvocalsound} {disfmarker} e to the local list . Meeting Recorder . Oh , you did ? OK . So you probably did get that . You saw that ? So Brian did tell {nonvocalsound} me that {nonvocalsound} in fact what you said , that , {nonvocalsound} uh {disfmarker} that {nonvocalsound} our {disfmarker} that they are {pause} making progress and that he 's going {disfmarker} that {nonvocalsound} they 're {nonvocalsound} going {disfmarker} he 's gonna check the f the output of the first transcription and {disfmarker} and {disfmarker} I mean , basically it 's {disfmarker} it 's all the difference in the world . I mean , basically he 's {disfmarker} he 's on it now . Yeah . Oh , that 's {disfmarker} this is a new development . So {disfmarker} so {disfmarker} so this is {disfmarker} so i it 'll happen . OK . Super . Super . OK . Great . Yeah . I mean , basically it 's just saying that one of our {disfmarker} one of our best people is on it , Yeah . you know , who just doesn't happen to be here anymore . Someone else pays him . So {disfmarker} But about the need for transcription , Isn't that great ? I mean , don't we {disfmarker} didn't we previously {vocalsound} decide that the {pause} IBM {pause} transcripts would have to be {pause} checked anyway and possibly augmented ? So . {vocalsound} Yeah . Yes . That 's true . So , I think having a good tool is worth something no matter what . Mm - hmm . Yeah . S OK . That 's {disfmarker} that 's a good point . Yeah , and Dave Gelbart did volunteer , Good . and since he 's not here , I 'll repeat it {disfmarker} to at least modify Transcriber , which , if we don't have something else that works , I think that 's a pretty good way of going . Mmm . Mm - hmm . And we discussed on some methods to do it . My approach originally , and I 've already hacked on it a little bit {disfmarker} it was too slow because I was trying to display all the waveforms . But he pointed out that you don't really have to . I think that 's a good point . Mm - hmm . Mm - hmm . That if you just display the mix waveform and then have a user interface for editing the different channels , that 's perfectly sufficient . Hmm . Yeah , exactly . And just keep those {nonvocalsound} things separate . And {disfmarker} and , um , Dan Ellis 's hack already allows them to be {nonvocalsound} able to display {vocalsound} different {nonvocalsound} waveforms to clarify overlaps and things , No . They can only display one , so that 's already {disfmarker} but they can listen to different ones . Oh , yes , but {disfmarker} Well , {vocalsound} uh , yes , but {nonvocalsound} what I mean is {pause} that , uh , from the transcriber 's {nonvocalsound} perspective , uh , those {nonvocalsound} two functions are separate . And Dan Ellis 's hack handles the , {vocalsound} um , choice {nonvocalsound} {disfmarker} the ability to choose different waveforms {vocalsound} from moment to moment . But only to listen to , not to look at . Yeah . Um {disfmarker} The waveform you 're looking at doesn't change . Yeah . That 's true . Yeah . Yeah , but {nonvocalsound} that 's {disfmarker} that 's OK , cuz they 're {disfmarker} they 're , you know , they 're focused on the ear anyway . Right . And then {disfmarker} and then Hmm . the hack to {vocalsound} preserve the overlaps {nonvocalsound} better would be one which creates different output files for each channel , Right . which then {nonvocalsound} would also serve Liz 's request {pause} of having , you know , a single channel , separable , uh , cleanly , easily separable , Mm - hmm . uh , transcript tied to a single channel , uh , audio . Mm - hmm . Have , uh , folks from NIST been in contact with you ? Not directly . I 'm trying to think if {disfmarker} if I could have gotten it over a list . OK . I don't {disfmarker} I don't think so . OK . Well , holidays may have interrupted things , cuz in {disfmarker} in {disfmarker} in {disfmarker} They {vocalsound} seem to want to {pause} get absolutely clear on standards for {disfmarker} transcription standards and so forth with {disfmarker} with us . Oh ! This was from before December . Yeah . Right . Because they 're {disfmarker} they 're presumably going to start recording next month . OK . OK . Oh , we should definitely get with them then , So . and agree upon a format . Though I don't remember email on that . So was I not in the loop on that ? Um . Yeah , I don't think I mailed anybody . I just think I told them to contact Jane {disfmarker} that , uh , if they had a {disfmarker} Oh , OK . That 's right . if , uh {disfmarker} that {disfmarker} that , uh , as the point person on it . Yeah , I think that 's right . But {disfmarker} Just , uh {disfmarker} So , yeah . Maybe I 'll , uh , ping them a little bit about it to {vocalsound} get that straight . OK . I 'm keeping the conventions {pause} absolutely {pause} as simple {nonvocalsound} as possible . Yeah . So is it {disfmarker} cuz with any luck there 'll actually be a {disfmarker} a {disfmarker} there 'll be collections at Columbia , collections at {disfmarker} at UW {disfmarker} I mean Dan {disfmarker} Dan is very interested in doing some other things , Right . Yeah . Yeah . Well , I think it 's important both for the notation and the machine representation to be the same . and collections at NIST . So {disfmarker} Yeah . So . N there was also this , {nonvocalsound} uh , email from Dan regarding the {pause} speech - non nonspeech segmentation thing . Yep . Yeah . Yeah . I don't know if , uh , uh , we wanna , uh {disfmarker} and Dan Gel - and Dave Gelbart is interested in pursuing the aspect {nonvocalsound} of using amplitude {nonvocalsound} as a {disfmarker} a {disfmarker} a {disfmarker} as a basis for the separation . Cross - correlation . Oh , yeah . He was talking {disfmarker} he was talking {disfmarker} I mean , uh , we {disfmarker} he had {disfmarker} Cross Yeah , cross - correlation . Cross I had mentioned this a couple times before , the c the commercial devices that do , uh , {vocalsound} uh , voice , uh {disfmarker} you know , active miking , Uh - huh . basically look at the amp at the energy at each of the mikes . And {disfmarker} and you basically compare the energy here to {vocalsound} some function of all of the mikes . Yeah . Yeah . OK . So , by doing that , you know , rather than setting any , uh , absolute threshold , you actually can do pretty good , uh , selection of who {disfmarker} who 's talking . OK . Uh {disfmarker} And those {disfmarker} those systems work very well , by the way , I mean , so people use them in {vocalsound} panel discussions and so forth with sound reinforcement differing in {disfmarker} in sort of , Uh - huh . uh {disfmarker} and , uh , those {disfmarker} if {disfmarker} Boy , the guy I knew who built them , built them like twenty {disfmarker} twenty years ago , Hmm . so they 're {disfmarker} {vocalsound} it 's {disfmarker} the {disfmarker} the techniques work pretty well . Fantastic . Cuz there is one thing that we don't have right now and that is the automatic , um , channel identifier . So . That {disfmarker} that , you know , that would g help in terms of encoding of overlaps . Mm - hmm . The {disfmarker} the transcribers would have less , uh , disentangling to do {pause} if that were available . Yeah . So I think , you know , basically you can look at some {disfmarker} p you have to play around a little bit , uh , to figure out what the right statistic is , But . Mm - hmm . Mm - hmm . but you compare each microphone to some statistic based on the {disfmarker} {vocalsound} on the overall {disfmarker} Yeah . Mm - hmm . OK . Uh , and we also have these {disfmarker} we have the advantage of having {pause} distant mikes too . So that , you cou yo Yeah , although the {disfmarker} the {disfmarker} using the close - talking I think would be much better . Wouldn't it ? Yeah . Um . I {disfmarker} I don't know . Yeah . I just {disfmarker} it 'd be {disfmarker} If I was actually working on it , I 'd sit there and {disfmarker} and play around with it , and {disfmarker} and get a feeling for it . I mean , the {disfmarker} the {disfmarker} the , uh {disfmarker} But , uh , you certainly wanna use the close - talking , as a {disfmarker} at least . Right . I don't know if the other would {disfmarker} would add some other helpful dimension or not . Mm - hmm . Mm - hmm . OK . What {disfmarker} what are the different , uh , classes to {disfmarker} to code , uh , the {disfmarker} the overlap , you will use ? Um , to code d What you {disfmarker} you {disfmarker} so types of overlap ? Yeah . Um , so {nonvocalsound} at a meeting that wasn't transcribed , we worked up a {disfmarker} a typology . Yeah . And , um {disfmarker} Look like , uh , you t you explaining in the blackboard ? The {disfmarker} ? Yeah ? Yeah . Yes , exactly . That hasn't changed . So it {nonvocalsound} i the {disfmarker} it 's basically a two - tiered structure where the first one is whether {nonvocalsound} the person who 's interrupted continues or not . And then below that there 're {nonvocalsound} subcategories , uh , that have more to do with , {nonvocalsound} you know , is it , {vocalsound} uh , simply {nonvocalsound} backchannel Mm - hmm . or is {nonvocalsound} it , um , someone completing someone else 's thought , or is it someone in introducing a new thought . Right . And I hope that if we do a forced alignment with the close - talking mike , that will be enough to recover at least some of the time the time information of when the overlap occurred . Huh . Yeah . Yeah . Mm - hmm . Well , {vocalsound} one would {disfmarker} We hope . Yeah . Who knows ? That 'd be {disfmarker} that 'd be nice . I mean , {vocalsound} I {disfmarker} I {disfmarker} I {disfmarker} I 've {disfmarker} So who 's gonna do that ? Who 's gonna do forced alignment ? Well , u uh , IBM was going to . Um {disfmarker} Oh , OK . Oh . and I imagine they still plan to but {disfmarker} but , you know , I haven't spoken with them about that recently . OK . Uh - huh . Well , uh , my suggestion now is {disfmarker} is on all of these things to , uh , contact Brian . OK . I 'll do that . Yeah . This is wonderful {nonvocalsound} to have a direct contact like that . Yeah . uh Well , th lemme ask {nonvocalsound} you this . Yeah . It occurs to me {disfmarker} {vocalsound} one of my transcribers t {nonvocalsound} told {nonvocalsound} me today that she 'll {nonvocalsound} be finished with one meeting , {vocalsound} um , by {disfmarker} Mm - hmm . well , she said tomorrow but then she said {nonvocalsound} {disfmarker} you know , but {nonvocalsound} {disfmarker} the , you know {disfmarker} let 's {disfmarker} let 's just , uh , say Mm - hmm . maybe the day after just to be s on the safe side . I could send Brian the , {nonvocalsound} um {disfmarker} the {nonvocalsound} transcript . I know these {nonvocalsound} are {disfmarker} er , uh , I could send him that {nonvocalsound} if {nonvocalsound} it would be possible , {nonvocalsound} or a good idea or not , to {nonvocalsound} try {nonvocalsound} to do a s forced alignment on what we 're {disfmarker} on the way we 're encoding overlaps now . Well , just talk to him about it . Yep . Good . I mean , you know , basically he 's {disfmarker} he just studies , he 's a colleague , a friend , and , Yeah ! uh , they {disfmarker} and {disfmarker} and , you know , the {disfmarker} the organization always did wanna help us . Super . Super . It was just a question of getting , you know , the right people connected in , who had the time . Right . Yeah , yeah . So , um , eh {disfmarker} Is he on the mailing list ? The Meeting Recorder mailing li ? Oh ! We should add him . Yeah . I {disfmarker} I {disfmarker} I don't know for sure . Yeah . Did something happen , Morgan , that he got put on this , or was he already on it , Add him . or {disfmarker} ? No , I , eh , eh , p It {disfmarker} it oc I {disfmarker} h it 's {disfmarker} Yeah , something happened . I don't know what . He asked for more work . Huh . But he 's on it now . That would be {nonvocalsound} like {disfmarker} that 'd be like him . He 's great . Right . So , uh , where are we ? Maybe , uh , uh , brief {disfmarker} Well , let 's {disfmarker} why don't we talk about microphone issues ? Yeah . That 'd be great . That was {disfmarker} that was a {disfmarker} Um , so one thing is that I did look on Sony 's for a replacement for the mikes {disfmarker} {vocalsound} for the head m head - worn ones cuz they 're so uncomfortable . But I think I need someone who knows more about mikes than I do , because I couldn't find a single other model that seemed like it would fit the connector , which seems really unlikely to me . Does anyone , like , know stores or {vocalsound} know about mikes who {disfmarker} who would know the right questions to ask ? Oh , I probably would . I mean , my knowledge is twenty years out of date but some of it 's still the same . Mm - hmm . So {disfmarker} Uh , so maybe we c we can take a look at that . You couldn't {disfmarker} you couldn't find the right connector to go into these things ? Yep . When I looked , i they listed one microphone and that 's it Huh ! as having that type of connector . But my guess is that Sony maybe uses a different number for their connector than everyone else does . And {disfmarker} and so {disfmarker} Mm - hmm . Well , let 's look at it together it seems {disfmarker} it seems really unlikely to me that there 's only one . and {disfmarker} And there 's no adaptor for it ? Yeah . Seems like there 'd be a {disfmarker} OK . As I said , who knows ? Mm - hmm . Who {disfmarker} who are we buying these from ? Um , That 'd be I have it downstairs . I don't remember off the top of my head . Yeah . OK . Yeah . We {disfmarker} we can try and look at that together . And then , uh {disfmarker} just in terms of how you wear them {disfmarker} I mean , I had thought about this before . I mean , when {disfmarker} when {disfmarker} when you use a product like DragonDictate , they have a very extensive description about how to wear the microphone and so on . Oh . But I felt that in a real situation we were very seldom gonna get people to really do it and maybe it wasn't worth concentrating on . But {disfmarker} Well , I think that that 's {disfmarker} that 's a good back - off position . That 's what I was saying {vocalsound} earlier , th that , you know , we are gonna get some {vocalsound} recordings that are imperfect and , hey , that 's life . But I {disfmarker} I think that it {disfmarker} it doesn't hurt , uh , the naturalness of the situation to try to have people {pause} wear the microphones properly , if possible , Mm - hmm . because , {vocalsound} um , the natural situation is really what we have with the microphones on the table . Oh . That 's true . I mean , I think , {vocalsound} you know , in the target applications that we 're talking about , people aren't gonna be wearing head - mounted mikes anyway . Yeah . Yeah . So this is just for u these head - mounted mikes are just for use with research . Mm - hmm . Yeah . And , uh , it 's gonna make {disfmarker} You know , if {disfmarker} if An - Andreas plays around with language modeling , he 's not gonna be m wanna be messed up by people breathing into the microphone . Right . So it 's {disfmarker} it 's , uh , uh {disfmarker} Well , I 'll dig through the documentation to DragonDictate and ste s see if they still have the little {pause} form . But it does happen . Yeah . Right ? I mean , and any {disfmarker} It 's interesting , uh , I talked to some IBM guys , uh , last January , I think , I was there . And {disfmarker} so people who were working on the {disfmarker} on their ViaVoice dictation product . Yeah . And they said , uh , the breathing is really a {disfmarker} a terrible problem {pause} for them , to {disfmarker} to not recognize breathing as speech . Wow . So , anything to reduce breathing is {disfmarker} is {disfmarker} is a good thing . Yeah . Well , that 's the {disfmarker} It seemed to me when I was using Dragon that it was really microphone placement helped an {disfmarker} in , uh {disfmarker} an enormous amount . Mm - hmm . So you want it enough to the side so that when you exhale through your nose , it doesn't {disfmarker} the wind doesn't hit the mike . Right . Mm - hmm . And then , uh {disfmarker} Everyone 's adjusting their microphones , of course . And then just close enough so that you get good volume . So you know , wearing it right about here seems to be about the right way to do it . Yeah . Yeah . Is {disfmarker} Uh - huh . I remember when I was {disfmarker} when I {disfmarker} I {disfmarker} I {disfmarker} I used , uh , um , {vocalsound} a prominent laboratory 's , uh , uh , speech recognizer about , {vocalsound} uh {disfmarker} This was , boy , this was a while ago , this was about twelve {disfmarker} twelve years ago or something . And , um , they were {disfmarker} they were perturbed with me because I was breathing in instead of breathing out . And they had models for {disfmarker} they {disfmarker} {vocalsound} they had Markov models for br breathing out but they didn't have them for breathing in . Yeah . Uh {disfmarker} That 's interesting . Well , what I wondered is whether it 's possible to have {disfmarker} {vocalsound} to maybe use the display at the beginning Yeah . to be able to {disfmarker} to judge how {disfmarker} how correctly {disfmarker} I mean , have someone do some routine whatever , and {disfmarker} and then see if when they 're breathing it 's showing . I mean , when {disfmarker} when it 's on , you can see it . I don't know if the {disfmarker} if it 's {disfmarker} I {disfmarker} You can definitely see it . Can you see the breathing ? Absolutely . Cuz I {disfmarker} Absolutely . Oh . Yeah . And so , you know , I 've {disfmarker} I 've sat here and watched sometimes the breathing , I and the bar going up and down , and I 'm thinking , I could say something , but I mean , I think {disfmarker} I don't want to make people self - conscious . Stop breathing ! It {disfmarker} it 's going to be imperfect . Yeah . Uh - huh . You 're not gonna get it perfect . And you can do some , uh , you know , first - order thing about it , which is to have people move it , uh , uh , a away from being just directly in front of the middle Yeah . Good . but not too far away . Yeah , i And then , you know , I think there 's not much {disfmarker} Because you can't al you know , interfere w you can't fine tune the meeting that much , I think . Right . Yeah . It 's sort of {disfmarker} That 's true . It just seems like i if something l simple like that can be tweaked {vocalsound} and the quality goes , you know , uh , dramatically up , then it might be worth {pause} doing . Yep . And then also {disfmarker} the position of the mike also . If it 's more directly , you 'll get better volume . So {disfmarker} so , like , yours is pretty far down {pause} below your mouth . Yeah . Yeah . But {disfmarker} Mm - hmm . My {disfmarker} my feedback from the transcribers is he is always close to crystal clear and {disfmarker} and just fan fantastic to {disfmarker} Yeah . Mmm , yeah . Mm - hmm . I don't know why that is . Well , I mean , you {disfmarker} Yeah , of course . You 're {disfmarker} you 're also {disfmarker} uh , your volume is {disfmarker} is greater . But {disfmarker} but still , I mean , they {disfmarker} they say {disfmarker} I 've been eating a lot . I it makes their {disfmarker} their job extremely easy . Uh . Yeah . And then there 's mass . Mm - hmm . Anyway . I could say something about {disfmarker} about the {disfmarker} Well , I don't know what you wanna do . Yeah . About what ? About the transcribers or anything or {disfmarker} ? I don't know . Well , the other {disfmarker} But , uh , just to {disfmarker} to , um {disfmarker} why don't we do that ? One more remark , uh , concerning the SRI recognizer . Um . It is useful to transcribe and then ultimately train models for things like breath , and also laughter is very , very frequent and important to {disfmarker} {vocalsound} to model . Mm - hmm . So , So , if you can in your transcripts mark {disfmarker} mark them ? mark very audible breaths and laughter especially , Mmm . um {disfmarker} They are . OK . They 're putting {disfmarker} Eh , so in curly brackets they put \" inhale \" or \" breath \" . Oh , great . Mm - hmm . It {disfmarker} they {disfmarker} and then in curly brackets they say \" laughter \" . Now they 're {disfmarker} {vocalsound} they 're not being {pause} awfully precise , uh , m So they 're two types of laughter that are not being distinguished . Mm - hmm . One is {vocalsound} when sometimes s someone will start laughing when they 're in the middle of a sentence . Mm - hmm . And {disfmarker} and then the other one is when they finish the sentence and then they laugh . So , um , I {disfmarker} I did s I did some double checking to look through {disfmarker} I mean , {vocalsound} you 'd need to have extra  e extra complications , like time tags indicating the beginning and ending of {disfmarker} {vocalsound} of the laughing through the utterance . It 's not so {disfmarker} I don't think it 's , um {disfmarker} And that {disfmarker} and what they 're doing is in both cases just saying \" curly brackets laughing \" a after the unit . As {disfmarker} as long as there is an indication that there was laughter somewhere between {pause} two words {vocalsound} I think that 's sufficient , Yeah . Good . Oh ! Against {disfmarker} they could do forced alignment . OK . because actually the recognition of laughter once you kn um {disfmarker} you know , is pretty good . Yeah . So as long as you can stick a {disfmarker} you know , a t a tag in there that {disfmarker} that indicates that there was laughter , Oh , I didn't know that . that would probably be , uh , sufficient to train models . OK . That would be a really interesting {pause} prosodic feature , Then {disfmarker} Yeah . And let me ask y and I gotta ask you one thing about that . when {disfmarker} Hmm . So , um , if they laugh between two words , you {disfmarker} you 'd get it in between the two words . Mm - hmm . Right . But if they laugh across three or four words you {disfmarker} you get it after those four words . Does that matter ? Yeah . Well , the thing that you {disfmarker} is hard to deal with is whe {vocalsound} when they speak while laughing . Um , and that 's , uh {disfmarker} I don't think that we can do very well with that . Right . So {disfmarker} Yeah . But , um , that 's not as frequent as just laughing between speaking , OK . So are {disfmarker} do you treat breath and laughter as phonetically , or as word models , or what ? so {disfmarker} Uh is it ? Huh . I {disfmarker} I think it 's frequent in {disfmarker} in the meeting . I think he 's right . Yeah . We tried both . Uh , currently , um , we use special words . There was a {disfmarker} there 's actually a word for {disfmarker} uh , it 's not just breathing but all kinds of mouth {disfmarker} Mm - hmm . Mouth stuff ? uh , mouth {disfmarker} mouth stuff . And then laughter is a {disfmarker} is a special word . How would we do that with the hybrid system ? Same thing . So train a phone {pause} in the neural net ? Same thing ? Yeah . Yeah . You ha Oh . And each of these words has a dedicated phone . No {disfmarker} Oh , it does ? So the {disfmarker} so the {disfmarker} the mouth noise , uh , word has just a single phone , um , that is for that . Right . So in the hybrid system we could train the net with a laughter phone and a breath sound phone . Yeah . Yeah . Yeah . I mean , it 's {disfmarker} it 's {disfmarker} it 's always the same thing . Mm - hmm . Right ? I mean , you could {disfmarker} you could say well , let {disfmarker}  we now think that laughter should have three sub sub {vocalsound} sub - units in the {disfmarker} the three states , uh {disfmarker} different states . Yeah . And then you would have three {disfmarker} I mean , you know , eh , eh , it 's u Do whatever you want . And the {disfmarker} the pronun the pronunciations {disfmarker} the pronunciations are l are somewhat non - standard . Yeah . Yeah , yeah . No . They actually are {disfmarker} uh , it 's just a single , s uh , you know , a single phone in the pronunciation , but it has a self - loop on it , so it can {disfmarker} To {pause} go on forever ? r can go on forever . And how do you handle it in the language model ? It 's just a {disfmarker} it 's just a word . It 's just a word in the language model . We train it like any other word . Cool . Yeah . We also tried , {vocalsound} um , absorbing these {disfmarker} uh , both laughter and {disfmarker} and actually also noise , and , um {disfmarker} Yeah . Yes . OK . Anyway . We also tried absorbing that into the pause model {disfmarker} I mean , the {disfmarker} the {disfmarker} the model that {disfmarker} that matches the stuff between words . Mm - hmm . And , um , it didn't work as well . So . Huh . OK . Mm - hmm . Can you hand me your digit form ? Sorry . I just wanna mark that you did not read digits . OK . Say hi for me . Good . You {disfmarker} you did get me to thinking about {disfmarker} I {disfmarker} I 'm not really sure which is more frequent , whether f f laughing {disfmarker} I think it may be an individual thing . Some people are more prone to laughing when they 're speaking . Yeah . I was noticing that with Dan in the one that we , uh {disfmarker} we hand tran hand - segmented , Yeah . I think {disfmarker} But I can't {disfmarker} Yeah . that {disfmarker} th he has these little chuckles as he talks . Yeah . OK . I 'm sure it 's very individual . And {disfmarker} and {disfmarker} one thing that c that we 're not doing , of course , is we 're not claiming to , uh , get {disfmarker} be getting a representation of mankind in these recordings . We have {vocalsound} this very , very tiny sample of {disfmarker} of {disfmarker} Yeah . Yeah . Yeah . Speech researchers ? Uh , yeah . And {disfmarker} {vocalsound} Yeah , r right . Speech research . So , uh , who knows . Uh {disfmarker} Yeah . Why don why don't we just {disfmarker} since we 're on this vein , why don't we just continue with , uh , what you were gonna say about the transcriptions OK . and {disfmarker} ? Um , um , the {disfmarker} I {disfmarker} I 'm really very for I 'm extremely fortunate with the people who , uh , applied and who are transcribing for us . They {vocalsound} are , um , um , uh really perceptive and very , um {disfmarker} and I 'm not just saying that cuz they might be hearing this . Cuz they 're gonna be transcribing it in a few days . No , they 're super . They 're {disfmarker} the they {disfmarker} very quick . OK . Turn the mikes off and let 's talk . Yeah , I know . I am {disfmarker} I 'm serious . They 're just super . So I , um , e you know , I {disfmarker} I brought them in and , um , trained them in pairs because I think people can raise questions {disfmarker} That 's a good idea . you know , i i the they think about different things and they think of different {disfmarker} and um , I trained them to , uh , f on about a minute or two of the one that was already transcribed . This also gives me a sense of {disfmarker} You know , I can {disfmarker} I can use that later , with reference to inter - coder reliability kind of issues . But the main thing was to get them used to the conventions and , {vocalsound} you know , the idea of the {disfmarker} th th the size of the unit versus how long it takes to play it back so these {disfmarker} th sort of calibration issues . And then , um , I just set them loose and they 're {disfmarker} they all have e a already background in using computers . They 're , um {disfmarker} they 're trained in linguistics . Good . Oh , no . Is that good or bad ? They got {disfmarker} Uh - huh . Well , they they 're very perce they 'll {disfmarker} So one of them said \" well , you know , he really said \" n \" , not really \" and \" , Yeah . Yeah . so what {vocalsound} {disfmarker} what should I do with that ? \" Yeah . And I said , \" well for our purposes , Yeah . I do have a convention . If it 's an {disfmarker} a noncanonical p \" That one , I think we {disfmarker} you know , with Eric 's work , I sort of figure we {disfmarker} we can just treat that as a variant . But I told them if {disfmarker} if there 's an obvious speech error , uh , like I said in one thing , OK . Yes . and I gave my {disfmarker} my example , like I said , \" microfon \" {pause} in instead of \" microphone \" . Didn't bother {disfmarker} I knew it when I said it . I remember s thinking \" oh , that 's not correctly pronounced \" . But it {disfmarker} but I thought {vocalsound} it 's not worth fixing cuz often when you 're speaking everybody knows what {disfmarker} what you mean . You 'll self - repair . Yeah . Yeah . But I have a convention that if it 's obviously a noncanonical pronunciation {disfmarker} a speech error with {disfmarker} you know , wi within the realm of resolution that you can tell in this native English {disfmarker} American English speaker , you know that I didn't mean to say \" microfon . \" Then you 'd put a little tick at the beginning of the word , Yeah . and that just signals that , um , this is not standard , and then in curly brackets \" pron {nonvocalsound} error \" . And , um , and other than that , it 's w word level . But , you know , the fact that they noticed , you know , the \" nnn \" . \" He said \" nnn \" , not \" and \" . What shall I do with that ? \" I mean , they 're very perceptive . And {disfmarker} and s several of them are trained in IPA . C they really could do phonetic transcription if {disfmarker} if we wanted them to . Mm - hmm . Right . Well {disfmarker} {vocalsound} Well , you know , it might be something we 'd wanna do with some , uh , s small subset {pause} of the whole thing . Hmm . Where were they when {pause} we needed them ? I think {disfmarker} We certainly wouldn't wanna do it with everything . And I 'm also thinking these people are a terrific pool . I mean , if , uh {disfmarker} so I {disfmarker} I told them that , um , we don't know if this will continue past the end of the month Uh - huh . and I also {disfmarker} m I think they know that the data p source is limited and I may not be able to keep them employed till the end of the month even , although I hope to . The other thing we could do , actually , uh , is , uh , use them for a more detailed analysis of the overlaps . And {disfmarker} Oh , that 'd be so super . They would be so {disfmarker} s so terrific . I mean , this was something that we were talking about . Right ? We could get a very detailed overlap if they were willing to transcribe each meeting four or five times . Right ? One for each participant . So they could by hand {disfmarker} Well , that 's one way to do it . Yeah . But I 've been saying the other thing is just go through it for the overlaps . Yeah . Mm - hmm , that 's right . Right ? And with the right in interface {disfmarker} Given that y and {disfmarker} and do {disfmarker} so instead of doing phonetic , uh , uh , transcription for the whole thing , Yeah . which {vocalsound} we know from the {disfmarker} Steve 's experience with the Switchboard transcription is , you know , very , very time - consuming . And {disfmarker} {vocalsound} and you know , it took them I don't know how many months to do {disfmarker} to get four hours . And so {vocalsound} that hasn't been really our focus . Uh , we can consider it . But , I mean , the other thing is since we 've been spending so much time thinking about overlaps is {disfmarker} is maybe get a much more detailed analysis of the overlaps . Yeah . Mm - hmm . But anyway , I 'm {disfmarker} I 'm open to c our consideration . That 'd be great . Hmm . I {disfmarker} I don't wanna say that by fiat . Yeah . I 'm open to every consideration of {vocalsound} what are some other kinds of detailed analysis that would be most useful . Mm - hmm . And , uh , uh , Hmm . I {disfmarker} I {disfmarker} I think {vocalsound} this year we {disfmarker} we actually , uh , can do it . Oh , wonderful . It 's a {disfmarker} we have {disfmarker} we have {disfmarker} due to @ @ {comment} variations in funding we have {disfmarker} we seem to be doing , uh , very well on m money for this {disfmarker} this year , and {vocalsound} next year we may have {disfmarker} have much less . Is {disfmarker} you mean two thousand one ? So I don't wanna hire a {disfmarker} Calendar year or {disfmarker} ? Uh , I mean , calendar year two thousand one . OK . Yeah . So it 's {disfmarker} uh , it 's {disfmarker} we don't wanna hire a bunch of people , a long - term staff , Full - time . Yeah . Mm - hmm . Yeah . because {vocalsound} the {disfmarker} the funding that we 've gotten is sort of a big chunk for this year . But {vocalsound} having {pause} temporary people doing some specific thing that we need is actually a perfect match to that kind of , uh , funding . Wonderful . Yeah . And then school will start in {disfmarker} in the sixt on the sixteenth . So . Some of them will have to cut back their hours at that point . Yeah . Are they working full - time now , or {disfmarker} ? But {disfmarker} {nonvocalsound} {vocalsound} Some of them are . Wow . Yeah . Well , why do I wouldn't say forty - hour weeks . No . But what I mean is {disfmarker} Oh , I shouldn't say it that way because {nonvocalsound} that does sound like forty - hour weeks . No . I th I {disfmarker} I would say they 're probably {nonvocalsound} {disfmarker} they don't have o they don't have other things that are taking away their time . I don't see how someone could do forty hours a week on transcription . Hmm . But {nonvocalsound} it 's {disfmarker} you can't . Yeah . Yeah . No . You 're right . It 's {disfmarker} i it would be too taxing . But , um , they 're putting {nonvocalsound} in a lot of {disfmarker} Yeah . And {disfmarker} and I checked them over . I {disfmarker} I {disfmarker} I {disfmarker} I haven't checked them all , but {pause} just spot - checking . They 're fantastic . I think it would be {disfmarker} I remember when we were transcribing BeRP , uh , uh , {vocalsound} uh , Ron Kay , uh , volunteered to {disfmarker} to do some of that . And , he was {disfmarker} the first {disfmarker} first stuff he did was transcribing Chuck . And he 's saying \" You {disfmarker} you know , I always thought Chuck spoke really well . \" Yeah . Yeah . Well , you know , and I also thought , y Liz has this , eh , you know , and I do also , this {disfmarker} this interest in the types of overlaps that are involved . These people would be {nonvocalsound} great choices for doing coding of that type if we wanted , We 'd have to mark them . or whatever . So , um . Mm - hmm . Mm - hmm . I think it would also be interesting to have , uh , a couple of the meetings have more than one transcriber do , Yeah . cuz I 'm curious about inter - annotator agreement . Mm - hmm . Yeah . OK . Yeah . Th - that 'd be {disfmarker} I think that 's a {disfmarker} a good idea . Yeah . You know , there 's also , the e In my mind , I think A An - Andreas was {pause} leading to this topic , the idea that , um , {vocalsound} we haven't yet seen the {disfmarker} the type of transcript that we get from IBM , and it may just be , you know , pristine . But on the other hand , given the lesser interface {disfmarker} Cuz this is , you know {disfmarker} we 've got a good interface , we 've got great headphones , m um {disfmarker} It could be that they will uh {disfmarker} theirs will end up being a kind of fir first pass or something . Something like that . Maybe an elaborate one , cuz again they probably are gonna do these alignments , which will also clear things up . That 's {disfmarker} that 's true . Al - although you have to s Don't you have to start with a close enough approximation {nonvocalsound} of the {disfmarker} of the verbal part {nonvocalsound} to be able to {disfmarker} ? Well , tha that 's {disfmarker} that 's debatable . OK . Right ? I mean , so the {disfmarker} so the argument is that if your statistical system is good {vocalsound} it will in fact , uh , clean things up . OK . Right ? So it it 's got its own objective criterion . Yeah . And , uh , so in principle you could start up with something that was kind of rough {disfmarker} I mean , to give an example of , um , something we used to do , uh , at one point , uh , back {disfmarker} back when Chuck was here in early times , is we would take , um , {vocalsound} da take a word and , uh , have a canonical pronunciation and , uh , if there was five phones in a word , {vocalsound} you 'd break up the word , {vocalsound} uh , into five equal - length pieces which is completely gross . Wrong . Yeah . Right ? I mean , th the timing is off {pause} all over the place in just about any word . Mm - hmm . OK . But it 's O K . You start off with that and the statistical system then aligns things , and eventually you get something that doesn't really look too bad . Oh , excellent . OK . So {disfmarker} so I think using a {disfmarker} a good {pause} aligner , um , actually can {disfmarker} can help a lot . Um . {vocalsound} But , uh , you know , they both help each other . If you have a {disfmarker} if you have a better starting point , then it helps the aligner . If you have a good alignment , it helps the , uh , th the human in {disfmarker} in taking less time to correct things . OK . So {disfmarker} so {disfmarker} Excellent . I guess there 's another aspect , too , and I don't know {disfmarker} uh , this {disfmarker} this is {disfmarker} very possibly a different , uh , topic . But , {nonvocalsound} uh , just let me say {pause} with reference to this idea of , um , {vocalsound} higher - order organization within meetings . So like in a {disfmarker} you know , the topics that are covered during a meeting with reference to the other , uh , uses of the data , Mm - hmm . so being able to {pause} find where so - and - so talked about such - and - such , then , um , um {disfmarker} e I mean , I {disfmarker} I {disfmarker} I did sort of a {disfmarker} {vocalsound} a rough {pause} pass {nonvocalsound} on encoding , like , episode - like level things on the , uh , transcribed meeting {disfmarker} Mm - hmm . already transcribed meeting . And I don't know if , um {disfmarker} Mm - hmm . where {nonvocalsound} that {disfmarker} i if that 's something that we wanna do with each meeting , sort of like a , um {disfmarker} it 's like a manifest , when you get a box full of stuff , or {disfmarker} or if that 's , um {disfmarker} Mm - hmm . I mean , i I {disfmarker} I don't know what uh , level of detail would be most useful . I don't know i if that 's something that {pause} I should do when I look over it , or if we want someone else to do , or whatever . Mm - hmm . But this issue of the contents of the meeting in an outline form . OK . Yeah . Meaning really isn't my thing . Um {disfmarker} I think it just {disfmarker} whoever is interested can do that . I mean , so if someone wants to use that data {disfmarker} OK . We 're running a little short here . That 's fine . We , uh , uh , cou trying to {disfmarker} I 'm finished . eh , was {disfmarker} p Well , you know , the thing I 'm concerned about is we wanted to do these digits Oh , yeah . and {disfmarker} and I haven't heard , uh , from Jose yet . Oh , yes . OK . What do you want ? Mm - hmm . So {disfmarker} We could skip the digits . Uh {disfmarker} We don't have to read digits each time . Uh {disfmarker} I {disfmarker} I {disfmarker} I think it {disfmarker} you know , another {disfmarker} another bunch of digits . More data is good . OK . Yeah . Sure . So {disfmarker} so I 'd like to do that . But I think , do you , maybe , eh {disfmarker} ? Did you prepare some whole thing you wanted us just to see ? Yeah . It 's {disfmarker} it 's prepared . Or what was that ? Yeah . Oh , k Sorry . Uh , how long a {disfmarker} ? I {disfmarker} I think it 's {disfmarker} it 's fast , because , uh , I have the results , eh , of the study of different energy without the law length . Eh , um , eh , in the {disfmarker} in the measurement , uh , the average , uh , dividing by the {disfmarker} by the , um , variance . Um , I {disfmarker} th i Yeah . the other , uh {disfmarker} the {disfmarker} the last w uh , meeting {disfmarker} eh , I don't know if you remain we have problem to {disfmarker} with the {disfmarker} {vocalsound} with {disfmarker} with the parameter {disfmarker} with the representations of parameter , because the {disfmarker} the valleys and the peaks in the signal , eh , look like , eh , it doesn't follow to the {disfmarker} to the energy in the signal . Yes . Right . And it was a problem , uh , with the scale . With what ? Eh , the scale . Scale . Scale . Eh , and I {disfmarker} I change the scale and we can see the {disfmarker} the variance . OK . But the bottom line is it 's still not , uh , separating out very well . Yeah . Yeah . Right ? The distribution {disfmarker} the distribution is {disfmarker} is similar . OK . So that 's {disfmarker} that 's {disfmarker} that 's enough then . OK . Yeah . No , I mean , that there 's no point in going through all of that if that 's the bottom line , really . Yeah . Mm - hmm . Yeah . So , I {disfmarker} I think we have to start {disfmarker} Uh , I mean , there there 's two suggestions , really , which is , uh {disfmarker} what we said before is that , Mmm , yeah . um , it looks like , at least that you haven't found an obvious way to normalize so that the energy is anything like a reliable , uh , indicator of the overlap . Yeah . Yeah . Um , I {disfmarker} I 'm {disfmarker} I 'm still {pause} a little f think that 's a little funny . These things l @ @ seems like there should be , Yeah . but {disfmarker} {vocalsound} but you don't want to keep , uh {disfmarker} keep knocking at it if it 's {disfmarker} if you 're not getting any {disfmarker} any result with that . But , I mean , the other things that we talked about is , uh , {vocalsound} pitch - related things and harmonicity - related things , Yeah . so {disfmarker} which we thought also should be some kind of a reasonable indicator . Um {disfmarker} But , uh , a completely different tack on it wou is the one that was suggested , uh , by your colleagues in Spain , Yeah . which is to say , don't worry so much about the , uh , features . Yeah . That is to say , use , you know , as {disfmarker} as you 're doing with the speech , uh , nonspeech , use some very general features . Yeah . Yeah . And , uh , then , uh , look at it more from the aspect of modeling . Yeah . You know , have a {disfmarker} have a couple Markov models and {disfmarker} and , uh , try to indi try to determine , you know , w when is th when are you in an overlap , when are you not in an overlap . Hmm . And let the , uh , uh , statistical system {pause} determine what 's the right way to look at the data . Yeah . I {disfmarker} I , um , I think it would be interesting to find individual features and put them together . I think that you 'd end up with a better system overall . Yeah . But given the limitation in time {vocalsound} and given the fact that Javier 's system already exists {pause} doing this sort of thing , Yeah . uh , but , uh , its main limitation is that , again , it 's only looking at silences which would {disfmarker} Yeah . Yeah . maybe that 's a better place to go . Yeah . Mm - hmm . So . I {disfmarker} I {disfmarker} I think that , eh , the possibility , eh , can be that , eh , Thilo , eh , working , eh , with a new class , not only , eh , nonspeech and speech , but , eh , in {disfmarker} in {disfmarker} in the speech class , Mm - hmm . Mm - hmm . dividing , eh , speech , eh , of {disfmarker} from a speaker and overlapping , to try {disfmarker} to {disfmarker} to do , eh , eh , a fast {disfmarker} a fast , eh , {vocalsound} experiment to {disfmarker} to prove that , nnn , this fea eh , general feature , {vocalsound} eh , can solve the {disfmarker} the {disfmarker} the problem , Yeah . and wh what {disfmarker} nnn , how far is {disfmarker} Maybe . Yeah . And , I {disfmarker} I have prepared the {disfmarker} the pitch tracker now . Mm - hmm . And I hope the {disfmarker} the next week I will have , eh , some results and we {disfmarker} we will show {disfmarker} we will see , eh , the {disfmarker} the parameter {disfmarker} the pitch , {vocalsound} eh , tracking in {disfmarker} with the program . I see . And , nnn , nnn {disfmarker} Ha - h have you ever looked at the , uh , uh {disfmarker} Javier 's , uh , speech segmenter ? No . No . No . Oh . Maybe m you could , you kn uh show Thilo that . Yeah . Yeah . Sure . Yeah . Cuz again the idea is there {disfmarker} the limitation there again was that he was {disfmarker} he was only using it to look at silence as a {disfmarker} as a {disfmarker} as a {disfmarker} as a p putative split point between speakers . Yeah . But if you included , uh , broadened classes then {pause} in principle maybe you can {pause} cover the overlap cases . OK . Yeah . Yeah , but I 'm not too sure if {disfmarker} if we can {pause} really represent {vocalsound} overlap with {disfmarker} with the s {pause} detector I {disfmarker} I {disfmarker} I used up to now , Mmm , yeah . Uh {disfmarker} Mm - hmm . I think with {disfmarker} the {disfmarker} to speech - nonspeech as {disfmarker} That 's right . But I think Javier 's {disfmarker} it 's only speech or it 's {disfmarker} it 's {disfmarker} it 's nonspeech . Ah . Yeah . Mm - hmm . I think Javier 's might be able to . So . N n It doesn't have the same Gaus - uh , H M M modeling , Yeah . which is I think a drawback . OK . But , uh {disfmarker} Well , it 's {disfmarker} sort of has a simple one . Mmm , yeah . Does it ? Right ? It 's {disfmarker} it 's just {disfmarker} it 's just a {disfmarker} isn't it just a Gaussian Yeah . for each {disfmarker} ? Yeah . And then {pause} he ch you choose optimal splitting . Hmm . Mm - hmm . Yeah . Oh , it doesn't have {disfmarker} it doesn't have any temporal , uh {disfmarker} ? Maybe I 'm misremembering , but I did not think it had a Markov {disfmarker} I thought it {disfmarker} Yeah . I gues I guess I don't remember either . Uh . It 's been a while . Yeah . Uh , I could have a look at it . Javier {disfmarker} Uh . So . You mean Ja - eh , eh , Javier program ? Mm - hmm . No , Javier di doesn't worked with , uh , a Markov {disfmarker} Yeah , I didn't think so . He on only train {disfmarker} Oh , OK . So he 's just {disfmarker} he just computes a Gaussian over potential {disfmarker} Yep . Yeah . It was only Gaussian . Oh , I see . I see . And so I {disfmarker} I think it would work fine for detecting overlap . This is the idea . And {disfmarker} and {disfmarker} It 's just , uh , that i it {disfmarker} he has the two - pass issue that {disfmarker} What he does is , as a first pass he {disfmarker} he {disfmarker} p he does , um , a guess at where the divisions might be and he overestimates . And that 's just a data reduction step , so that you 're not trying at every time interval . OK . And so those are the putative {pause} places where he tries . Yeah . Yeah . OK . And right now he 's doing that with silence and that doesn't work with the Meeting Recorder . So if we used another method to get the first pass , I think it would probably work . Yeah . Yeah . Sure . Yeah . Yeah , OK . It 's a good method . As long as the len as long the segments are long enough . Yeah . That 's the other problem . So {disfmarker} O - k OK . So let me go back to what you had , though . Yeah . Um . Mm - hmm . The other thing one could do is {disfmarker} Couldn't {disfmarker} I mean , it 's {disfmarker} So you have two categories Yeah . and you have Markov models for each . Couldn't you have a third category ? So you have , uh {disfmarker} you have , {vocalsound} uh , nonspeech , single - person speech , and multiple - person speech ? He has this on his board actually . Don't you have , like those {disfmarker} those several different {vocalsound} categories on the board ? Right ? And then you have a Markov model for each ? Um {disfmarker} I 'm not sure . I {disfmarker} I thought about , uh , adding , uh , uh , another class too . But it 's not too easy , I think , the {disfmarker} the transition between the different class , to model them in {disfmarker} in the system I have now . But it {disfmarker} it {disfmarker} it could be possible , I think , I see . I see . in principle . Yeah , I mean , I {disfmarker} This is all pretty gross . Yeah . I mean , the {disfmarker} th the reason why , uh , I was suggesting originally that we look at features is because I thought , well , we 're doing something we haven't done before , Yeah . we should at least look at the space and understand {disfmarker} Yeah . Yeah . It seems like if two people {disfmarker} two or more people talk at once , it should get louder , Yeah . uh , and , uh , uh , there should be some discontinuity in pitch contours , I had the impression . Yeah . Yeah . and , uh , there should overall be a , um , smaller proportion of the total energy that is explained by any particular harmonic {pause} sequence in the spectrum . Right . Yeah . So those are all things that should be there . Yeah . Mm - hmm . So far , um , uh , Jose has {disfmarker} has been {disfmarker} By the way , I was told I should be calling you Pepe , but {disfmarker} Yeah . by your friends , but Anyway , Yeah . um , uh , the {disfmarker} has {disfmarker} has , uh , been exploring , uh , e largely the energy issue and , um , as with a lot of things , it is not {disfmarker} uh , like this , it 's not as simple as it sounds . Yeah . And then there 's , you know {disfmarker} Is it energy ? Is it log energy ? Is it LPC residual energy ? Is it {disfmarker} is it {disfmarker} {vocalsound} is it , uh , delta of those things ? Uh , what is it no Obviously , just a simple number {disfmarker} {vocalsound} absolute number isn't gonna work . So {vocalsound} it should be with {disfmarker} compared to what ? Should there be a long window for the {vocalsound} normalizing factor and a short window for what you 're looking at ? Yeah . Or , you know , how b short should they be ? So , Hmm . th he 's been playing around with a lot of these different things and {disfmarker} and so far at least has not come up with {vocalsound} any combination that really gave you an indicator . Yeah . So I {disfmarker} I still have a hunch that there 's {disfmarker} it 's in there some place , but it may be {disfmarker} given that you have a limited time here , it {disfmarker} it just may not be the best thing to {disfmarker} {vocalsound} to {disfmarker} to focus on for the remaining of it . Yeah . To overrule , yeah . So pitch - related and harmonic - related , I 'm {disfmarker} I 'm {pause} somewhat more hopeful for it . Yeah . Yeah . But it seems like if we just wanna get something to work , Yeah . Yeah . that , uh , their suggestion of {disfmarker} of {disfmarker} Th - they were suggesting going to Markov models , uh , but in addition there 's an expansion of what Javier did . And one of those things , looking at the statistical component , One . Yeah . even if the features that you give it are maybe not ideal for it , it 's just sort of this general filter bank Yeah . or {disfmarker} {vocalsound} or cepstrum or something , um {disfmarker} Eee {vocalsound} it 's in there somewhere probably . But , eh , what did you think about the possibility of using the Javier software ? Eh , I mean , the , uh {disfmarker} the , uh {disfmarker} the BIC criterion , the {disfmarker} the {disfmarker} t to train the {disfmarker} the Gaussian , eh , using the {disfmarker} the mark , eh , by hand , eh , eh , to distinguish be mmm , to train overlapping zone and speech zone . I mean , eh , {vocalsound} I {disfmarker} I {disfmarker} I think that an interesting , eh , experiment , eh , could be , th eh , to prove that , mmm , if s we suppose that , eh , the {disfmarker} the first step {disfmarker} {vocalsound} I mean , the {disfmarker} the classifier what were the classifier from Javier or classifier from Thilo ? W What happen with the second step ? I {disfmarker} I mean , what {disfmarker} what happen with the , eh {disfmarker} the , uh , clu the , uh {disfmarker} the clu the clustering process ? Mm - hmm . Using the {disfmarker} the Gaussian . You mean Javier 's ? Yeah . What do you mean ? I {disfmarker} I mean , that is {disfmarker} is enough {disfmarker} is enough , eh , to work well , eh , to , eh , separate or to distinguish , eh , between overlapping zone and , eh , speaker zone ? Because th {vocalsound} if {disfmarker} if we {disfmarker} if we , eh , nnn , develop an classifier {disfmarker} and the second step doesn't work {pause} well , eh , we have {pause} another problem . I {disfmarker} Yeah . I had tried doing it by hand at one point with a very short sample , N and it worked pretty well , but I haven't worked with it a lot . So what I d I d I took a hand - segmented sample Nnn , yeah . and I added ten times the amount of numbers at random , Yeah . and it did pick out pretty good boundaries . Oh . Yeah . But is {disfmarker} is {disfmarker} if {disfmarker} But this was just very anecdotal sort of thing . But it 's possible with my segmentation by hand {pause} that we have information about the {disfmarker} the overlapping , Right . So if we {disfmarker} if we fed the hand - segmentation to Javier 's and it doesn't work , then we know something 's wrong . uh {disfmarker} Yeah . The {disfmarker} N n Yeah . No . The demonstration by hand . Segmentation by hand I {disfmarker} I {disfmarker} I think is the fast experiment . Yeah . I think that 's probably worthwhile doing . Uh , we can prove that the {disfmarker} Uh - huh . Whether it 'll work or not . this kind o emph emphasises parameter and Gaussian {disfmarker} Yeah . Yeah . Yep . Y do you know where his software is ? Have you used it at all ? I yeah have . I have . OK .  So . I {disfmarker} I have as well , so if you need {disfmarker} need help let me know . OK . Let 's read some digits . OK . uuh Mm - hmm . And we are {disfmarker}",
        "summarize": null
    }
]