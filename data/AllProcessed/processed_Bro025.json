[
    {
        "transcript": "Alright . We 're on . Test , um . Test , test , test . Guess that 's me . Yeah . OK . Ooh , Thursday . So . There 's two sheets of paper in front of us . What are these ? Yeah . So . This is the arm wrestling ? Uh . Yeah , we formed a coalition actually . Yeah . Almost . We already made it into one . Oh , good . Yeah . Excellent . Yeah . That 's the best thing . Mm - hmm . So , tell me about it . So it 's {disfmarker} well , it 's {pause} spectral subtraction or Wiener filtering , um , depending on if we put {disfmarker} if we square the transfer function or not . Right . And then with over - estimation of the noise , depending on the , uh {disfmarker} the SNR , with smoothing along time , um , smoothing along frequency . Mm - hmm . It 's very simple , smoothing things . Mm - hmm . And , um , {vocalsound} the best result is {vocalsound} when we apply this procedure on FFT bins , uh , with a Wiener filter . Mm - hmm . And there is no noise addition after {disfmarker} after that . OK . So it 's good because {vocalsound} {vocalsound} it 's difficult when we have to add noise to {disfmarker} to {disfmarker} to find the right level . OK . Are you looking at one in {disfmarker} in particular of these two ? Yeah . So the sh it 's the sheet that gives fifty - f three point sixty - six . Mm - hmm . Um , {vocalsound} the second sheet is abo uh , about the same . It 's the same , um , idea but it 's working on mel bands , {vocalsound} and it 's a spectral subtraction instead of Wiener filter , and there is also a noise addition after , uh , cleaning up the mel bins . Mmm . Well , the results are similar . Yeah . I mean , {vocalsound} it 's {disfmarker} {comment} it 's actually , uh , very similar . Mm - hmm . I mean , {vocalsound} if you look at databases , uh , the , uh , one that has the smallest {disfmarker} smaller overall number is actually better on the Finnish and Spanish , uh , but it is , uh , worse on the , uh , Aurora {disfmarker} It 's worse on {disfmarker} I mean on the , uh , TI - TI - digits , on the multi - condition in TI - digits . Yeah . uh , uh . Um . Mmm . So , it probably doesn't matter that much either way . But , um , when you say u uh , unified do you mean , uh , it 's one piece of software now , or {disfmarker} ? So now we are , yeah , setting up the software . Mm - hmm . Um , it should be ready , uh , very soon . Um , and we So what 's {disfmarker} what 's happened ? I think I 've missed something . OK . So a week ago {disfmarker} maybe you weren't around when {disfmarker} when {disfmarker} when Hynek and Guenther and I {disfmarker} ? Hynek was here . Yeah . I didn't . Oh , OK . So {disfmarker} Yeah , let 's summarize . Um {disfmarker} And then if I summarize somebody can tell me if I 'm wrong , which will also be possibly helpful . What did I just press here ? I hope this is still working . p - p - p We , uh {disfmarker} we looked at , {nonvocalsound} uh {disfmarker} anyway we {disfmarker} {vocalsound} after coming back from QualComm we had , you know , very strong feedback and , uh , I think it was {vocalsound} Hynek and Guenter 's and my opinion also that , um , you know , we sort of spread out to look at a number of different ways of doing noise suppression . But given the limited time , uh , it was sort of time to {pause} choose one . Mm - hmm . Mmm . Uh , and so , uh , th the vector Taylor series hadn't really worked out that much . Uh , the subspace stuff , uh , had not been worked with so much . Um , so it sort of came down to spectral subtraction versus Wiener filtering . Hmm . Uh , we had a long discussion about how they were the same and how they were d uh , completely different . Mm - hmm . And , uh , I mean , fundamentally they 're the same sort of thing but the math is a little different so that there 's a {disfmarker} a {disfmarker} {vocalsound} there 's an exponent difference in the index {disfmarker} you know , what 's the ideal filtering , and depending on how you construct the problem . Uh - huh . And , uh , I guess it 's sort {disfmarker} you know , after {disfmarker} after that meeting it sort of made more sense to me because {vocalsound} um , if you 're dealing with power spectra then how are you gonna choose your error ? And typically you 'll do {disfmarker} choose something like a variance . And so that means it 'll be something like the square of the power spectra . Whereas when you 're {disfmarker} when you 're doing the {disfmarker} the , uh , um , {vocalsound} looking at it the other way , you 're gonna be dealing with signals Mm - hmm . and you 're gonna end up looking at power {disfmarker} uh , noise power that you 're trying to reduce . And so , eh {disfmarker} so there should be a difference {vocalsound} of {disfmarker} you know , conceptually of {disfmarker} of , uh , a factor of two in the exponent . Mm - hmm . But there 're so many different little factors that you adjust in terms of {disfmarker} of , uh , {vocalsound} uh , over - subtraction and {disfmarker} and {disfmarker} and {disfmarker} and {disfmarker} and so forth , um , that {vocalsound} arguably , you 're c and {disfmarker} and {disfmarker} and the choice of do you {disfmarker} do you operate on the mel bands or do you operate on the FFT beforehand . There 're so many other choices to make that are {disfmarker} are almost {disfmarker} well , if not independent , certainly in addition to {pause} the choice of whether you , uh , do spectral subtraction or Wiener filtering , that , um , {vocalsound} @ @ again we sort of felt the gang should just sort of figure out which it is they wanna do and then let 's pick it , go forward with it . So that 's {disfmarker} that was {disfmarker} that was last week . And {disfmarker} {vocalsound} and , uh , we said , uh , take a week , go arm wrestle , you know , Oh . figure it out . I mean , and th the joke there was that each of them had specialized in one of them . Oh , OK . And {disfmarker} and so they {disfmarker} so instead they went to Yosemite and bonded , and {disfmarker} and they came out with a single {disfmarker} single piece of software . So it 's {vocalsound} another {disfmarker} another victory for international collaboration . So . So {disfmarker} so you guys have combined {disfmarker} or you 're going to be combining the software ? Uh . Well , the piece of software has , like , plenty of options , Oh boy . like you can parse command - line arguments . So depending on that , it {disfmarker} it becomes either spectral subtraction or Wiener filtering . Oh , OK . So , ye They 're close enough . Well , that 's fine , but the thing is {disfmarker} the important thing is that there is a piece of software that you {disfmarker} that we all will be using now . Yeah . Yeah . Yes . There 's just one piece of software . Yeah . Yeah . I need to allow it to do everything and even more {disfmarker} more than this . Right . Well , if we want to , like , optimize different parameters of {disfmarker} Parameters . Yeah . Sure . Yeah , we can do it later . But , still {disfmarker} so , there will be a piece of software with , {vocalsound} {vocalsound} uh , will give this system , the fifty - three point sixty - six , by default and {disfmarker} Mm - hmm . How {disfmarker} how is {disfmarker} how good is that ? Mm - hmm . I {disfmarker} I {disfmarker} I don't have a sense of {disfmarker} It 's just one percent off of the {pause} best proposal . Best system . It 's between {disfmarker} i we are second actually if we take this system . OK . Yeah . Yeah . Right ? Compared to the last evaluation numbers ? Yeah . But , uh {disfmarker} w which we sort of were before Yeah . Mm - hmm . Yeah . but we were considerably far behind . And the thing is , this doesn't have neural net in yet for instance . You know ? Mm - hmm . Hmm . So it {disfmarker} so , um , it 's {disfmarker} it it 's not using our full bal bag of tricks , if you will . Mm - hmm . And , uh , and it {disfmarker} it is , uh , very close in performance to the best thing that was there before . Uh , but , you know , looking at it another way , maybe more importantly , uh , {vocalsound} we didn't have any explicit noise , uh , handling {disfmarker} stationary {disfmarker} dealing with {disfmarker} e e we didn't explicitly have anything to deal with stationary noise . Mm - hmm . And now we do . So will the {pause} neural net operate on the output from either the Wiener filtering or the spectral subtraction ? Or will it operate on the original ? Well , so {disfmarker} so {disfmarker} so argu arguably , I mean , what we should do {disfmarker} I mean , I gather you have {disfmarker} it sounds like you have a few more days of {disfmarker} of nailing things down with the software and so on . But {disfmarker} and then {disfmarker} but , um , {vocalsound} arguably what we should do is , even though the software can do many things , we should for now pick a set of things , th these things I would guess , and not change that . Mm - hmm . And then focus on {pause} everything that 's left . And I think , you know , that our goal should be by next week , when Hynek comes back , {vocalsound} uh , to {disfmarker} uh , really just to have a firm path , uh , for the {disfmarker} you know , for the time he 's gone , of {disfmarker} of , uh , what things will be attacked . But I would {disfmarker} I would {disfmarker} I would thought think that what we would wanna do is not futz with this stuff for a while because what 'll happen is we 'll change many other things in the system , Mm - hmm . and then we 'll probably wanna come back to this and possibly make some other choices . But , um . But just conceptually , where does the neural net go ? Do {disfmarker} do you wanna h run it on the output of the spectrally subtracted {disfmarker} ? Mmm . Well , depending on its size {disfmarker} Well , one question is , is it on the , um , server side or is it on the terminal side ? Uh , if it 's on the server side , it {disfmarker} you probably don't have to worry too much about size . Mm - hmm . So that 's kind of an argument for that . We do still , however , have to consider its latency . So the issue is {disfmarker} is , um , {vocalsound} for instance , could we have a neural net that only looked at the past ? Right . Um , what we 've done in uh {disfmarker} in the past is to use the neural net , uh , to transform , {vocalsound} um , all of the features that we use . So this is done early on . This is essentially , {vocalsound} um , um {disfmarker} I guess it 's {disfmarker} it 's more or less like a spee a speech enhancement technique here {disfmarker} Mm - hmm . right ? {disfmarker} where we 're just kind of creating {vocalsound} new {disfmarker} if not new speech at least new {disfmarker} new FFT 's that {disfmarker} that have {disfmarker} you know , which could be turned into speech {disfmarker} uh , that {disfmarker} that have some of the noise removed . Mm - hmm . Mm - hmm . Um , after that we still do a mess of other things to {disfmarker} to produce a bunch of features . Right . And then those features are not now currently transformed {vocalsound} by the neural net . And then the {disfmarker} the way that we had it in our proposal - two before , we had the neural net transformed features and we had {vocalsound} the untransformed features , which I guess you {disfmarker} you actually did linearly transform with the KLT , Yeah . Yeah . Right . but {disfmarker} but {disfmarker} but {disfmarker} uh , to orthogonalize them {disfmarker} but {disfmarker} {vocalsound} but they were not , uh , processed through a neural net . And Stephane 's idea with that , as I recall , was that {vocalsound} you 'd have one part of the feature vector that was very discriminant and another part that wasn't , Mm - hmm . uh , which would smooth things a bit for those occasions when , uh , the testing set was quite different than what you 'd trained your discriminant features for . So , um , all of that is {disfmarker} is , uh {disfmarker} still seems like a good idea . The thing is now we know some other constraints . We can't have unlimited amounts of latency . Uh , y you know , that 's still being debated by the {disfmarker} by people in Europe but , {vocalsound} uh , no matter how they end up there , it 's not going to be unlimited amounts , Yeah . so we have to be a little conscious of that . Um . So there 's the neural net issue . There 's the VAD issue . And , uh , there 's the second stream {pause} thing . And I think those that we {disfmarker} last time we agreed that those are the three things that have to get , uh , focused on . What was the issue with the VAD ? Well , better {comment} ones are good . And so the w the default , uh , boundaries that they provide are {disfmarker} they 're OK , but they 're not all that great ? I guess they still allow two hundred milliseconds on either side or some ? Is that what the deal is ? Mm - hmm . Uh , so th um , they keep two hundred milliseconds at the beginning and end of speech . And they keep all the {disfmarker} Outside the beginnings and end . Yeah . Uh - huh . And all the speech pauses , which is {disfmarker} Sometimes on the SpeechDat - Car you have pauses that are more than one or two seconds . Wow . More than one second for sure . Um . Hmm . Yeah . And , yeah , it seems to us that this way of just dropping the beginning and end is not {disfmarker} We cou we can do better , I think , Mm - hmm . because , um , {vocalsound} with this way of dropping the frames they improve {pause} over the baseline by fourteen percent and {vocalsound} Sunil already showed that with our current VAD we can improve by more than twenty percent . On top of the VAD that they provide ? No . Just using either their VAD or our current VAD . Our way . Oh , OK . So , our current VAD is {disfmarker} is more than twenty percent , while their is fourteen . Theirs is fourteen ? I see . Yeah . Huh . So . Yeah . And {pause} another thing that we did also is that we have all this training data for {disfmarker} let 's say , for SpeechDat - Car . We have channel zero which is clean , channel one which is far - field microphone . And if we just take only the , um , VAD probabilities computed on the clean signal and apply them on the far - field , uh , test utterances , {vocalsound} then results are much better . Mm - hmm . In some cases it divides the error rate by two . Wow . So it means that there are stim {comment} still {disfmarker} How {disfmarker} how much latency does the , uh {disfmarker} does our VAD add ? If {disfmarker} if we can have a good VAD , well , it would be great . Is it significant , Uh , right now it 's , um , a neural net with nine frames . or {disfmarker} ? So it 's forty milliseconds plus , um , the rank ordering , which , uh , should be Like another ten frames . ten {disfmarker} Yeah . Rank . Oh . So , right now it 's one hundred and forty {pause} milliseconds . With the rank ordering {disfmarker} ? I 'm sorry . The {disfmarker} the {disfmarker} the smoothing {disfmarker} the m the {disfmarker} the filtering of the probabilities . The {disfmarker} The , um {disfmarker} on the R . Yeah . It 's not a median filtering . It 's just {disfmarker} We don't take the median value . We take something {disfmarker} Um , so we have eleven , um , frames . Oh , this is for the VAD . Yeah . And {disfmarker} for the VAD , yeah {disfmarker} Oh , OK . Yeah . and we take th the third . Yeah . Dar Um . Yeah . Um . So {disfmarker} {comment} Yeah , I was just noticing on this that it makes reference to delay . Mmm . So what 's the {disfmarker} ? If you ignore {disfmarker} Um , the VAD is sort of in {disfmarker} in parallel , isn't i isn't it , with {disfmarker} with the {disfmarker} ? I mean , it isn't additive with the {disfmarker} the , uh , LDA and the Wiener filtering , and so forth . The LDA ? Right ? Yeah . So {disfmarker} so what happened right now , we removed the delay of the LDA . Mm - hmm . Yeah . So we {disfmarker} I mean , if {disfmarker} so if we {disfmarker} if {disfmarker} so which is like if we reduce the delay of VA So , the f the final delay 's now ba is f determined by the delay of the VAD , because the LDA doesn't have any delay . So if we re if we reduce the delay of the VAD , I mean , it 's like effectively reducing the delay . How {disfmarker} how much , uh , delay was there on the LDA ? So the LDA and the VAD both had a hundred millisecond delay . So and they were in parallel , so which means you pick either one of them {disfmarker} Mmm . the {disfmarker} the biggest , whatever . I see . Mm - hmm . So , right now the LDA delays are more . And there {disfmarker} Oh , OK . And there didn't seem to be any , uh , penalty for that ? There didn't seem to be any penalty for making it causal ? Pardon ? Oh , no . It actually made it , like , point one percent better or something , actually . OK . Well , may as well , then . Or something like that And he says Wiener filter is {disfmarker} is forty milliseconds delay . and {disfmarker} So is it {disfmarker} ? Yeah . So that 's the one which Stephane was discussing , like {disfmarker} Mmm . The smoothing ? Yeah . The {disfmarker} you smooth it and then delay the decision by {disfmarker} So . Right . OK . So that 's {disfmarker} that 's really not {disfmarker} not bad . So we may in fact {disfmarker} we 'll see what they decide . We may in fact have , {vocalsound} um , the {disfmarker} the , uh , latency time available for {disfmarker} to have a neural net . I mean , sounds like we probably will . So . Mm - hmm . That 'd be good . Cuz I {disfmarker} cuz it certainly always helped us before . So . What amount of latency are you thinking about when you say that ? Uh . Well , they 're {disfmarker} you know , they 're disputing it . Mmm . You know , they 're saying , uh {disfmarker} one group is saying a hundred and thirty milliseconds and another group is saying two hundred and fifty milliseconds . Two hundred and fifty is what it was before actually . So , Oh . uh , some people are lobbying {disfmarker} lobbying {comment} to make it shorter . Hmm . Um . And , um . Were you thinking of the two - fifty or the one - thirty when you said we should {pause} have enough for the neural net ? Well , it just {disfmarker} it {disfmarker} when we find that out it might change exactly how we do it , is all . Oh , OK . I mean , how much effort do we put into making it causal ? I mean , {vocalsound} I think the neural net will probably do better if it looks at a little bit of the future . Mm - hmm . But , um , it will probably work to some extent to look only at the past . And we ha you know , limited machine and human time , and {vocalsound} effort . And , you know , how {disfmarker} how much time should we put into {disfmarker} into that ? So it 'd be helpful if we find out from the {disfmarker} the standards folks whether , you know , they 're gonna restrict that or not . Mm - hmm . Um . But I think , you know , at this point our major concern is making the performance better and {disfmarker} and , um , {vocalsound} if , uh , something has to take a little longer in latency in order to do it that 's {pause} you know , a secondary issue . Mm - hmm . But if we get told otherwise then , you know , we may have to c clamp down a bit more . Mmm . So , the one {disfmarker} one {disfmarker} one difference is that {disfmarker} was there is like we tried computing the delta and then doing the frame - dropping . S Mm - hmm . The earlier system was do the frame - dropping and then compute the delta on the {disfmarker} Uh - huh . So this {disfmarker} Which could be a kind of a funny delta . Right ? Yeah . Oh , oh . So that 's fixed in this . Yeah , we talked about that . Yeah . So we have no delta . And then {disfmarker} Yeah . Uh - huh . Good . So the frame - dropping is the last thing that we do . So , yeah , what we do is we compute the silence probability , convert it to that binary flag , Uh - huh . and then in the end you c up upsample it to {vocalsound} match the final features number of {disfmarker} Mm - hmm . Did that help then ? It seems to be helping on the well - matched condition . So that 's why this improvement I got from the last result . So . And it actually r reduced a little bit on the high mismatch , so in the final weightage it 's b b better because the well - matched is still weighted more than {disfmarker} So , @ @ I mean , you were doing a lot of changes . Did you happen to notice how much , {vocalsound} uh , the change was due to just this frame - dropping problem ? What about this ? Uh , y you had something on it . Right ? Just the frame - dropping problem . Yeah . But it 's {disfmarker} it 's difficult . Sometime we {disfmarker} we change two {disfmarker} two things together and {disfmarker} But it 's around {pause} maybe {disfmarker} it 's less than one percent . Uh - huh . Yeah . It {disfmarker} Well . {vocalsound} But like we 're saying , if there 's four or five things like that then {vocalsound} pretty sho soon you 're talking real improvement . Yeah . Yeah . And it {disfmarker} Yeah . And then we have to be careful with that also {disfmarker} with the neural net Yeah . because in {comment} the proposal the neural net was also , uh , working on {disfmarker} after frame - dropping . Mm - hmm . Um . Oh , that 's a real good point . So . Well , we 'll have to be {disfmarker} to do the same kind of correction . It might be hard if it 's at the server side . Right ? Mmm . Well , we can do the frame - dropping on the server side or we can just be careful at the terminal side to send a couple of more frames before and after , and {disfmarker} So . I think it 's OK . OK . You have , um {disfmarker} So when you {disfmarker} Uh , maybe I don't quite understand how this works , but , um , couldn't you just send all of the frames , but mark the ones that are supposed to be dropped ? Cuz you have a bunch more bandwidth . Right ? Well , you could . Yeah . I mean , it {disfmarker} it always seemed to us that it would be kind of nice to {disfmarker} in addition to , uh , reducing insertions , actually use up less bandwidth . Yeah . Yeah . But nobody seems to have {vocalsound} cared about that in this {pause} evaluation . And that way the net could use {disfmarker} So . If the net 's on the server side then it could use all of the {pause} frames . Yes , it could be . It 's , like , you mean you just transferred everything and then finally drop the frames after the neural net . Mm - hmm . Right ? Yeah . That 's {disfmarker} that 's one thing which {disfmarker} Mm - hmm . But you could even mark them , before they get to the server . Yeah . Right now we are {disfmarker} Uh , ri Right now what {disfmarker} wha what we did is , like , we just mark {disfmarker} we just have this additional bit which goes around the features , {vocalsound} saying it 's currently a {disfmarker} it 's a speech or a nonspeech . Oh , OK . So there is no frame - dropping till the final features , like , including the deltas are computed . I see . And after the deltas are computed , you just pick up the ones that are marked silence and then drop them . Mm - hmm . I see . I see . So it would be more or less the same thing with the neural net , I guess , actually . Mm - hmm . So . Yeah , that 's what {disfmarker} that 's what {disfmarker} that 's what , uh , this is doing right now . I see . OK . Yeah . Mm - hmm . Um . OK . So , uh , what 's , uh {disfmarker} ? That 's {disfmarker} that 's a good set of work that {disfmarker} that , uh {disfmarker} Just one more thing . Like , should we do something f more for the noise estimation , because we still {disfmarker} ? Yeah . I was wondering about that . That was {disfmarker} I {disfmarker} I had written that down there . Yeah . Mm - hmm . Um {disfmarker} So , we , uh {disfmarker} actually I did the first experiment . This is {pause} with just fifteen frames . Um . We take the first fifteen frame of each utterance to it , Yeah . and average their power spectra . Um . I tried just plugging the , um , {vocalsound} uh , Guenter noise estimation on this system , and it {disfmarker} uh , it got worse . Um , but of course I didn't play {pause} with it . Uh - huh . But {disfmarker} Mm - hmm . Uh , I didn't {pause} do much more {pause} for noise estimation . I just tried this , Hmm . Yeah . Well , it 's not surprising it 'd be worse the first time . and {disfmarker} But , um , Mm - hmm . it does seem like , you know , i i i i some compromise between always depending on the first fifteen frames and a a always depending on a {disfmarker} a pause is {disfmarker} is {disfmarker} is a good idea . Uh , maybe you have to weight the estimate from the first - teen {disfmarker} fifteen frames more heavily than {disfmarker} than was done in your first attempt . But {disfmarker} Mm - hmm . but {disfmarker} Yeah , I guess . Yeah . Um . No , I mean {disfmarker} Um , do you have any way of assessing how well or how poorly the noise estimation is currently doing ? Mmm . No , we don't . Yeah . We don't have nothing {pause} that {disfmarker} Is there {disfmarker} was there any experiment with {disfmarker} ? Well , I {disfmarker} I did {disfmarker} The only experiment where I tried was I used the channel zero VAD for the noise estimation and frame - dropping . So I don't have a {disfmarker} {vocalsound} I don't have a split , like which one helped more . Yeah . So . It {disfmarker} it was the best result I could get . Mm - hmm . So , that 's the {disfmarker} So that 's something you could do with , um , this final system . Right ? Just do this {disfmarker} everything that is in this final system except , {vocalsound} uh , use the channel zero . Mm - hmm . For the noise estimation . Yeah . Yeah . We can try something . And then see how much better it gets . Mm - hmm . Sure . If it 's , you know , essentially not better , then {pause} it 's probably not worth Yeah . any more . Yeah . But the Guenter 's argument is slightly different . It 's , like , ev even {disfmarker} even if I use a channel zero VAD , I 'm just averaging the {disfmarker} {vocalsound} the s power spectrum . But the Guenter 's argument is , like , if it is a non - stationary {pause} segment , then he doesn't update the noise spectrum . So he 's , like {disfmarker} he tries to capture only the stationary part in it . So the averaging is , like , {vocalsound} different from {pause} updating the noise spectrum only during stationary segments . So , th the Guenter was arguing that , I mean , even if you have a very good VAD , averaging it , like , over the whole thing is not a good idea . I see . Because you 're averaging the stationary and the non - stationary , and finally you end up getting something which is not really the s because , you {disfmarker} anyway , you can't remove the stationary part fr I mean , non - stationary part from {vocalsound} the signal . Not using these methods anyway . Yeah . So {disfmarker} Yeah . So you just {pause} update only doing {disfmarker} or update only the stationary components . Yeah . So , that 's {disfmarker} so that 's still a slight difference from what Guenter is trying  Well , yeah . And {disfmarker} and also there 's just the fact that , um , eh , uh , although we 're trying to do very well on this evaluation , um , we actually would like to have something that worked well in general . And , um , relying on having fifteen frames at the front or something is {disfmarker} is pretty {disfmarker} Yeah , yeah . I mean , you might , you might not . Mmm . Mm - hmm . So , um . Um , it 'd certainly be more robust to different kinds of input if you had at least some updates . Um . Mm - hmm . But , um . Well , I don't know . What {disfmarker} what do you , uh {disfmarker} what do you guys see as {disfmarker} as being what you would be doing in the next week , given wha what 's {pause} happened ? Cure the VAD ? Yeah . What was that ? VAD . Oh . And {disfmarker}  OK . So , should we keep the same {disfmarker} ? I think we might try to keep the same idea of having a neural network , but {vocalsound} training it on more data and adding better features , I think , but {disfmarker} because the current network is just PLP features . Well , it 's trained on noisy {pause} PLP {disfmarker} Just the cepstra . Yeah . PLP features computed on noisy speech . But {vocalsound} {vocalsound} there is no nothing particularly robust in these features . So , I I uh {disfmarker} No . There 's no RASTA , no {disfmarker} So , uh , I {disfmarker} I don't remember what you said {vocalsound} the answer to my , uh , question earlier . Will you {disfmarker} will you train the net on {disfmarker} after you 've done the spectral subtraction or the Wiener filtering ? This is a different net . Oh . So we have a VAD which is like neur that 's a neural net . Oh , yeah . Hmm . Oh , you 're talking about the VAD net . OK . Yeah . Mm - hmm . I see . So that {disfmarker} that VAD was trained on the noisy features . Mm - hmm . So , right now we have , like , uh {disfmarker} we have the cleaned - up features , so we can have a better VAD by training the net on {pause} the cleaned - up speech . Mm - hmm . I see . I see . Yeah , but we need a VAD for uh noise estimation also . So it 's , like , where do we want to put the VAD ? Uh , it 's like {disfmarker} Can you use the same net to do both , or {disfmarker} ? For {disfmarker} Can you use the same net that you {disfmarker} that I was talking about to do the VAD ? Mm - hmm . Uh , it actually comes at v at the very end . Mm - hmm . So the net {disfmarker} the final net {disfmarker} I mean , which is the feature net {disfmarker} so that actually comes after a chain of , like , LDA plus everything . So it 's , like , it takes a long time to get a decision out of it . And {disfmarker} {vocalsound} and you can actually do it for final frame - dropping , but not for the VA - f noise estimation . Mm - hmm . You see , the idea is that the , um , initial decision to {disfmarker} that {disfmarker} that you 're in silence or speech happens pretty quickly . Oh , OK . Hmm . Cuz that 's used by some of these other {disfmarker} ? And that {disfmarker} Yeah . And that 's sort of fed forward , and {disfmarker} and you say \" well , flush everything , it 's not speech anymore \" . Oh , OK . I see . Yeah . I thought that was only used for doing frame - dropping later on . Um , it is used , uh {disfmarker} Yeah , it 's only used f Well , it 's used for frame - dropping . Um , it 's used for end of utterance Mmm . because , you know , there 's {disfmarker} {vocalsound} if you have {pause} more than five hundred milliseconds of {disfmarker} of {disfmarker} of nonspeech then you figure it 's end of utterance or something like that . Mm - hmm . So , um . And it seems important for , like , the on - line normalization . Um . We don't want to update the mean and variance during silen long silence portions . Um . So it {disfmarker} it has to be done before Oh . I see . this mean and variance normalization . Um . Um . Yeah . So probably the VAD and {disfmarker} and maybe testing out the noise {pause} estimation a little bit . I mean , keeping the same method but {disfmarker} but , uh , {vocalsound} seeing if you cou but , um noise estimation could be improved . Those are sort of related issues . Mm - hmm . It probably makes sense to move from there . And then , uh , {vocalsound} later on in the month I think we wanna start including the {pause} neural net at the end . Um . OK . Anything else ? The Half Dome was great . Good . Yeah . You didn't {disfmarker} didn't fall . That 's good . Well , yeah . Our e our effort would have been devastated if you guys had {comment} {vocalsound} run into problems . So , Hynek is coming back next week , you said ? Yeah , that 's the plan . Hmm . I guess the week after he 'll be , uh , going back to Europe , and so we wanna {disfmarker} Is he in Europe right now or is he up at {disfmarker} ? No , no . He 's {disfmarker} he 's {disfmarker} he 's dropped into the US . Yeah . Yeah . Oh . Hmm . So . Uh . {vocalsound} So , uh . Uh , the idea was that , uh , we 'd {disfmarker} we 'd sort out where we were going next with this {disfmarker} with this work before he , uh , left on this next trip . Good . {vocalsound} {vocalsound} Uh , Barry , you just got through your {vocalsound} quals , so I don't know if you {vocalsound} have much to say . But , uh . Mmm . No , just , uh , looking into some {disfmarker} some of the things that , um , {vocalsound} uh , John Ohala and Hynek , um , gave as feedback , um , as {disfmarker} as a starting point for the project . Um . In {disfmarker} in my proposal , I {disfmarker} I was thinking about starting from a set of , uh , phonological features , {vocalsound} or a subset of them . Um , but that might not be necessarily a good idea according to , um , John . Mm - hmm . He said , uh , um , these {disfmarker} these phonological features are {disfmarker} are sort of figments of imagination also . Mm - hmm . Um . S In conversational speech in particular . I think you can {disfmarker} you can put them in pretty reliably in synthetic speech . Ye But {vocalsound} we don't have too much trouble recognizing synthetic speech since we create it in the first place . So , it 's {disfmarker} Right . Yeah . So , um , a better way would be something more {disfmarker} more data - driven , Mm - hmm . just looking at the data and seeing what 's similar and what 's not similar . Mm - hmm . So , I 'm {disfmarker} I 'm , um , taking a look at some of , um , {vocalsound} Sangita 's work on {disfmarker} on TRAPS . She did something where , um {disfmarker} {vocalsound} w where the TRAPS learn She clustered the {disfmarker} the temporal patterns of , um , certain {disfmarker} certain phonemes in {disfmarker} in m averaged over many , many contexts . And , uh , some things tended to cluster . Mm - hmm . Right ? You know , like stop {disfmarker} stop consonants clustered really well . Hmm . Um , silence was by its own self . Mm - hmm . And , uh , um , {vocalsound} v vocalic was clustered . Mm - hmm . And , {vocalsound} um , so , {vocalsound} those are {pause} interesting things to {disfmarker} So you 're {disfmarker} now you 're sort of looking to try to gather a set of these types of features ? Right . Mm - hmm . Yeah . Just to see where {disfmarker} where I could start off from , Mm - hmm . uh , you know ? A {disfmarker} a {disfmarker} a set of small features and continue to iterate and find , uh , a better set . Mm - hmm . Yeah . OK . Well , short meeting . That 's OK . Yeah . OK . So next week hopefully we 'll {disfmarker} can get Hynek here to {disfmarker} to join us and , uh , uh . Should we do digits ? Digits , digits . OK , now . Go ahead , Morgan . You can start . Alright . Let me get my glasses on so I can {pause} see them . OK . OK . And we 're off . Mm",
        "summarize": null
    }
]