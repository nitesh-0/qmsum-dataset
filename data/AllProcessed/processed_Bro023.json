[
    {
        "transcript": "OK , we 're going . Damn . And uh Hans - uh , Hans - Guenter will be here , um , I think by next {disfmarker} next Tuesday or so . Oh , OK . Mm - hmm . So he 's {disfmarker} he 's going to be here for about three weeks , Oh ! That 's nice . Just for a visit ? and , uh {disfmarker} Uh , we 'll see . Huh . We might {disfmarker} might end up with some longer collaboration or something . Cool . So he 's gonna look in on everything we 're doing Mm - hmm . and give us his {disfmarker} his thoughts . And so it 'll be another {disfmarker} another good person looking at things . Oh . Hmm . Th - that 's his spectral subtraction group ? Yeah , Is that right ? yeah . Oh , OK . So I guess I should probably talk to him a bit too ? Oh , yeah . Yeah . Yeah . No , he 'll be around for three weeks . He 's , uh , um , very , very , easygoing , easy to talk to , and , uh , very interested in everything . Really nice guy . Yeah , yeah . Yeah , we met him in Amsterdam . Yeah , yeah , he 's been here before . Oh , OK . I mean , he 's {disfmarker} he 's {disfmarker} he 's {disfmarker} he 's {disfmarker} Wh - Back when I was a grad student he was here for a , uh , uh {disfmarker} a year or {comment} n six months . I haven't noticed him . N nine months . Something like that . Something like that . Yeah . Yeah . Yeah . He 's {disfmarker} he 's done a couple stays here . Hmm . Yeah . So , um , {vocalsound} {comment} I guess we got lots to catch up on . And we haven't met for a couple of weeks . We didn't meet last week , Morgan . Um , I went around and talked to everybody , and it seemed like they {disfmarker} they had some new results but rather than them coming up and telling me I figured we should just wait a week and they can tell both {disfmarker} you know , all of us . So , um , why don't we {disfmarker} why don't we start with you , Dave , and then , um , we can go on . Oh , OK . So . So , um , since we 're looking at putting this , um {disfmarker} mean log m magnitude spectral subtraction , um , into the SmartKom system , I I did a test seeing if , um , it would work using past only {comment} and plus the present to calculate the mean . So , I did a test , um , {vocalsound} where I used twelve seconds from the past and the present frame to , um , calculate the mean . And {disfmarker} Twelve seconds {disfmarker} Twelve {disfmarker} twelve seconds back from the current {pause} frame , is that what you mean ? Uh {disfmarker} Twelve seconds , um , counting back from the end of the current frame , OK , OK . yeah . So it was , um , twen I think it was twenty - one frames and that worked out to about twelve seconds . Mm - hmm . And compared to , um , do using a twelve second centered window , I think there was a drop in performance but it was just a slight drop . Hmm ! Mm - hmm . Is {disfmarker} is that right ? Um , yeah , I mean , it was pretty {disfmarker} it was pretty tiny . Yeah . Uh - huh . So that was encouraging . And , um , that {disfmarker} that {disfmarker} um , that 's encouraging for {disfmarker} for the idea of using it in an interactive system like And , um , another issue I 'm {disfmarker} I 'm thinking about is in the SmartKom system . So say twe twelve seconds in the earlier test seemed like a good length of time , but what happens if you have less than twelve seconds ? And , um {disfmarker} So I w bef before , um {disfmarker} Back in May , I did some experiments using , say , two seconds , or four seconds , or six seconds . In those I trained the models using mean subtraction with the means calculated over two seconds , or four seconds , or six seconds . And , um , here , I was curious , what if I trained the models using twelve seconds but I f I gave it a situation where the test set I was {disfmarker} subtracted using two seconds , or four seconds , or six seconds . And , um {disfmarker} So I did that for about three different conditions . And , um {disfmarker} I mean , I th I think it was , um , four se I think {disfmarker} I think it was , um , something like four seconds and , um , six seconds , and eight seconds . Something like that . And it seems like it {disfmarker} it {disfmarker} it hurts compared to if you actually train the models {comment} using th that same length of time but it {disfmarker} it doesn't hurt that much . Um , u usually less than point five percent , although I think I did see one where it was a point eight percent or so rise in word error rate . But this is , um , w where , um , even if I train on the , uh , model , and mean subtracted it with the same length of time as in the test , it {disfmarker} the word error rate is around , um , ten percent or nine percent . So it doesn't seem like that big a d a difference . But it {disfmarker} but looking at it the other way , isn't it {disfmarker} what you 're saying that it didn't help you to have the longer time for training , if you were going to have a short time for {disfmarker} That {disfmarker} that 's true . Um , I mean , why would you do it , if you knew that you were going to have short windows in testing . Wa Yeah , it seems like for your {disfmarker} I mean , in normal situations you would never get twelve seconds of speech , right ? I 'm not {disfmarker} e u You need twelve seconds in the past to estimate , right ? Or l or you 're looking at six sec {disfmarker} seconds in future and six in {disfmarker} Yeah . Um , t twelve s No , total . N n uh {disfmarker} For the test it 's just twelve seconds in the past . No , it 's all {disfmarker} Oh , OK . Is this twelve seconds of {disfmarker} uh , regardless of speech or silence ? Or twelve seconds of speech ? Of {disfmarker} of speech . OK . Mm - hmm . The other thing , um , which maybe relates a little bit to something else we 've talked about in terms of windowing and so on is , that , um , I wonder if you trained with twelve seconds , and then when you were two seconds in you used two seconds , and when you were four seconds in , you used four seconds , and when you were six {disfmarker} and you basically build up to the twelve seconds . So that if you have very long utterances you have the best , Yeah . but if you have shorter utterances you use what you can . Right . And that 's actually what we 're planning to do in OK . Yeah . But {disfmarker} s so I g So I guess the que the question I was trying to get at with those experiments is , \" does it matter what models you use ? Does it matter how much time y you use to calculate the mean when you were , um , tra doing the training data ? \" Right . But I mean the other thing is that that 's {disfmarker} I mean , the other way of looking at this , going back to , uh , mean cepstral subtraction versus RASTA kind of things , is that you could look at mean cepstral subtraction , especially the way you 're doing it , uh , as being a kind of filter . And so , the other thing is just to design a filter . You know , basically you 're {disfmarker} you 're {disfmarker} you 're doing a high - pass filter or a band - pass filter of some sort and {disfmarker} and just design a filter . And then , you know , a filter will have a certain behavior and you loo can look at the start up behavior when you start up with nothing . Mm - hmm . And {disfmarker} and , you know , it will , uh , if you have an IIR filter for instance , it will , um , uh , not behave in the steady - state way that you would like it to behave until you get a long enough period , but , um , uh , by just constraining yourself to have your filter be only a subtraction of the mean , you 're kind of , you know , tying your hands behind your back because there 's {disfmarker} filters have all sorts of be temporal and spectral behaviors . Mm - hmm . And the only thing , you know , consistent that we know about is that you want to get rid of the very low frequency component . Hmm . But do you really want to calculate the mean ? And you neglect all the silence regions {comment} or you just use everything that 's twelve seconds , and {disfmarker} Um , you {disfmarker} do you mean in my tests so far ? Ye - yeah . Most of the silence has been cut out . OK . Just {disfmarker} There 's just inter - word silences . Mm - hmm . And they are , like , pretty short . Shor Pretty short . Yeah , OK . Yeah . Yeah . Mm - hmm . So you really need a lot of speech to estimate the mean of it . Well , if I only use six seconds , it still works pretty well . Yeah . Yeah . Uh - huh . I saw in my test before . I was trying twelve seconds cuz that was the best {pause} in my test before OK . and that increasing past twelve seconds didn't seem to help . Hmm . Huh . th um , yeah , I guess it 's something I need to play with more to decide how to set that up for the SmartKom system . Like , may maybe if I trained on six seconds it would work better when I only had two seconds or four seconds , and {disfmarker} Yeah . Yeah . And , um {disfmarker} OK . Yeah , and again , if you take this filtering perspective and if you essentially have it build up over time . I mean , if you computed means over two and then over four , and over six , essentially what you 're getting at is a kind of , uh , ramp up of a filter anyway . And so you may {disfmarker} may just want to think of it as a filter . But , uh , if you do that , then , um , in practice somebody using the SmartKom system , one would think {comment} {disfmarker} if they 're using it for a while , it means that their first utterance , instead of , you know , getting , uh , a forty percent error rate reduction , they 'll get a {disfmarker} uh , over what , uh , you 'd get without this , uh , um , policy , uh , you get thirty percent . And then the second utterance that you give , they get the full {disfmarker} you know , uh , full benefit of it if it 's this ongoing thing . Oh , so you {disfmarker} you cache the utterances ? That 's how you get your , uh {disfmarker} Well , I 'm saying in practice , yeah , M Ah . OK . that 's {disfmarker} If somebody 's using a system to ask for directions or something , OK . you know , they 'll say something first . And {disfmarker} and to begin with if it doesn't get them quite right , ma m maybe they 'll come back and say , \" excuse me ? \" Mm - hmm . uh , or some {disfmarker} I mean it should have some policy like that anyway . Mm - hmm . And {disfmarker} and , uh , uh , in any event they might ask a second question . And it 's not like what he 's doing doesn't , uh , improve things . It does improve things , just not as much as he would like . And so , uh , there 's a higher probability of it making an error , uh , in the first utterance . What would be really cool is if you could have {disfmarker} uh , this probably {disfmarker} users would never like this {disfmarker} but if you had {disfmarker} could have a system where , {vocalsound} before they began to use it they had to introduce themselves , verbally . Mm - hmm . You know . \" Hi , my name is so - and - so , Yeah . I 'm from blah - blah - blah . \" And you could use that initial speech to do all these adaptations and {disfmarker} Right . Mm - hmm . Oh , the other thing I guess which {disfmarker} which , uh , I don't know much about {disfmarker} as much as I should about the rest of the system but {disfmarker} but , um , couldn't you , uh , if you {disfmarker} if you sort of did a first pass I don't know what kind of , uh , uh , capability we have at the moment for {disfmarker} for doing second passes on {disfmarker} on , uh , uh , some kind of little {disfmarker} small lattice , or a graph , or confusion network , or something . But if you did first pass with , um , the {disfmarker} with {disfmarker} either without the mean sub subtraction or with a {disfmarker} a very short time one , and then , um , once you , uh , actually had the whole utterance in , if you did , um , the , uh , uh , longer time version then , based on everything that you had , um , and then at that point only used it to distinguish between , you know , top N , um , possible utterances or something , you {disfmarker} you might {disfmarker} it might not take very much time . I mean , I know in the large vocabulary stu uh , uh , systems , people were evaluating on in the past , some people really pushed everything in to make it in one pass but other people didn't and had multiple passes . And , um , the argument , um , against multiple passes was u u has often been \" but we want to this to be r you know {disfmarker} have a nice interactive response \" . And the counterargument to that which , say , uh , BBN I think had , {comment} was \" yeah , but our second responses are {disfmarker} second , uh , passes and third passes are really , really fast \" . Mm - hmm . So , um , if {disfmarker} if your second pass takes a millisecond who cares ? Um . S so , um , the {disfmarker} the idea of the second pass would be waiting till you have more recorded speech ? Or {disfmarker} ? Yeah , so if it turned out to be a problem , that you didn't have enough speech because you need a longer {disfmarker} longer window to do this processing , then , uh , one tactic is {disfmarker} you know , looking at the larger system and not just at the front - end stuff {comment} {disfmarker} is to take in , um , the speech with some simpler mechanism or shorter time mechanism , Mm - hmm . um , do the best you can , and come up with some al possible alternates of what might have been said . And , uh , either in the form of an N - best list or in the form of a lattice , or {disfmarker} or confusion network , or whatever . Mm - hmm . And then the decoding of that is much , much faster or can be much , much faster if it isn't a big bushy network . And you can decode that now with speech that you 've actually processed using this longer time , uh , subtraction . Mmm . So I mean , it 's {disfmarker} it 's common that people do this sort of thing where they do more things that are more complex or require looking over more time , whatever , in some kind of second pass . Mm - hmm . OK . um , and again , if the second pass is really , really fast {disfmarker} Uh , another one I 've heard of is {disfmarker} is in {disfmarker} in connected digit stuff , um , going back and l and through backtrace and finding regions that are considered to be a d a digit , but , uh , which have very low energy . Mm - hmm . OK . So , uh {disfmarker} I mean , there 's lots of things you can do in second passes , at all sorts of levels . Anyway , I 'm throwing too many things out . But . So is that , uh {disfmarker} that it ? I guess that 's it . OK , uh , do you wanna go , Sunil ? Yep . Um , so , the last two weeks was , like {disfmarker} So I 've been working on that Wiener filtering . And , uh , found that , uh , s single {disfmarker} like , I just do a s normal Wiener filtering , like the standard method of Wiener filtering . And that doesn't actually give me any improvement over like {disfmarker} I mean , uh , b it actually improves over the baseline but it 's not like {disfmarker} it doesn't meet something like fifty percent or something . So , I 've been playing with the v Improves over the base line MFCC system ? Yeah . Yeah . Yeah . Yeah . So , um {disfmarker} So that 's {disfmarker} The improvement is somewhere around , like , thirty percent over the baseline . Is that using {disfmarker} in combination with something else ? No , just {disfmarker} just one stage Wiener filter With {disfmarker} with a {disfmarker} which is a standard Wiener filter . No , no , but I mean in combination with our on - line normalization or with the LDA ? Yeah , yeah , yeah , yeah . So I just plug in the Wiener filtering . Oh , OK . I mean , in the s in our system , where {disfmarker} Oh , OK . So , I di i di So , does it g does that mean it gets worse ? Or {disfmarker} ? No . It actually improves over the baseline of not having a Wiener filter in the whole system . Like I have an LDA f LDA plus on - line normalization , and then I plug in the Wiener filter in that , Yeah ? so it improves over not having the Wiener filter . So it improves but it {disfmarker} it doesn't take it like be beyond like thirty percent over the baseline . So {disfmarker} But that 's what I 'm confused about , cuz I think {disfmarker} I thought that our system was more like forty percent without the Wiener filtering . No , it 's like , uh , Mmm . Is this with the v new VAD ? well , these are not {disfmarker} No , it 's the old VAD . So my baseline was , {vocalsound} uh , {vocalsound} nine {disfmarker} This is like {disfmarker} w the baseline is ninety - five point six eight , and eighty - nine , and {disfmarker} So I mean , if you can do all these in word errors it 's a lot {disfmarker} a lot easier actually . What was that ? Sorry ? If you do all these in word error rates it 's a lot easier , right ? Oh , OK , OK , OK . Errors , right , I don't have . OK , cuz then you can figure out the percentages . It 's all accuracies . Yeah . The baseline is something similar to a w I mean , the t the {disfmarker} the baseline that you are talking about is the MFCC baseline , right ? The t yeah , there are two baselines . Or {disfmarker} ? OK . So the baseline {disfmarker} One baseline is MFCC baseline that {disfmarker} When I said thirty percent improvement it 's like MFCC baseline . Mm - hmm . So {disfmarker} so {disfmarker} so what 's it start on ? The MFCC baseline is {disfmarker} is what ? Is at what level ? It 's the {disfmarker} it 's just the mel frequency and that 's it . No , what 's {disfmarker} what 's the number ? Uh , so I I don't have that number here . OK , OK , OK , I have it here . Uh , it 's the VAD plus the baseline actually . I 'm talking about the {disfmarker} the MFCC plus I do a frame dropping on it . So that 's like {disfmarker} the word error rate is like four point three . Like {disfmarker} Ten point seven . Four point three . What 's ten point seven ? It 's a medium misma OK , sorry . There 's a well ma well matched , medium mismatched , and a high matched . Ah . So I don't have the {disfmarker} like the {disfmarker} Yeah . So {disfmarker} OK , four point three , ten point seven , And forty forty . and {disfmarker} Forty percent is the high mismatch . OK . And that becomes like four point three {disfmarker} Not changed . Yeah , it 's like ten point one . Still the same . And the high mismatch is like eighteen point five . Eighteen point five . Five . And what were you just describing ? Oh , the one is {disfmarker} this one is just the baseline plus the , uh , Wiener filter plugged into it . But where 's the , uh , on - line normalization and so on ? Oh , OK . So {disfmarker} Sorry . So , with the {disfmarker} with the on - line normalization , the performance was , um , ten {disfmarker} OK , so it 's like four point three . Uh , and again , that 's the ba the ten point , uh , four and twenty point one . That was with on - line normalization and LDA . So the h well matched has like literally not changed by adding on - line or LDA on it . But the {disfmarker} I mean , even the medium mismatch is pretty much the same . And the high mismatch was improved by twenty percent absolute . OK , and what kind of number {disfmarker} an and what are we talking about here ? It 's the It - it 's Italian . Is this TI - digits I 'm talking about Italian , or {disfmarker} Italian ? yeah . And what did {disfmarker} So , what was the , um , uh , corresponding number , say , for , um , uh , the Alcatel system for instance ? Mmm .  Do you know ? Yeah , so it looks to be , um {disfmarker} You have it ? Yep , it 's three point four , uh , eight point , uh , seven , and , uh , thirteen point seven . Yep . OK . So {disfmarker} Thanks . OK . Mm - hmm . OK . So , uh , this is the single stage Wiener filter , with {disfmarker} The noise estimation was based on first ten frames . Mm - hmm . Actually I started with {disfmarker} using the VAD to estimate the noise and then I found that it works {disfmarker} it doesn't work for Finnish and Spanish because the VAD endpoints are not good to estimate the noise because it cuts into the speech sometimes , so I end up overestimating the noise and getting a worse result . So it works only for Italian by u for {disfmarker} using a VAD to estimate noise . Mm - hmm . It works for Italian because the VAD was trained on Italian . Mm - hmm . So , uh {disfmarker} so this was , uh {disfmarker} And so this was giving {disfmarker} um , this {disfmarker} this was like not improving a lot on this baseline of not having the Wiener filter on it . And , so , uh , I ran this stuff with one more stage of Wiener filtering on it but the second time , what I did was I {disfmarker} estimated the new Wiener filter based on the cleaned up speech , and did , uh , smoothing in the frequency to {disfmarker} to reduce the variance {disfmarker} Mm - hmm . I mean , I have {disfmarker} I 've {disfmarker} I 've observed there are , like , a lot of bumps in the frequency when I do this Wiener filtering which is more like a musical noise or something . And so by adding another stage of Wiener filtering , the results on the SpeechDat - Car was like , um {disfmarker} So , I still don't have the word error rate . I 'm sorry about it . But the overall improvement was like fifty - six point four six . This was again using ten frames of noise estimate and two stage of Wiener filtering . And the rest is like the LDA plu and the on - line normalization all remaining the same . Uh , so this was , like , compared to , uh , uh {disfmarker} Fifty - seven is what you got by using the French Telecom system , right ? No , I don't think so . Y i Is it on Italian ? No , this is over the whole SpeechDat - Car . So {disfmarker} Oh , yeah , fifty - seven {disfmarker} point {disfmarker} Right . Yeah , so the new {disfmarker} the new Wiener filtering schema is like {disfmarker} some fifty - six point four six which is like one percent still less than what you got using the French Telecom system . Uh - huh . Mm - hmm . But it 's a pretty similar number in any event . It 's very similar . Yeah . But again , you 're {disfmarker} you 're more or less doing what they were doing , right ? It 's {disfmarker} it 's different in a sense like I 'm actually cleaning up the cleaned up spectrum which they 're not doing . They 're d what they 're doing is , they have two stage {disfmarker} stages of estimating the Wiener filter , but {disfmarker} the final filter , what they do is they {disfmarker} they take it to their time domain by doing an inverse Fourier transform . Yeah . And they filter the original signal using that fil filter , Uh - huh . which is like final filter is acting on the input noisy speech rather than on the cleaned up . So this is more like I 'm doing Wiener filter twice , but the only thing is that the second time I 'm actually smoothing the filter and then cleaning up the cleaned up spectrum first level . And so that {disfmarker} that 's {disfmarker} that 's what the difference is . OK . And actually I tried it on s the original clean {disfmarker} I mean , the original spectrum where , like , I {disfmarker} the second time I estimate the filter but actually clean up the noisy speech rather the c s first {disfmarker} output of the first stage and that doesn't {disfmarker} seems to be a {disfmarker} giving , I mean , that much improvement . I {disfmarker} I didn didn't run it for the whole case . And {disfmarker} and what I t what I tried was , by using the same thing but {disfmarker} Uh , so we actually found that the VAD is very , like , crucial . I mean , just by changing the VAD itself gives you the {disfmarker} a lot of improvement Mm - hmm . by instead of using the current VAD , if you just take up the VAD output from the channel zero , {comment} when {disfmarker} instead of using channel zero and channel one , because that was the p that was the reason why I was not getting a lot of improvement for estimating {comment} the noise . So I just used the channel zero VAD to estimate the noise so that it gives me some reliable mar markers for this noise estimation . What 's a channel zero VAD ? Um , I 'm {disfmarker} I 'm confused about that . so , it 's like {disfmarker} So it 's the close - talking microphone . Yeah , the close - talking without {disfmarker} Oh , oh , oh , oh . So because the channel zero and channel one are like the same speech , but only w I mean , the same endpoints .  But the only thing is that the speech is very noisy for channel one , so you can actually use the output of the channel zero for channel one for the VAD . I mean , that 's like a cheating method . Right . I mean , so a are they going to pro What are they doing to do , do we know yet ? about {disfmarker} as far as what they 're {disfmarker} what the rules are going to be and what we can use ? Yeah , so actually I received a {disfmarker} a new document , describing this . Yeah , that 's {disfmarker} And what they did finally is to , mmm , uh , not to align the utterances but to perform recognition , um , only on the close - talking microphone , Which is the channel zero . and to take the result of the recognition to get the boundaries uh , of speech . So it 's not like that 's being done in one place or one time . And {disfmarker} That 's {disfmarker} that 's just a rule and we 'd {disfmarker} you {disfmarker} you were permitted to do that . Is {disfmarker} is that it ? Uh , I think they will send , um , files but we {disfmarker} we don't {disfmarker} Well , apparently {disfmarker} Oh , so they will send files so everybody will have the same boundaries to work with ? Yeah . Yeah . But actually their alignment actually is not seems to be improving in like on all cases . OK . Oh , i Yeah , so what happened here is that , um , the overall improvement that they have with this method {disfmarker} So {disfmarker} Well , to be more precise , what they have is , they have these alignments and then they drop the beginning silence and {disfmarker} and the end silence but they keep , uh , two hundred milliseconds before speech and two hundred after speech . And they keep the speech pauses also . Um , and the overall improvement over the MFCC baseline So , when they just , uh , add this frame dropping in addition it 's r uh , forty percent , right ? Mm - hmm . Fourteen percent , I mean . Mm - hmm . Yeah , which is {disfmarker} Um , which is , um , t which is the overall improvement . But in some cases it doesn't improve at all . Like , uh , y do you remember which case ? Mm - hmm . It gives like negative {disfmarker} Well , in {disfmarker} in like some Italian and TI - digits , Yeah , some @ @ . right ? Right . Yeah . So by using the endpointed speech , actually it 's worse than the baseline in some instances , which could be due to the word pattern . Mmm . Yeah . Yeah , And {disfmarker} Yeah , the other thing also is that fourteen percent is less than what you obtain using a real VAD . Yeah , our neural net {disfmarker} So with without cheating like this . Yeah , yeah . So {disfmarker} Uh {disfmarker} So I think this shows that there is still work {disfmarker} Uh , well , working on the VAD is still {disfmarker} still important I think . Yeah , c Uh {disfmarker} Can I ask just a {disfmarker} a high level question ? Can you just say like one or two sentences about Wiener filtering and why {disfmarker} why are people doing that ? Hmm . What 's {disfmarker} what 's the deal with that ? OK , so the Wiener filter , it 's {disfmarker} it 's like {disfmarker} it 's like you try to minimize {disfmarker} I mean , so the basic principle of Wiener filter is like you try to minimize the , uh , d uh , difference between the noisy signal and the clean signal if you have two channels . Like let 's say you have a clean t signal and you have an additional channel where you know what is the noisy signal . Mm - hmm . And then you try to minimize the error between these two . Mm - hmm . So that 's the basic principle . And you get {disfmarker} you can do that {disfmarker} I mean , if {disfmarker} if you have only a c noisy signal , at a level which you , you w try to estimate the noise from the w assuming that the first few frames are noise or if you have a w voice activity detector , uh , you estimate the noise spectrum . Mm - hmm . And then you {disfmarker} Do you assume the noise is the same ? Yeah . in {disfmarker} yeah , after the speech starts . Uh - huh . So {disfmarker} but that 's not the case in , uh , many {disfmarker} many of our cases but it works reasonably well . I see . And {disfmarker} and then you What you do is you , uh b fff . So again , I can write down some of these eq Oh , OK . Yeah . And then you do this {disfmarker} uh , this is the transfer function of the Wiener filter , so \" SF \" is a clean speech spectrum , power spectrum Mm - hmm . And \" N \" is the noisy power spectrum . And so this is the transfer function . Right And , actually , I guess {disfmarker} Yeah . Yeah . And then you multiply your noisy power spectrum with this . You get an estimate of the clean power spectrum . I see . OK . So {disfmarker} but the thing is that you have to estimate the SF from the noisy spectrum , what you have . So you estimate the NF from the initial noise portions and then you subtract that from the current noisy spectrum to get an estimate of the SF . So sometimes that becomes zero because you do you don't have a true estimate of the noise . So the f filter will have like sometimes zeros in it Mm - hmm . because some frequency values will be zeroed out because of that . And that creates a lot of discontinuities across the spectrum because @ @ the filter . So , uh , so {disfmarker} that 's what {disfmarker} that was just the first stage of Wiener filtering that I tried . So is this , um , basically s uh , similar to just regular spectral subtraction ? It {disfmarker} It 's all pretty related , Yeah . yeah . It 's {disfmarker} it 's {disfmarker} there 's a di there 's a whole class of techniques where you try in some sense to minimize the noise . Uh - huh . And it 's typically a mean square sense , uh {disfmarker} uh {disfmarker} uh , i in {disfmarker} in {disfmarker} in some way . And , uh {disfmarker} uh , spectral subtraction is {disfmarker} is , uh {disfmarker} uh , one approach to it . Do people use the Wiener filtering in combination with the spectral subtraction typically , or is i are they sort of competing techniques ? Not seen . They are very s similar techniques . Yeah . O oh , OK . So it 's like I haven't seen anybody using s Wiener filter with spectral subtraction . Mm - hmm . I see , I see . I mean , in the long run you 're doing the same thing Mm - hmm . Yeah . but y but there you make different approximations , and {disfmarker} in spectral subtraction , for instance , there 's a {disfmarker} a {disfmarker} an estimation factor . Mmm . You sometimes will figure out what the noise is and you 'll multiply that noise spectrum times some constant and subtract that rather than {disfmarker} and sometimes people {disfmarker} even though this really should be in the power domain , sometimes people s work in the magnitude domain because it {disfmarker} it {disfmarker} it works better . Mm - hmm . And , uh , uh , you know . So why did you choose , uh , Wiener filtering over some other {disfmarker} one of these other techniques ? Uh , the reason was , like , we had this choice of using spectral subtraction , Wiener filtering , and there was one more thing which I which I 'm trying , is this sub space approach . So , Stephane is working on spectral subtraction . Oh , OK . So I picked up {disfmarker} So you 're sort of trying @ @ them all . Y Yeah , Ah , we just wanted to have a few noise production {disfmarker} compensation techniques I see . Oh , OK . and then pick some from that {disfmarker} Mm - hmm . pick one . I m I mean {disfmarker} yeah , I mean , there 's Car - Carmen 's working on another , on the vector Taylor series . VA Yeah , VAD . w Yeah . So they were just kind of trying to cover a bunch of different things with this task and see , you know , what are {disfmarker} what are the issues for each of them . Ah , OK . That makes sense . Yeah . Yeah . Mm - hmm . Mm - hmm . Um . Cool , thanks . So {disfmarker} so one of {disfmarker} one of the things that I tried , like I said , was to remove those zeros in the fri filter by doing some smoothing of the filter . Yeah . Mm - hmm . Like , you estimate the edge of square and then you do a f smoothing across the frequency so that those zeros get , like , flattened out . Mm - hmm . And that doesn't seems to be improving by trying it on the first time . So what I did was like I p did this and then you {disfmarker} I plugged in the {disfmarker} one more {disfmarker} the same thing but with the smoothed filter the second time . Mm - hmm . And that seems to be working . Mm - hmm . So that 's where I got like fifty - six point five percent improvement on SpeechDat - Car with that . And {disfmarker} So the other thing what I tried was I used still the ten frames of noise estimate but I used this channel zero VAD to drop the frames . So I 'm not {disfmarker} still not estimating . And that has taken the performance to like sixty - seven percent in SpeechDat - Car , which is {disfmarker} which {disfmarker} which like sort of shows that by using a proper VAD you can just take it to further , better levels . And {disfmarker} So . So that 's sort of like , you know , best - case performance ? Yeah , so far I 've seen sixty - seven {disfmarker} I mean , no , I haven't seen s like sixty - seven percent . And , uh , using the channel zero VAD to estimate the noise also seems to be improving but I don't have the results for all the cases with that . So I used channel zero VAD to estimate noise as a lesser 2 x frame , which is like , {vocalsound} everywhere I use the channel zero VAD . And that seems to be the best combination , uh , rather than using a few frames to estimate and then drop a channel . So I 'm {disfmarker} I 'm still a little confused . Is that channel zero information going to be accessible during this test . Nnn , no . This is just to test whether we can really improve by using a better VAD . Mm - hmm . So , Mm - hmm . I mean {disfmarker} So this is like the noise compensation f is fixed Mm - hmm . but you make a better decision on the endpoints . That 's , like {disfmarker} seems to be {disfmarker} Mm - hmm . so we c so I mean , which {disfmarker} which means , like , by using this technique what we improve just the VAD Yes . we can just take the performance by another ten percent or better . OK . So , that {disfmarker} that was just the , uh , reason for doing that experiment . And , w um {disfmarker} Yeah , but this {disfmarker} all these things , I have to still try it on the TI - digits , which is like I 'm just running . And there seems to be not improving a {disfmarker} a lot on the TI - digits , so I 'm like investigating that , why it 's not . And , um , um {disfmarker} Well after that . So , uh {disfmarker} so the other {disfmarker} the other thing is {disfmarker} like I 've been {disfmarker} I 'm doing all this stuff on the power spectrum . So {disfmarker} Tried this stuff on the mel as well {disfmarker} mel and the magnitude , and mel magnitude , and all those things . But it seems to be the power spectrum seems to be getting the best result . So , one of {disfmarker} one of reasons I thought like doing the averaging , after the filtering using the mel filter bank , that seems to be maybe helping rather than trying it on the mel filter ba filtered outputs . Mm - hmm . Mm - hmm . So just th Ma Makes sense . Yeah , th that 's {disfmarker} that 's the only thing that I could think of why {disfmarker} why it 's giving improvement on the mel . And , yep . So that 's it . Uh , how about the subspace stuff ? Subspace , {comment} I 'm {disfmarker} I 'm like {disfmarker} that 's still in {disfmarker} a little bit in the back burner because I 've been p putting a lot effort on this to make it work , on tuning things and other stuff . OK . So I was like going parallely but not much of improvement . I 'm just {disfmarker} have some skeletons ready , need some more time for it . OK . Mmm . Tha - that it ? Yep . Yep . Cool . Do you wanna go , Stephane ? Uh , yeah . So , {vocalsound} I 've been , uh , working still on the spectral subtraction . Um , So to r to remind you {vocalsound} {vocalsound} a little bit of {disfmarker} of what I did before , is just {vocalsound} to apply some spectral subtraction with an overestimation factor also to get , um , an estimate of the noise , uh , spectrum , and subtract this estimation of the noise spectrum from the , uh , signal spectrum , {comment} but subtracting more when the SNR is {disfmarker} is , uh , low , which is a technique that it 's often used . \" Subtracting more \" , meaning {disfmarker} ? So you overestimate the noise spectrum . You multiply the noise spectrum by a factor , uh , which depends on the SNR . Oh , OK . I see . So , above twenty DB , it 's one , so you just subtract the noise . Mm - hmm . And then it 's b Generally {disfmarker} Well , I use , actually , a linear , uh , function of the SNR , Mm - hmm . which is bounded to , like , two or three , {comment} when the SNR is below zero DB . Mm - hmm . Mm - hmm . Um , doing just this , uh , either on the FFT bins or on the mel bands , um , t doesn't yield any improvement Oh ! Um , uh , what are you doing with negative , uh , powers ? o Yeah . So there is also a threshold , of course , because after subtraction you can have negative energies , Mm - hmm . and {disfmarker} So what I {disfmarker} I just do is to put , uh {disfmarker} to {disfmarker} to add {disfmarker} to put the threshold first and then to add a small amount of noise , which right now is speech - shaped . Um {disfmarker} Speech - shaped ? Yeah , so it 's {disfmarker} a it has the overall {disfmarker} overall energy , uh {disfmarker} pow it has the overall power spectrum of speech . So with a bump around one kilohertz . So when y when you talk about there being something less than zero after subtracting the noise , is that at a particular frequency bin ? i Uh - huh . Yeah . OK . There can be frequency bins with negative values . And so when you say you 're adding something that has the overall shape of speech , is that in a {disfmarker} in a particular frequency bin ? Or you 're adding something across all the frequencies when you get these negatives ? For each frequencies I a I 'm adding some , uh , noise , but the a the amount of {disfmarker} the amount of noise I add is not the same for all the frequency bins . Ah ! OK . I gotcha . Right . Uh . Right now I don't think if it makes sense to add something that 's speech - shaped , because then you have silence portion that have some spectra similar to the sp the overall speech spectra . Mm - hmm . But {disfmarker} Yeah . So this is something I can still work on , So what does that mean ? but {disfmarker} Hmm . I 'm trying to understand what it means when you do the spectral subtraction and you get a negative . It means that at that particular frequency range you subtracted more energy than there was actually {disfmarker} That means that {disfmarker} Mm - hmm . Yeah . So {disfmarker} so yeah , you have an {disfmarker} an estimation of the noise spectrum , but sometimes , of course , it 's {disfmarker} as the noise is not perfectly stationary , sometimes this estimation can be , uh , too small , so you don't subtract enough . But sometimes it can be too large also . If {disfmarker} if the noise , uh , energy in this particular frequency band drops for some reason . Mm - hmm . Mm - hmm . Mmm . So in {disfmarker} in an ideal word i world {comment} if the noise were always the same , then , when you subtracted it the worst that i you would get would be a zero . I mean , the lowest you would get would be a zero , cuz i if there was no other energy there you 're just subtracting exactly the noise . Right . Mm - hmm , Yep , there 's all {disfmarker} there 's all sorts of , uh , deviations from the ideal here . yeah . I mean , for instance , you 're {disfmarker} you 're talking about the signal and noise , um , at a particular point . And even if something is sort of stationary in ster terms of statistics , there 's no guarantee that any particular instantiation or piece of it is exactly a particular number or bounded by a particular range . Mm - hmm . So , you 're figuring out from some chunk of {disfmarker} of {disfmarker} of the signal what you think the noise is . Then you 're subtracting that from another chunk , Mm - hmm . and there 's absolutely no reason to think that you 'd know that it wouldn't , uh , be negative in some places . Mm - hmm . Hmm . Uh , on the other hand that just means that in some sense you 've made a mistake because you certainly have stra subtracted a bigger number than is due to the noise . Mm - hmm . Um {disfmarker} Also , we speak {disfmarker} the whole {disfmarker} where all this stuff comes from is from an assumption that signal and noise are uncorrelated . And that certainly makes sense in s in {disfmarker} in a statistical interpretation , that , you know , over , um , all possible realizations that they 're uncorrelated Mm - hmm . or assuming , uh , ergodicity that i that i um , across time , uh , it 's uncorrelated . But if you just look at {disfmarker} a quarter second , uh , and you cross - multiply the two things , uh , you could very well , uh , end up with something that sums to something that 's not zero . So in fact , the two signals could have some relation to one another . And so there 's all sorts of deviations from ideal in this . And {disfmarker} and given all that , you could definitely end up with something that 's negative . But if down the road you 're making use of something as if it is a power spectrum , um , then it can be bad to have something negative . Now , the other thing I wonder about actually is , what if you left it negative ? What happens ? Is that the log ? I mean , because {disfmarker} Um , are you taking the log before you add them up to the mel ? After that . No , after . Right . So the thing is , I wonder how {disfmarker} if you put your thresholds after that , I wonder how often you would end up with , uh {disfmarker} with negative values . But you will {disfmarker} But you end up reducing some neighboring frequency bins {disfmarker} @ @ in the average , right ? When you add the negative to the positive value which is the true estimate . Yeah . But nonetheless , uh , you know , these are {disfmarker} it 's another f kind of smoothing , right ? that you 're doing . Yeah . Right . So , you 've done your best shot at figuring out what the noise should be , and now i then you 've subtracted it off . And then after that , instead of {disfmarker} instead of , uh , uh , leaving it as is and adding things {disfmarker} adding up some neighbors , you artificially push it up . Hmm . Which is , you know , it 's {disfmarker} there 's no particular reason that that 's the right thing to do either , right ? Yeah , yeah . So , um , uh , i in fact , what you 'd be doing is saying , \" well , we 're d we 're {disfmarker} we 're going to definitely diminish the effect of this frequency in this little frequency bin in the {disfmarker} in the overall mel summation \" . It 's just a thought . I d I don't know if it would be {disfmarker} Sort of the opposite of that would be if {disfmarker} if you find out you 're going to get a negative number , you don't do the subtraction for that bin . Yeah . Uh - huh . That is true . Nnn , yeah , Mm - hmm . although {disfmarker} That would be almost the opposite , right ? Instead of leaving it negative , you don't do it . If your {disfmarker} if your subtraction 's going to result in a negative number , you {disfmarker} you don't do subtraction in that . Yeah , but that means that in a situation where you thought that {disfmarker} that the bin was almost entirely noise , you left it . Yeah . Yeah , I 'm just saying that 's like the opposite . We just {disfmarker} Uh . Yeah . Yeah . Yeah . Well , yeah that 's {disfmarker} that 's the opposite , Mm - hmm . yeah . And , yeah , some people also {disfmarker} if it 's a negative value they , uh , re - compute it using inter interpolation from the edges and bins . For frames , frequency bins . Yeah . Well , there are different things that you can do . Oh . People can also , uh , reflect it back up and essentially do a full wave rectification instead of a {disfmarker} instead of half wave . Oh . But it was just a thought that {disfmarker} that it might be something to try . Mm - hmm . Mm - hmm . Yep . Well , actually I tried , {vocalsound} something else based on this , um , is to {disfmarker} to put some smoothing , um , because it seems to {disfmarker} to help or it seems to help the Wiener filtering Mm - hmm . and , mmm {disfmarker} So what I did is , uh , some kind of nonlinear smoothing . Actually I have a recursion that computes {disfmarker} Yeah , let me go back a little bit . Actually , when you do spectral subtraction you can , uh , find this {disfmarker} this equivalent in the s in the spectral domain . You can uh compute , y you can say that d your spectral subtraction is a filter , um , and the gain of this filter is the , um , {vocalsound} signal energy minus what you subtract , divided by the signal energy . And this is a gain that varies over time , and , you know , of course , uh , depending on the s on the noise spectrum and on the speech spectrum . And {disfmarker} what happen actually is that during low SNR values , the gain is close to zero but it varies a lot . Mmm , and this {disfmarker} this is the cause of musical noise and all these {disfmarker} the {disfmarker} {comment} the fact you {disfmarker} we go below zero one frame and then you can have an energy that 's above zero . Mm - hmm . And {disfmarker} Mmm . So the smoothing is {disfmarker} I did a smoothing actually on this gain , uh , trajectory . But it 's {disfmarker} the smoothing is nonlinear in the sense that I tried to not smooth if the gain is high , because in this case we know that , uh , the estimate of the gain is correct because we {disfmarker} we are not close to {disfmarker} to {disfmarker} to zero , um , and to do more smoothing if the gain is low . Mmm . Um . Yeah . So , well , basically that 's this idea , and it seems to give pretty good results , uh , although I 've just {disfmarker} just tested on Italian and Finnish . And on Italian it seems {disfmarker} my result seems to be a little bit better than the Wiener filtering , Mm - hmm . Yeah , the one you showed yesterday . right ? Right ? Yeah . Uh , I don't know if you have these improvement the detailed improvements for Italian , Finnish , and Spanish there Fff . No , I don't have , for each , or you have {disfmarker} just have your own . I {disfmarker} I just {disfmarker} just have the final number here . Mm - hmm . So these numbers he was giving before with the four point three , and the ten point one , and so forth , those were Italian , right ? Yeah , yeah , yeah . So {disfmarker} so , no , Yeah . Uh {disfmarker} I actually didn't give you the number which is the final one , uh , no , we 've {disfmarker} which is , after two stages of Wiener filtering . I mean , that was I just {disfmarker} well , like the overall improvement is like fifty - six point five . So , Right . Mm - hmm . I mean , his number is still better than what I got in the two stages of Wiener filtering . Yeah . Right . On Italian . But on Finnish it 's a little bit worse , apparently . Mm - hmm . Um {disfmarker} But do you have numbers in terms of word error rates on {disfmarker} on Italian ? So just so you have some sense of reference ? Yeah . Uh , so , it 's , uh , three point , uh , eight . Uh - huh . Am I right ? Oh , OK . Yeah , right , OK . And then , uh , d uh , nine point , uh , one . Mm - hmm . And finally , uh , sixteen point five . And this is , um , spectral subtraction plus what ? Plus {disfmarker} plus nonlinear smoothing . Well , it 's {disfmarker} the system {disfmarker} it 's exactly the sys the same system as Sunil tried , On - line normalization and LDA ? but {disfmarker} Yeah . Yeah . Yeah . But instead of double stage Wiener filtering , it 's {disfmarker} it 's this smoothed spectral subtraction . Um , yeah . What is it the , um , France Telecom system uses Right . for {disfmarker} Do they use spectral subtraction , or Wiener filtering , or {disfmarker} ? They use spectral subtraction , right . For what ? French Telecom . It {disfmarker} it 's Wiener filtering , Oh , it 's {disfmarker} it 's Wiener filtering . am I right ? Oh . Sorry . Well , it 's some kind of Wiener filtering {disfmarker} Yeah , filtering . Yeah , it 's not exactly Wiener filtering but some variant of Wiener filtering . Yeah . I see . Yeah . Yeah , plus , uh , I guess they have some sort of cepstral normalization , as well . s They have like {disfmarker} yeah , th the {disfmarker} just noise compensation technique is a variant of Wiener filtering , Mm - hmm . plus they do some {disfmarker} some smoothing techniques on the final filter . The {disfmarker} th they actually do the filtering in the time domain . Mmm . Yeah . Hmm . So they would take this HF squared back , taking inverse Fourier transform . And they convolve the time domain signal with that . Oh , I see . And they do some smoothing on that final filter , impulse response . Hmm . But they also have two {disfmarker} two different smoothing @ @ . I mean , I 'm {disfmarker} I 'm @ @ . One in the time domain and one in the frequency domain by just taking the first , um , coefficients of the impulse response . But . So , basically it 's similar . I mean , what you did , it 's similar It 's similar in the smoothing and {disfmarker} because you have also two {disfmarker} two kind of smoothing . Yeah . One in the time domain , and one in the frequency domain , Yeah . The frequency domain . yeah . Does the smoothing in the time domain help {disfmarker} Um {disfmarker} Well , do you get this musical noise stuff with Wiener filtering or is that only with , uh , spectral subtraction ? No , you get it with Wiener filtering also . Yeah . Does the smoothing in the time domain help with that ? Or some other smoothing ? Oh , no , you still end up with zeros in the s spectrum . Sometimes . Yeah . Hmm . I mean , it 's not clear that these musical noises hurt us in recognition . Hmm . We don't know if they do . Yeah . I mean , they {disfmarker} they sound bad . Mm - hmm . Yeah , I know . But we 're not listening to it , usually . Mm - hmm . Hmm . Uh , actually the {disfmarker} the smoothing that I did {disfmarker} do here reduced the musical noise . Well , it {disfmarker} Mm - hmm . Yeah , yeah , Mmm . the {disfmarker} Well , I cannot {disfmarker} you cannot hear beca well , actually what I d did not say is that this is not in the FFT bins . This is in the mel frequency bands . Um {disfmarker} So , it could be seen as a f a {disfmarker} a smoothing in the frequency domain because I used , in ad mel bands in addition and then the other phase of smoothing in the time domain . Mmm . But , when you look at the spectrogram , if you don't have an any smoothing , you clearly see , like {disfmarker} in silence portions , and at the beginning and end of speech , you see spots of high energy randomly distributed over the {disfmarker} the spectrogram . Mm - hmm . Mm - hmm . Um {disfmarker} That 's the musical noise ? Which is musical noise , Mm - hmm . yeah , if {disfmarker} if it {disfmarker} If you listen to it {disfmarker} uh , if you do this in the FFT bins , then you have spots of energy randomly distributing . And if you f if you re - synthesize these spot sounds as , like , sounds , Mm - hmm . uh {disfmarker} Well , none of these systems , by the way , have {disfmarker} I mean , y you both are {disfmarker} are working with , um , our system that does not have the neural net , And {disfmarker} Yep . right ? Yeah . Mm - hmm . OK . So one would hope , presumably , that the neural net part of it would {disfmarker} would improve things further as {disfmarker} as they did before . Yeah . Yeah . Um {disfmarker} Yeah , although if {disfmarker} if we , um , look at the result from the proposals , {comment} one of the reason , uh , the n system with the neural net was , um , more than {disfmarker} well , around five percent better , is that it was much better on highly mismatched condition . I 'm thinking , for instance , on the TI - digits trained on clean speech and tested on noisy speech . Mm - hmm . Uh , for this case , the system with the neural net was much better . Mm - hmm . But not much on the {disfmarker} in the other cases . Yeah . And if we have no , uh , spectral subtraction or Wiener filtering , um , i the system is {disfmarker} Uh , we thought the neural {disfmarker} neural network is much better than before , even in these cases of high mismatch . So , maybe the neural net will help less but , um {disfmarker} Maybe . Could you train a neural net to do spectral subtraction ? Yeah , it could do a nonlinear spectral subtraction Mm - hmm . but I don't know if it {disfmarker} I mean , you have to figure out what your targets are . Yeah , I was thinking if you had a clean version of the signal and {disfmarker} and a noisy version , and your targets were the M F - uh , you know , whatever , frequency bins {disfmarker} Mm - hmm . Right . Mm - hmm . Yeah , well , that 's not so much spectral subtraction then , Mm - hmm . but {disfmarker} but {disfmarker} but it 's {disfmarker} but at any rate , yeah , people , uh {disfmarker} People do that ? y yeah , in fact , we had visitors here who did that I think when you were here ba way back when . Mm - hmm . Hmm . Uh , people {disfmarker} d done lots of experimentation over the years with training neural nets . And it 's not a bad thing to do . It 's another approach . Hmm . M I mean , it 's {disfmarker} it , um {disfmarker} Mm - hmm . The objection everyone always raises , which has some truth to it is that , um , it 's good for mapping from a particular noise to clean but then you get a different noise . Mm - hmm . And the experiments we saw that visitors did here showed that it {disfmarker} there was at least some , um , {vocalsound} {comment} gentleness to the degradation when you switched to different noises . It did seem to help . So that {disfmarker} you 're right , that 's another {disfmarker} another way to go . How did it compare on {disfmarker} I mean , for {disfmarker} for good cases where it {disfmarker} it {disfmarker} uh , stuff that it was trained on ? Did it do pretty well ? Oh , yeah , it did very well . Mmm . Yeah . Mmm . Um , Mm - hmm . but to some extent that 's kind of what we 're doing . I mean , we 're not doing exactly that , we 're not trying to generate good examples but by trying to do the best classifier you possibly can , for these little phonetic categories , Mm - hmm . You could say it 's sort of built in . It 's {disfmarker} Yeah , it 's kind of built into that . Hmm . And {disfmarker} and that 's why we have found that it {disfmarker} it does help . Mm - hmm . Um {disfmarker} so , um , yeah , I mean , we 'll just have to try it . But I {disfmarker} I would {disfmarker} I would {disfmarker} I would imagine that it will help some . I mean , it {disfmarker} we 'll just have to see whether it helps more or less the same , but I would imagine it would help some . Mm - hmm . So in any event , all of this {disfmarker} I was just confirming that all of this was with a simpler system . Yeah , OK ? yeah . Um , Yeah , so this is th the , um {disfmarker} Well , actually , this was kind of the first try with this spectral subtraction plus smoothing , Mm - hmm . and I was kind of excited by the result . Mm - hmm . Um , then I started to optimize the different parameters . And , uh , the first thing I tried to optimize is the , um , time constant of the smoothing . And it seems that the one that I chose for the first experiment was the optimal one , so {vocalsound} uh , It 's amazing how often that happens . Um , so this is the first thing . Um {disfmarker} Yeah , another thing that I {disfmarker} it 's important to mention is , um , that this has a this has some additional latency . Um . Because when I do the smoothing , uh , it 's a recursion that estimated the means , so {disfmarker} of the g of the gain curve . And this is a filter that has some latency . And I noticed that it 's better if we take into account this latency . So , instead o of using the current estimated mean to , uh , subtract the current frame , it 's better to use an estimate that 's some somewhere in the future . Um {disfmarker} And that 's what causes the latency ? OK . You mean , the m the mean is computed o based on some frames in the future also ? Mm - hmm . Yeah . Or {disfmarker} or no ? It 's the recursion , so it 's {disfmarker} it 's the center recursion , right ? Mm - hmm . Um {disfmarker} and the latency of this recursion is around fifty milliseconds . One five ?  One five ? Five zero ? Five zero , Five zero . yeah . Yeah . Um , I 'm sorry , mmm . why {disfmarker} why is that delay coming ? Like , you estimate the mean ? Yeah , the mean estimation has some delay , right ? Oh , yeah . I mean , the {disfmarker} the filter that {disfmarker} that estimates the mean has a time constant . It isn't {disfmarker} OK , so it 's like it looks into the future also . OK . Yeah . What if you just look into the past ? It 's , uh , not as good . It 's not bad . How m by how much ? Um , it helps a lot over the ba the baseline but , mmm {disfmarker} By how much ? it {disfmarker} It 's around three percent , um , relative . Worse . Yeah . Yeah . Um , Hmm . mmm {disfmarker} So , uh {disfmarker} It 's depending on how all this stuff comes out we may or may not be able to add any latency . Yeah , but {disfmarker} Yeah . So , yeah , it depends . Uh , y actually , it 's {disfmarker} it 's l it 's three percent . Right . Mmm . Yeah , b but I don't think we have to worry too much on that right now while {disfmarker} you kno . Mm - hmm . Um , s Yeah , I mean , I think the only thing is that {disfmarker} So {disfmarker} I would worry about it a little . Mm - hmm . Because if we completely ignore latency , and then we discover that we really have to do something about it , we 're going to be {disfmarker} find ourselves in a bind . Mm - hmm . So , um , you know , maybe you could make it twenty - five . You know what I mean ? Yeah . Yeah , just , you know , just be {disfmarker} be a little conservative Oh yes . because we may end up with this crunch where all of a sudden we have to cut the latency in half or something . s Mm - hmm . Yeah . OK . Um . So , yeah , there are other things in the , um , algorithm that I didn't , uh , @ @ a lot yet , Oh ! which {disfmarker} Sorry . A quick question just about the latency thing . If {disfmarker} if there 's another part of the system that causes a latency of a hundred milliseconds , is this an additive thing ? Or c or is yours hidden in that ? Mm - hmm . Uh {disfmarker} No , it 's {disfmarker} it 's added . It 's additive . OK . Mm - hmm . We can {disfmarker} OK . We can do something in parallel also , in some like {disfmarker} some cases like , if you wanted to do voice activity detection . Uh - huh . And we can do that in parallel with some other filtering you can do . Mmm . So you can make a decision on that voice activity detection and then you decide whether you want to filter or not . Yeah . But by then you already have the sufficient samples to do the filtering . Mm - hmm . So {disfmarker} So , sometimes you can do it anyway . I mean , couldn't , uh {disfmarker} I {disfmarker} Couldn't you just also {disfmarker} I mean , i if you know that the l the largest latency in the system is two hundred milliseconds , don't you {disfmarker} couldn't you just buffer up that number of frames and then everything uses that buffer ? Yeah . And that way it 's not additive ? Well , in fact , everything is sent over in buffers cuz of {disfmarker} isn't it the TCP buffer some {disfmarker} ? You mean , the {disfmarker} the data , the super frame or something ? Mm - hmm . Yeah , yeah . Yeah . Yeah , but that has a variable latency because the last frame doesn't have any latency Mm - hmm . and first frame has a twenty framed latency . So you can't r rely on that latency all the time . Yeah . Because {disfmarker} I mean the transmission over {disfmarker} over the air interface is like a buffer . Yeah . Twenty frame {disfmarker} Yeah . twenty four frames . Yeah . So {disfmarker} But the only thing is that the first frame in that twenty - four frame buffer has a twenty - four frame latency . And the last frame doesn't have any latency . Mm - hmm . Because it just goes as {disfmarker} Yeah , I wasn't thinking of that one in particular Yeah . but more of , you know , if {disfmarker} if there is some part of your system that has to buffer twenty frames , uh , can't the other parts of the system draw out of that buffer and therefore not add to the latency ? Yeah . Yeah . And {disfmarker} and that 's sort of one of the {disfmarker} all of that sort of stuff is things that they 're debating in their standards committee . Oh ! Hmm . Mm - hmm . Yeah . So , um , there is uh , {comment} these parameters that I still have to {disfmarker} to look at . Like , I played a little bit with this overestimation factor , uh , but I still have to {disfmarker} to look more at this , um , at the level of noise I add after . Uh , I know that adding noise helped , um , the system just using spectral subtraction without smoothing , but I don't know right now if it 's still important or not , and if the level I choose before is still the right one . Same thing for the shape of the {disfmarker} the noise . Maybe it would be better to add just white noise instead of speech shaped noise . That 'd be more like the JRASTA thing in a sense . Yeah . Mm - hmm . Um , yep . Uh , and another thing is to {disfmarker} Yeah , for this I just use as noise estimate the mean , uh , spectrum of the first twenty frames of each utterance . I don't remember for this experiment what did you use for these two stage {disfmarker} I used ten {disfmarker} just ten frames . Yeah , because {disfmarker} The ten frames ? I mean , the reason was like in TI - digits I don't have a lot . I had twenty frames most of the time . Mm - hmm . Um . But , so what 's this result you told me about , the fact that if you use more than ten frames you can {disfmarker} improve by t Well , that 's {disfmarker} that 's using the channel zero . If I use a channel zero VAD to estimate the noise . Oh , OK . Which {disfmarker} But this is ten frames plus {disfmarker} plus Channel zero dropping . channel {disfmarker} Hmm . Uh , no , these results with two stage Wiener filtering is ten frames t Oh , this {disfmarker} but possibly more . I mean , if channel one VAD gives you {disfmarker} f Yeah . Mm - hmm . Yeah . Yeah . OK . Yeah , but in this experiment I did {disfmarker} I didn't use any VAD . I just used the twenty first frame to estimate the noise . And {disfmarker} So I expected it to be a little bit better , {vocalsound} if , uh , I use more {disfmarker} more frames . Um . OK , that 's it for spectral subtraction . The second thing I was working on is to , um , try to look at noise estimation , {comment} mmm , and using some technique that doesn't need voice activity detection . Um , and for this I u simply used some code that , uh , {vocalsound} I had from {disfmarker} from Belgium , which is technique that , um , takes a bunch of frame , um , and for each frequency bands of this frame , takes a look at the minima of the energy . And then average these minima and take this as an {disfmarker} an energy estimate of the noise for this particular frequency band . And there is something more to this actually . What is done is that , {vocalsound} uh , these minima are computed , um , based on , um , high resolution spectra . So , I compute an FFT based on the long , uh , signal frame which is sixty - four millisecond {disfmarker} So you have one minimum for each frequency ? What {disfmarker} what I {disfmarker} what I d uh , I do actually , is to take a bunch of {disfmarker} to take a tile on the spectrogram and this tile is five hundred milliseconds long and two hundred hertz wide . Mmm . And this tile {disfmarker} Uh , in this tile appears , like , the harmonics if you have a voiced sound , because it 's {disfmarker} it 's the FTT bins . And when you take the m the minima of {disfmarker} of these {disfmarker} this tile , when you don't have speech , these minima will give you some noise level estimate , If you have voiced speech , these minima will still give you some noise estimate because the minima are between the harmonics . And {disfmarker} If you have other {disfmarker} other kind of speech sounds then it 's not the case , but if the time frame is long enough , uh , like s five hundred milliseconds seems to be long enough , {comment} you still have portions which , uh , are very close {disfmarker} whi which minima are very close to the noise energy . I 'm confused . You said five hundred milliseconds Mmm ? but you said sixty - four milliseconds . Which is which ? What ? Sixty - four milliseconds is to compute the FFT , uh , bins . Yeah , The {disfmarker} the FFT . yeah . Um , actually it 's better to use sixty - four milliseconds because , um , if you use thirty milliseconds , then , uh , because of the {disfmarker} this short windowing and at low pitch , uh , sounds , {vocalsound} the harmonics are not , wha uh , correctly separated . Mm - hmm . So if you take these minima , it {disfmarker} b {vocalsound} they will overestimate the noise a lot . So you take sixty - four millisecond F F Ts and then you average them {comment} over five hundred ? Or {disfmarker} ? Uh , what do you do over five hundred ? So I take {disfmarker} to {disfmarker} I take a bunch of these sixty - four millisecond frame to cover five hundred milliseconds , Ah . OK . and then I look for the minima , Mmm . I see . on the {disfmarker} on {disfmarker} on the bunch of uh fifty frames , right ? I see . Mmm . So the interest of this is that , as y with this technique you can estimate u some reasonable noise spectra with only five hundred milliseconds of {disfmarker} of signal , so if the {disfmarker} the n the noise varies a lot , uh , you can track {disfmarker} better track the noise , Mm - hmm . which is not the case if you rely on the voice activity detector . So even if there are no no speech pauses , you can track the noise level . The only requirement is that you must have , in these five hundred milliseconds segment , {comment} you must have voiced sound at least . Cuz this {disfmarker} these will help you to {disfmarker} to track the {disfmarker} the noise level . Um . So what I did is just to simply replace the VAD - based , uh , noise estimate by this estimate , first on SpeechDat - Car {disfmarker} Well , only on SpeechDat - Car actually . And it 's , uh , slightly worse , like one percent relative compared to the VAD - based {pause} estimates . Um , I think the reason why it 's not better , is that the SpeechDat - Car noises are all stationary . Um . So , u y y there really is no need to have something that 's adaptive Mm - hmm . and {disfmarker} Uh , well , they are mainly stationary . Um . But , I expect s maybe some improvement on TI - digits because , nnn , in this case the noises are all sometimes very variable . Uh , so I have to test it . Mmm . But are you comparing with something {disfmarker} e I 'm {disfmarker} I 'm {disfmarker} p s a little confused again , i it {disfmarker} Uh , when you compare it with the V A D - based , Mm - hmm . VAD - Is this {disfmarker} is this the {disfmarker} ? It 's {disfmarker} It 's the France - Telecom - based spectra , s uh , Wiener filtering and VAD . So it 's their system but just I replace their noise estimate by this one . Oh , you 're not doing this with our system ? In i I 'm not {disfmarker} No , no . Yeah , it 's our system but with just the Wiener filtering from their system . Right ? Mmm . OK . Yeah . Actually , th the best system that we still have is , uh , our system but with their noise compensation scheme , right ? Right . But {disfmarker} So I 'm trying to improve on this , and {disfmarker} by {disfmarker} by replacing their noise estimate by , uh , something that might be better . OK . But the spectral subtraction scheme that you reported on also re requires a {disfmarker} a noise estimate . Yeah . Yeah . Couldn't you try this for that ? But I di Do you think it might help ? Not yet , because I did this in parallel , I see , and I was working on one and the other . I see . Yeah . Um , Yeah . Yeah , for {disfmarker} for sure I will . I can try also , mmm , the spectral subtraction . So I 'm also using that n new noise estimate technique on this Wiener filtering what I 'm trying . OK . So I {disfmarker} I have , like , some experiments running , I don't have the results . Mm - hmm . Yeah . So . Yeah . I don't estimate the f noise on the ten frames but use his estimate . Yeah . Mm - hmm . Um . Yeah . I , um , also implemented a sp um {disfmarker} spectral whitening idea which is in the , um , Ericsson proposal . Uh , the idea is just to {vocalsound} um , flatten the log , uh , spectrum , um , and to flatten it more if the {disfmarker} the probability of silence is higher . So in this way , you can also reduce {disfmarker} somewhat reduce the musical noise and you reduce the variability if you have different noise shapes , because the {disfmarker} the spectrum becomes more flat in the silence portions . Um . Yeah . With this , no improvement , uh , but there are a lot of parameters that we can play with and , um {disfmarker} Actually , this {disfmarker} this could be seen as a soft version of the frame dropping because , um , you could just put the threshold and say that \" below the threshold , I will flatten {disfmarker} comp completely flatten the {disfmarker} the spectrum \" . And above this threshold , uh , keep the same spectrum . So it would be like frame dropping , because during the silence portions which are below the threshold of voice activity probability , {comment} uh , w you would have some kind of dummy frame which is a perfectly flat spectrum . And this , uh , whitening is something that 's more soft because , um , you whiten {disfmarker} you just , uh , have a function {disfmarker} the whitening is a function of the speech probability , so it 's not a hard decision . Mm - hmm . Um , so I think maybe it can be used together with frame dropping and when we are not sure about if it 's speech or silence , well , maybe it has something do with this . It 's interesting . I mean , um , you know , in {disfmarker} in JRASTA we were essentially adding in , uh , white {disfmarker} uh , white noise dependent on our estimate of the noise . Mm - hmm . On the overall estimate of the noise . Uh , I think it never occurred to us to use a probability in there . Mm - hmm . You could imagine one that {disfmarker} that {disfmarker} that made use of where {disfmarker} where the amount that you added in was , uh , a function of the probability of it being s speech or noise . Mm - hmm . Mm - hmm . Yeah , w Yeah , right now it 's a constant that just depending on the {disfmarker} the noise spectrum . There 's {disfmarker} Yeah . Mm - hmm . Mm - hmm . Cuz that {disfmarker} that brings in sort of powers of classifiers that we don't really have in , uh , this other estimate . So it could be {disfmarker} it could be interesting . Mm - hmm . Mm - hmm . What {disfmarker} what {disfmarker} what point does the , uh , system stop recording ? How much {disfmarker} It 'll keep going till {disfmarker} I guess when they run out of disk space , It went a little long ? I mean , disk {disfmarker} but {disfmarker} I think we 're OK . So . OK . Yeah . Uh {disfmarker} Yeah , so there are {disfmarker} with this technique there are some {disfmarker} I just did something exactly the same as {disfmarker} as the Ericsson proposal but , um , {vocalsound} the probability of speech is not computed the same way . And I think , i for {disfmarker} yeah , for a lot of things , actually a g a good speech probability is important . Like for frame dropping you improve , like {disfmarker} you can improve from ten percent as Sunil showed , if you use the channel zero speech probabilities . Mm - hmm . Mm - hmm . For this it might help , um {disfmarker} Mm - hmm . S so , yeah . Uh , so yeah , the next thing I started to do is to , {vocalsound} uh , try to develop a better voice activity detector . And , um {disfmarker} I d um {disfmarker} yeah , for this I think we can maybe try to train the neural network for voice activity detection on all the data that we have , including all the SpeechDat - Car data . Um {disfmarker} And so I 'm starting to obtain alignments on these databases . Um , and the way I mi I do that is that I just use the HTK system but I train it only on the close - talking microphone . And then I aligned {disfmarker} I obtained the Viterbi alignment of the training utterances . Um {disfmarker} It seems to be , uh i Actually what I observed is that for Italian it doesn't seem {disfmarker} Th - there seems to be a problem . No . So , it doesn't seems to help by their use of channel zero or channel one . Well . Because {disfmarker} What ? Uh , you mean their d the frame dropping , right ? Yeah , it doesn't {disfmarker} Yeah . Yeah . So , u but actually the VAD was trained on Italian also , Italian . so {disfmarker} Um , the c the current VAD that we have was trained on , uh , t SPINE , right ? TI - digits . Italian , and TI - digits with noise and {disfmarker}  Uh , yeah . And it seems to work on Italian but not on the Finnish and Spanish data . So , maybe one reason is that s s Finnish and Spanish noise are different . And actually we observed {disfmarker} we listened to some of the utterances and sometimes for Finnish there is music in the recordings and strange things , right ? Yeah . Um {disfmarker} Yeah , so the idea was to train all the databases and obtain an alignment to train on these databases , and , um , also to , um , try different kind of features , {vocalsound} uh , as input to the VAD network . And we came up with a bunch of features that we want to try like , um , the spectral slope , the , um , the degree o degree of voicing with the features that , uh , we started to develop with Carmen , um , e with , uh , the correlation between bands and different kind of features , Yeah . Mm - hmm . and {disfmarker} Yeah . The energy also . The energy . Yeah . Yeah , right . Yeah . Of course . Yeah . OK . Well , Hans - Guenter will be here next week so I think he 'll be interested in all {disfmarker} all of these things . And , so . Mm - hmm . Mmm . OK , shall we , uh , do digits ? Yeah . Want to go ahead , Morgan ? Sure . OK .",
        "summarize": null
    }
]