[
    {
        "transcript": "We 're going ? OK . Sh - Close your door on {disfmarker} door on the way out ? OK . Thanks . Thanks . Oh . Yeah . Probably wanna get this other door , too . OK . So . Um . {vocalsound} {vocalsound} What are we talking about today ? Uh , well , first there are perhaps these uh Meeting Recorder digits that we tested . Oh , yeah . That was kind of uh interesting . So . The {disfmarker} both the uh {disfmarker} {vocalsound} the SRI System and the oth Um . And for one thing that {disfmarker} that sure shows the {vocalsound} difference between having a lot of uh training data {vocalsound} or not , Of data ? Yeah . uh , the uh {disfmarker} {vocalsound} The best kind of number we have on the English uh {disfmarker} on near microphone only is {disfmarker} is uh three or four percent . Mm - hmm . And uh it 's significantly better than that , using fairly simple front - ends {vocalsound} on {disfmarker} {vocalsound} on the uh {disfmarker} {vocalsound} uh , with the SRI system . Mm - hmm . So I th I think that the uh {disfmarker} But that 's {disfmarker} that 's using uh a {disfmarker} a pretty huge amount of data , mostly not digits , of course , but {disfmarker} but then again {disfmarker} Well , yeah . In fact , mostly not digits for the actual training the H M Ms whereas uh in this case we 're just using digits for training the H M Yeah . Right . Did anybody mention about whether the {disfmarker} the SRI system is a {disfmarker} {vocalsound} is {disfmarker} is doing the digits um the wor as a word model or as uh a sub s sub - phone states ? I guess it 's {disfmarker} it 's uh allophone models , Yeah . Probably . so , well {disfmarker} Huh ? Yeah . I think so , because it 's their very d huge , their huge system . Yeah . And . But . So . There is one difference {disfmarker} Well , the SRI system {disfmarker} the result for the SRI system that are represented here are with adaptation . So there is {disfmarker} It 's their complete system and {disfmarker} including on - line uh unsupervised adaptation . That 's true . And if you don't use adaptation , the error rate is around fifty percent worse , I think , if I remember . OK . Yeah . It 's tha it 's that much , huh ? Nnn . It 's {disfmarker} Yeah . It 's quite significant . Oh . OK . Yeah . Still . Mm - hmm . But {disfmarker} but uh what {disfmarker} what I think I 'd be interested to do given that , is that we {disfmarker} we should uh {vocalsound} take {disfmarker} I guess that somebody 's gonna do this , right ? {disfmarker} is to take some of these tandem things and feed it into the SRI system , right ? Yeah . Yeah . We can do something like that . Yeah . Because {disfmarker} Yeah . But {disfmarker} But I guess the main point is the data because uh {vocalsound} I am not sure . Our back - end is {disfmarker} is fairly simple but until now , well , the attempts to improve it or {disfmarker} have fail Ah , well , I mean uh what Chuck tried to {disfmarker} to {disfmarker} to do Yeah , but he 's doing it with the same data , right ? I mean so to {disfmarker} {vocalsound} So there 's {disfmarker} there 's {disfmarker} there 's two things being affected . Yeah . So it 's {disfmarker} Yeah . I mean . One is that {disfmarker} that , you know , there 's something simple that 's wrong with the back - end . We 've been playing a number of states Mm - hmm . uh I {disfmarker} I don't know if he got to the point of playing with the uh number of Gaussians yet Mm - hmm . but {disfmarker} but uh , uh , you know . But , yeah , so far he hadn't gotten any big improvement , Mm - hmm . but that 's all with the same amount of data which is pretty small . Yeah . And um . Mmm . So , yeah , we could retrain some of these tandem on {disfmarker} on huge {disfmarker} Well , you could do that , but I 'm saying even with it not {disfmarker} with that part not retrained , just {disfmarker} just using {disfmarker} having the H M Ms {disfmarker} much better H M Ah , yeah . Just {disfmarker} f for the HMM models . Yeah . Yeah . Mm - hmm . Mm - hmm . Um . {vocalsound} But just train those H M Ms using different features , the features coming from our Aurora stuff . Yeah . So . Yeah . But {vocalsound} what would be interesting to see also is what {disfmarker} what {disfmarker} perhaps it 's not related , the amount of data but the um recording conditions . I don't know . Because {vocalsound} it 's probably not a problem of noise , because our features are supposed to be robust to noise . Well , yeah . It 's not a problem of channel , because there is um {vocalsound} {vocalsound} normalization with respect to the channel . So {disfmarker} I {disfmarker} I {disfmarker} I 'm sorry . What {disfmarker} what is the problem that you 're trying to explain ? The {disfmarker} the fact that {disfmarker} the result with the tandem and Aurora system are {vocalsound} uh so much worse . That the {disfmarker} Oh . So much worse ? Oh . Yeah . I uh but I 'm {disfmarker} I 'm almost certain that it {disfmarker} it {disfmarker} {vocalsound} I mean , that it has to do with the um amount of training data . It {disfmarker} It {disfmarker} it 's {disfmarker} it 's orders of magnitude off . Yeah but {disfmarker} Yeah . Yeah but we train only on digits and it 's {disfmarker} it 's a digit task , so . Well . But {disfmarker} but having a huge {disfmarker} If {disfmarker} {vocalsound} if you look at what commercial places do , they use a huge amount of data . It {disfmarker} Mm - hmm . This is a modest amount of data . Alright . Yeah . So . {vocalsound} I mean , ordinarily you would say \" well , given that you have enough occurrences of the digits , you can just train with digits rather than with , you know \" {disfmarker} Mm - hmm . Mm - hmm . But the thing is , if you have a huge {disfmarker} in other words , do word models {disfmarker} But if you have a huge amount of data then you 're going to have many occurrences of similar uh allophones . Right . Mmm . And that 's just a huge amount of training for it . Yeah . So it 's {vocalsound} um {disfmarker} {vocalsound} I {disfmarker} I think it has to be that , because , as you say , this is , you know , this is near - microphone , Mm - hmm . it 's really pretty clean data . Mm - hmm . Um . Now , some of it could be the fact that uh {disfmarker} let 's see , in the {disfmarker} in these multi - train things did we include noisy data in the training ? Yeah . I mean , that could be hurting us actually , for the clean case . Yeah . Well , actually we see that the clean train for the Aurora proposals are {disfmarker} are better than the multi - train , It is if {disfmarker} Yeah . yeah . Yeah . Cuz this is clean data , and so that 's not too surprising . Mm - hmm . But um . Uh . So . Well , o I guess what I meant is that well , let 's say if we {disfmarker} if we add enough data to train on the um on the Meeting Recorder digits , I guess we could have better results than this . Uh - huh . Mm - hmm . And . What I meant is that perhaps we can learn something uh from this , what 's {disfmarker} what 's wrong uh what {disfmarker} what is different between TI - digits and these digits and {disfmarker} What kind of numbers are we getting on TI - digits ? It 's point eight percent , so . Oh . I see . Four - Fourier . So in the actual TI - digits database we 're getting point eight percent , Yeah . Yeah . and here we 're getting three or four {disfmarker} three , let 's see , three for this ? Mm - hmm . Yeah . Sure , but I mean , um point eight percent is something like double uh or triple what people have gotten who 've worked very hard at doing that . Mm - hmm . And {disfmarker} and also , as you point out , there 's adaptation in these numbers also . So if you , you know , put the ad adap take the adaptation off , then it {disfmarker} for the English - Near you get something like two percent . Mmm . And here you had , you know , something like three point four . And I could easily see that difference coming from this huge amount of data that it was trained on . Mm - hmm . So it 's {disfmarker} Mm - hmm . You know , I don't think there 's anything magical here . Yeah . It 's , you know , we used a simple HTK system with a modest amount of data . And this is a {disfmarker} a , you know , modern {vocalsound} uh system uh has {disfmarker} has a lot of nice points to it . Yeah . Mm - hmm . Um . So . I mean , the HTK is an older HTK , even . So . Yeah it {disfmarker} it 's not that surprising . Mm - hmm . But to me it just {disfmarker} it just meant a practical {vocalsound} point that um if we want to {vocalsound} publish results on digits that {disfmarker} that people pay {vocalsound} attention to we probably should uh {disfmarker} Cuz we 've had the problem before that you get {disfmarker} show some {vocalsound} nice improvement on something that 's {disfmarker} that 's uh , uh {disfmarker} it seems like too large a number , and uh {vocalsound} uh people don't necessarily take it so seriously . Mm - hmm . Um . Yeah . Yeah . So the three point four percent for this uh is {disfmarker} is uh {disfmarker} So why is it {disfmarker} It 's an interesting question though , still . Why is {disfmarker} why is it three point four percent for the d the digits recorded in this environment as opposed to {vocalsound} the uh point eight percent for {disfmarker} for {disfmarker} for the original TI - digits database ? Um . Yeah . th that 's {disfmarker} th that 's my point Given {disfmarker} given the same {disfmarker} Yeah . So ignore {disfmarker} ignoring the {disfmarker} the {disfmarker} the SRI system for a moment , I {disfmarker} I {disfmarker} I don't I {disfmarker} Mm - hmm . just looking at {vocalsound} the TI - di the uh tandem system , if we 're getting point eight percent , which , yes , it 's high . It 's , you know , it {disfmarker} it 's not awfully high , Mm - hmm . but it 's , you know {disfmarker} it 's {disfmarker} it 's high . Um . {vocalsound} Why is it {vocalsound} uh four times as high , or more ? Yeah , I guess . Right ? I mean , there 's {disfmarker} {vocalsound} even though it 's close - miked there 's still {disfmarker} there really is background noise . Mm - hmm . Um . And {vocalsound} uh I suspect when the TI - digits were recorded if somebody fumbled or said something wrong or something that they probably made them take it over . Mm - hmm . It was not {disfmarker} I mean there was no attempt to have it be realistic in any {disfmarker} in any sense at all . Well . Yeah . And acoustically , it 's q it 's {disfmarker} I listened . It 's quite different . TI - digit is {disfmarker} it 's very , very clean and it 's like studio recording Mm - hmm . whereas these Meeting Recorder digits sometimes you have breath noise and Mmm . Right . Yeah . So I think they were {disfmarker} It 's {nonvocalsound} not controlled at all , I mean . Bless you . Thanks . I {disfmarker} Yeah . I think it 's {disfmarker} it 's {disfmarker} So . Yes . Mm - hmm . But It 's {disfmarker} I think it 's {disfmarker} it 's the indication it 's harder . Yeah . Uh . {vocalsound} Yeah and again , you know , i that 's true either way . I mean so take a look at the uh {disfmarker} {vocalsound} um , the SRI results . I mean , they 're much much better , but still you 're getting something like one point three percent for uh things that are same data as in T {disfmarker} TI - digits the same {disfmarker} same text . Mm - hmm . Uh . And uh , I 'm sure the same {disfmarker} same system would {disfmarker} would get , you know , point {disfmarker} point three or point four or something {vocalsound} on the actual TI - digits . So this {disfmarker} I think , on both systems the {vocalsound} these digits are showing up as harder . Mmm . Um . Mm - hmm . Which I find sort of interesting cause I think this is closer to {disfmarker} uh I mean it 's still read . But I still think it 's much closer to {disfmarker} to what {disfmarker} what people actually face , {vocalsound} um when they 're {disfmarker} they 're dealing with people saying digits over the telephone . I mean . {vocalsound} I don't think uh {disfmarker} I mean , I 'm sure they wouldn't release the numbers , but I don't think that uh {vocalsound} the uh {disfmarker} the {disfmarker} the companies that {disfmarker} that do telephone {vocalsound} speech get anything like point four percent on their {vocalsound} digits . I 'm {disfmarker} I 'm {disfmarker} I 'm sure they get {disfmarker} Uh , I mean , for one thing people do phone up who don't have uh uh Middle America accents and it 's a we we it 's {disfmarker} it 's {disfmarker} it 's US . Mm - hmm . it has {disfmarker} has many people {vocalsound} {vocalsound} who sound in many different ways . So . Um . I mean . OK . That was that topic . What else we got ? Um . Did we end up giving up on {disfmarker} on , any Eurospeech submissions , But {disfmarker} or {disfmarker} ? I know Thilo and Dan Ellis are {disfmarker} are submitting something , but uh . Yeah . I {disfmarker} {vocalsound} I guess e the only thing with these {disfmarker} the Meeting Recorder and , well , {disfmarker} So , I think , yeah {disfmarker} I think we basically gave up . Um . {vocalsound} Now , actually for the {disfmarker} for the Aur - uh But {disfmarker} we do have stuff for Aurora , right ? Because {disfmarker} because we have ano an extra month or something . Yeah . Yeah . Yeah . So . Yeah , for sure we will do something for the special session . Yeah . Well , that 's fine . So th so {disfmarker} so we have a couple {disfmarker} a couple little things on Meeting Recorder Yeah . Mm - hmm . and we have {disfmarker} {vocalsound} We don't {disfmarker} we don't have to flood it with papers . We 're not trying to prove anything to anybody . so . That 's fine . Um . Anything else ? Yeah . Well . So . Perhaps the point is that we 've been working on {vocalsound} is , yeah , we have put the um the good VAD in the system and {vocalsound} it really makes a huge difference . Um . So , yeah . I think , yeah , this is perhaps one of the reason why our system was not {disfmarker} {vocalsound} not the best , because with the new VAD , it 's very {disfmarker} the results are similar to the France Telecom results and perhaps even better sometimes . Hmm . Huh . Um . So there is this point . Uh . The problem is that it 's very big and {vocalsound} {vocalsound} we still have to think how to {disfmarker} where to put it and {disfmarker} {vocalsound} um , Mm - hmm . because it {disfmarker} it {disfmarker} well , this VAD uh either some delay and we {disfmarker} if we put it on the server side , it doesn't work , because on the server side features you already have LDA applied {vocalsound} from the f from the terminal side and {vocalsound} so you accumulate the delay so the VAD should be before the LDA which means perhaps on the terminal side and then smaller {vocalsound} and So wha where did this good VAD come from ? So . It 's um from OGI . So it 's the network trained {disfmarker} it 's the network with the huge amounts on hidden {disfmarker} of hidden units , and um nine input frames compared to the VAD that was in the proposal which has a very small amount of hidden units and fewer inputs . This is the one they had originally ? Yeah . Oh . Yeah , but they had to {pause} get rid of it because of the space , didn't they ? Yeah . So . Yeah . But the abso assumption is that we will be able to make a VAD that 's small and that works fine . And . So we can {disfmarker} Well . So that 's a problem . Yeah . Yeah but {disfmarker} nnn . But the other thing is uh to use a different VAD entirely . I mean , uh i if {disfmarker} if there 's a {vocalsound} if {disfmarker} if {disfmarker} I {disfmarker} I don't know what the thinking was amongst the {disfmarker} the {disfmarker} the {vocalsound} the ETSI folk but um if everybody agreed sure let 's use this VAD and take that out of there {disfmarker} Mm - hmm . Mm - hmm . They just want , apparently {disfmarker} they don't want to fix the VAD because they think there is some interaction between feature extraction and {disfmarker} and VAD or frame dropping But they still {vocalsound} want to {disfmarker} just to give some um {vocalsound} requirement for this VAD because it 's {disfmarker} it will not be part of {disfmarker} they don't want it to be part of the standard . OK . So . So it must be at least uh somewhat fixed but not completely . So there just will be some requirements that are still not {disfmarker} uh not yet uh ready I think . Determined . I see . But I was thinking that {disfmarker} that uh {vocalsound} s \" Sure , there may be some interaction , Nnn . but I don't think we need to be stuck on using our or OGI 's {pause} VAD . We could use somebody else 's if it 's smaller or {disfmarker} Yeah . You know , as long as it did the job . Mm - hmm . So that 's good . Uh . So there is this thing . There is um {disfmarker} Yeah . Uh I designed a new {disfmarker} a new filter because when I designed other filters with shorter delay from the LDA filters , {vocalsound} there was one filter with fif sixty millisecond delay and the other with ten milliseconds Right . and {vocalsound} uh Hynek suggested that both could have sixty - five sixty - s I think it 's sixty - five . Yeah . Yeah . Both should have sixty - five because {disfmarker} You didn't gain anything , right ? Yeah . And . So I did that and uh it 's running . So , {vocalsound} let 's see what will happen . Uh but the filter is of course closer to the reference filter . Mm - hmm . Mmm . Um . Yeah . I think {disfmarker} So that means logically , in principle , it should be better . So probably it 'll be worse . Yeah Or in the basic perverse nature uh of reality . Yeah . OK . Yeah . Sure . Yeah . OK . Yeah , and then we 've started to work with this of um voiced - unvoiced stuff . Mm - hmm . And next week I think we will {vocalsound} perhaps try to have um a new system with uh uh MSG stream also see what {disfmarker} what happens . So , something that 's similar to the proposal too , but with MSG stream . Mm - hmm . Mm - hmm . Mmm . OK . No , I w {vocalsound} I begin to play {vocalsound} with Matlab and to found some parameter robust for voiced - unvoiced decision . But only to play . And we {disfmarker} {vocalsound} they {disfmarker} we found that maybe w is a classical parameter , the {vocalsound} sq the variance {vocalsound} between the um FFT of the signal and the small spectrum of time {vocalsound} we {disfmarker} after the um mel filter bank . Uh - huh . And , well , is more or less robust . Is good for clean speech . Is quite good {vocalsound} for noisy speech . Huh ? Mm - hmm . but um we must to have bigger statistic with TIMIT , Mm - hmm . and is not ready yet to use on , Yeah . well , I don't know . Yeah . Yeah . So , basically we wa want to look at something like the ex the ex excitation signal and {disfmarker} Right . Mm - hmm . which are the variance of it and {disfmarker} I have here . I have here for one signal , for one frame . Mmm . Yeah . Uh - huh . The {disfmarker} the mix of the two , noise and unnoise , and the signal is this . Clean , and this noise . Uh . These are the two {disfmarker} the mixed , the big signal is for clean . Well , I 'm s uh {disfmarker} There 's {disfmarker} None of these axes are labeled , so I don't know what this {disfmarker} What 's this axis ? Uh this is uh {disfmarker} this axis is {vocalsound} nnn , \" frame \" . Frame . Mm - hmm . And what 's th what this ? Uh , this is uh energy , log - energy of the spectrum . Of the this is the variance , the difference {nonvocalsound} between the spectrum of the signal and FFT of each frame of the signal and this mouth spectrum of time after the f may fit for the two , For this one . For the noi this big , to here , they are to signal . This is for clean and this is for noise . Oh . There 's two things on the same graph . Yeah . I don't know . I {disfmarker} I think that I have d another graph , but I 'm not sure . So w which is clean and which is noise ? Yeah . I think the lower one is noise . The lower is noise and the height is clean . OK . So it 's harder to distinguish It 's height . but it {disfmarker} but it g Yeah . with noise of course but {disfmarker} but {disfmarker} Oh . I must to have . Uh . Pity , but I don't have two different And presumably when there 's a {disfmarker} a {disfmarker} So this should the {disfmarker} the {disfmarker} the t voiced portions . Uh - huh . Yeah , it is the height is voiced portion . The p the peaks should be voiced portion . And this is the noise portion . Uh - huh . And this is more or less like this . But I meant to have see @ @ two {disfmarker} two the picture . Yeah . Yeah . This is , for example , for one frame . Yeah the {disfmarker} the spectrum of the signal . And this is the small version of the spectrum after ML mel filter bank . Yeah . And this is the difference ? And this is I don't know . This is not the different . This is trying to obtain {vocalsound} with LPC model the spectrum but using Matlab without going factor and s No pre - emphasis ? Yeah . Not pre - emphasis . Nothing . Yeah so it 's {disfmarker} doesn't do too well there . And the {disfmarker} I think that this is good . This is quite similar . this is {disfmarker} {vocalsound} this is another frame . ho how I obtained the {vocalsound} envelope , {nonvocalsound} this envelope , with the mel filter bank . Right . So now I wonder {disfmarker} I mean , do you want to {disfmarker} I know you want to get at something orthogonal from what you get with the smooth spectrum Um . But if you were to really try and get a voiced - unvoiced , do you {disfmarker} do you want to totally ignore that ? I mean , do you {disfmarker} do you {disfmarker} I mean , clearly a {disfmarker} a very big {disfmarker} very big cues {vocalsound} for voiced - unvoiced come from uh spectral slope and so on , right ? Mm - hmm . Um . Yeah . Well , this would be {disfmarker} this would be perhaps an additional parameter , Yeah . simply isn't {disfmarker} I see . Yeah . Yeah because when did noise clear {nonvocalsound} in these section is clear Uh . Mm - hmm . if s @ @ {nonvocalsound} val value is indicative that is a voice frame and it 's low values Yeah . Yeah . Well , you probably want {disfmarker} I mean , {vocalsound} certainly if {vocalsound} you want to do good voiced - unvoiced detection , you need a few features . Each {disfmarker} each feature is {vocalsound} by itself not enough . But , you know , people look at {disfmarker} at slope and {vocalsound} uh first auto - correlation coefficient , divided by power . Mmm . Or {disfmarker} or uh um there 's uh {disfmarker} I guess we prob probably don't have enough computation to do a simple pitch detector or something ? I mean with a pitch detector you could have a {disfmarker} {vocalsound} have a {disfmarker} an estimate of {disfmarker} of what the {disfmarker} Mmm . Uh . Or maybe you could you just do it going through the P FFT 's figuring out some um probable {vocalsound} um harmonic structure . Right . And {disfmarker} and uh . Mmm . you have read up and {disfmarker} you have a paper , {vocalsound} the paper that you s give me yesterday . they say that yesterday {vocalsound} they are some {nonvocalsound} problem Oh , yeah . But {disfmarker} Yeah , but it 's not {disfmarker} it 's , yeah , it 's {disfmarker} it 's another problem . and the {disfmarker} Is another problem . Yeah Um . Yeah , there is th this fact actually . If you look at this um spectrum , Yeah . What 's this again ? Is it {vocalsound} the mel - filters ? Yeah like this . Of kind like this . Yeah . OK . So the envelope here is the output of the mel - filters Mm - hmm . and what we clearly see is that in some cases , and it clearly appears here , and the {disfmarker} the harmonics are resolved by the f Well , there are still appear after mel - filtering , Mm - hmm . and it happens {vocalsound} for high pitched voice because the width of the lower frequency mel - filters {vocalsound} is sometimes even smaller than the pitch . Yeah . It 's around one hundred , one hundred and fifty hertz {vocalsound} Nnn . Right . And so what happens is that this uh , add additional variability to this envelope and {vocalsound} {vocalsound} um Yeah . so we were thinking to modify the mel - spectrum to have something that {disfmarker} that 's smoother on low frequencies . That 's as {disfmarker} as a separate thing . i Yeah . Yeah . This is a separate thing . Separate thing ? Yeah . Yeah . And . Yeah . Maybe so . Um . Yeah . So , what {disfmarker} Yeah . What I was talking about was just , starting with the FFT you could {disfmarker} you could uh do a very rough thing to estimate {disfmarker} estimate uh pitch . Yeah . Mm - hmm . And uh uh , given {disfmarker} you know , given that , uh {vocalsound} you could uh uh come up with some kind of estimate of how much of the low frequency energy was {disfmarker} was explained by {disfmarker} {vocalsound} by uh uh those harmonics . Mm - hmm . Uh . It 's uh a variant on what you 're s what you 're doing . The {disfmarker} I mean , the {disfmarker} the {vocalsound} the mel does give a smooth thing . But as you say it 's not that smooth here . And {disfmarker} and so if you {disfmarker} {vocalsound} if you just you know subtracted off uh your guess of the harmonics then something like this would end up with {vocalsound} quite a bit lower energy in the first fifteen hundred hertz or so and {disfmarker} and our first kilohertz , even . Mm - hmm . And um {vocalsound} if was uh noisy , the proportion that it would go down would be if it was {disfmarker} if it was unvoiced or something . Mm - hmm . So you oughta be able to {vocalsound} pick out voiced segments . At least it should be another {disfmarker} another cue . So . {vocalsound} Anyway . Mm - hmm . OK ? That 's what 's going on . Uh . What 's up with you ? Um {vocalsound} our t I went to {vocalsound} talk with uh Mike Jordan this {disfmarker} this week Mm - hmm . um {nonvocalsound} and uh {vocalsound} shared with him the ideas about um {vocalsound} extending the Larry Saul work and um I asked him some questions about factorial H M so like later down the line when {vocalsound} we 've come up with these {disfmarker} these feature detectors , how do we {disfmarker} {vocalsound} how do we uh {vocalsound} you know , uh model the time series that {disfmarker} that happens um {vocalsound} {vocalsound} and {vocalsound} and we talked a little bit about {vocalsound} factorial H M Ms and how {vocalsound} um when you 're doing inference {disfmarker} or w when you 're doing recognition , there 's like simple Viterbi stuff that you can do for {disfmarker} {vocalsound} for these H M and {vocalsound} the uh {disfmarker} {vocalsound} the great advantages that um a lot of times the factorial H M Ms don't {vocalsound} um {vocalsound} don't over - alert the problem there they have a limited number of parameters and they focus directly on {disfmarker} {vocalsound} on uh the sub - problems at hand so {vocalsound} you can imagine {vocalsound} um {vocalsound} five or so parallel {vocalsound} um features um transitioning independently and then {vocalsound} at the end you {disfmarker} you uh couple these factorial H M Ms with uh {disfmarker} {vocalsound} with uh undirected links um based on {disfmarker} {vocalsound} based on some more data . Hmm . So he {disfmarker} he seemed {disfmarker} he seemed like really interested in {disfmarker} {vocalsound} in um {disfmarker} in this and said {disfmarker} said this is {disfmarker} this is something very do - able and can learn a lot and um yeah , I 've just been {vocalsound} continue reading um about certain things . Mm - hmm . um thinking of maybe using um {vocalsound} um m modulation spectrum stuff to {vocalsound} um {disfmarker} as features um also in the {disfmarker} in the sub - bands Mm - hmm . because {vocalsound} it seems like {vocalsound} the modulation um spectrum tells you a lot about the intelligibility of {disfmarker} of certain um words and stuff So , um . Yeah . Just that 's about it . OK . OK . And um so I 've been looking at Avendano 's work and um uh I 'll try to write up in my next stat status report a nice description of {vocalsound} what he 's doing , but it 's {disfmarker} it 's an approach to deal with {vocalsound} reverberation or that {disfmarker} the aspect of his work that I 'm interested in the idea is that um {vocalsound} {vocalsound} {vocalsound} normally an analysis frames are um {vocalsound} too short to encompass reverberation effects um in full . You miss most of the reverberation tail in a ten millisecond window and so {vocalsound} {vocalsound} you {disfmarker} you 'd like it to be that {vocalsound} um {vocalsound} the reverberation responses um simply convolved um in , but it 's not really with these ten millisecond frames cuz you j But if you take , say , a two millisecond {vocalsound} um window {disfmarker} I 'm sorry a two second window then in a room like this , most of the reverberation response {vocalsound} is included in the window and the {disfmarker} then it um {vocalsound} then things are l more linear . It is {disfmarker} it is more like the reverberation response is simply c convolved and um {disfmarker} {vocalsound} and you can use channel normalization techniques {vocalsound} like uh in his thesis he 's assuming that the reverberation response is fixed . He just does um {vocalsound} mean subtraction , which is like removing the DC component of the modulation spectrum and {vocalsound} that 's supposed to d um deal {disfmarker} uh deal pretty well with the um reverberation and um {vocalsound} the neat thing is you can't take these two second frames and feed them to a speech recognizer um {vocalsound} so he does this {vocalsound} um {vocalsound} method training trading the um {vocalsound} the spectral resolution for time resolution {vocalsound} and um {vocalsound} come ca uh synthesizes a new representation which is with say ten second frames but a lower s um {vocalsound} frequency resolution . So I don't really know the theory . I guess it 's {disfmarker} these are called \" time frequency representations \" and h he 's making the {disfmarker} the time sh um finer grained and the frequency resolution um less fine grained . Mm - hmm . s so I 'm {disfmarker} I guess my first stab actually in continuing {vocalsound} his work is to um {vocalsound} re - implement this {disfmarker} this thing which um {vocalsound} changes the time and frequency resolutions cuz he doesn't have code for me . So that that 'll take some reading about the theory . I don't really know the theory . Mm - hmm . Oh , and um , {vocalsound} another f first step is um , so the {disfmarker} the way I want to extend his work is make it able to deal with a time varying reverberation response um {vocalsound} and um we don't really know {vocalsound} how fast the um {disfmarker} the reverberation response is varying the Meeting Recorder data um so um {vocalsound} we {disfmarker} we have this um block least squares um imp echo canceller implementation and um {vocalsound} I want to try {vocalsound} finding {vocalsound} the {disfmarker} the response , say , between a near mike and the table mike for someone using the echo canceller and looking at the echo canceller taps and then {vocalsound} see how fast that varies {vocalsound} from block to block . Mm - hmm . That should give an idea of how fast the reverberation response is changing . Mm - hmm . OK . Um . I think we 're {vocalsound} sort of done . Yeah . So let 's read our digits and go home . Um . S so um y you do {disfmarker} I think you read some of the {disfmarker} the zeros as O 's and some as zeros . Yeah . Is there a particular way we 're supposed to read them ? There are only zeros here . Well . No . \" O \" {disfmarker} \" O \" {disfmarker} \" O \" \" O \" {disfmarker} \" O \" {disfmarker} \" O \" and \" zero \" are two ways that we say that digit . Eee . Yeah . So it 's {disfmarker} Ha ! But {disfmarker} so it 's {disfmarker} i Perhaps in the sheets there should be another sign for the {disfmarker} if we want to {disfmarker} the {disfmarker} the guy to say \" O \" or No . I mean . I think people will do what they say . It 's {disfmarker} It 's OK . Yeah . I mean in digit recognition we 've done before , you have {disfmarker} you have two pronunciations for that value , \" O \" and \" zero \" . Alright . OK . OK . But it 's perhaps more difficult for the people to prepare the database then , if {disfmarker} because here you only have zeros No , they just write {disfmarker} and {disfmarker} and people pronounce \" O \" or zero {disfmarker} they {disfmarker} they write down OH . or they write down ZERO a and they {disfmarker} and they each have their own pronunciation . Yeah but if the sh the sheet was prepared with a different sign for the \" O \" . But people wouldn't know what that wa I mean {vocalsound} there is no convention for it . OK . Yeah . See . I mean , you 'd have to tell them {vocalsound} \" OK when we write this , say it tha \" , OK . you know , and you just {disfmarker} They just want people to read the digits as you ordinarily would Mm - hmm . Yeah . and {disfmarker} and people say it different ways . Yep . OK . Is this a change from the last batch of {disfmarker} of um forms ? Because in the last batch it was spelled out which one you should read . Yeah , it was orthographic , so . Yes . That 's right . It was {disfmarker} it was spelled out , and they decided they wanted to get at more the way people would really say things . Oh . OK . That 's also why they 're {disfmarker} they 're bunched together in these different groups . So {disfmarker} so it 's {disfmarker} OK . Yeah . So it 's {disfmarker} it 's {disfmarker} Everything 's fine . OK . OK . Actually , let me just s since {disfmarker} since you brought it up , I was just {disfmarker} it was hard not to be self - conscious about that when it {vocalsound} after we {disfmarker} since we just discussed it . But I realized that {disfmarker} that um {vocalsound} when I 'm talking on the phone , certainly , and {disfmarker} and saying these numbers , {vocalsound} I almost always say zero . And uh {disfmarker} cuz {disfmarker} because uh i it 's two syllables . It 's {disfmarker} it 's more likely they 'll understand what I said . So that {disfmarker} that {disfmarker} that 's the habit I 'm in , but some people say \" O \" and {disfmarker} Yeah I normally say \" O \" cuz it 's easier to say . Yeah it 's shorter . Yeah . So it 's {disfmarker} So . {vocalsound} So uh . \" O \" Now , don't think about it . Oh , no ! OK . We 're done .",
        "summarize": null
    }
]